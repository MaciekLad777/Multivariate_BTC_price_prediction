{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wGjUW-TFrukp"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "file_path = \"/content/drive/MyDrive/CRYPTO/Preprocessed_data/data.csv\"\n",
        "\n",
        "data = pd.read_csv(file_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "nan_values = data.isna().any().any()\n",
        "\n",
        "if nan_values:\n",
        "    print(\"There are NaN values in the DataFrame.\")\n",
        "else:\n",
        "    print(\"There are no NaN values in the DataFrame.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2UeY2rYYr8S",
        "outputId": "e6e6907d-fe18-4fb5-9fed-c7b110e49233"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are NaN values in the DataFrame.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Na początek wypełniamy brakujące wartości średnią wartości z danej kolumny"
      ],
      "metadata": {
        "id": "_nuAl0a8zBIu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data_filled = data.fillna(data.mean())"
      ],
      "metadata": {
        "id": "De79xJSfY_Z7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA = data_filled.values"
      ],
      "metadata": {
        "id": "ld5-cyTDFVM8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA[0][:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PD5DrB7PAZpv",
        "outputId": "2cd97ef9-8484-4c12-9a1c-fc7f865880ea"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7.44683008e+03, 7.44683008e+03, 7.10152002e+03, 7.14358008e+03,\n",
              "       2.05314000e+00])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dzielimy dane na ramki.\n",
        "\n",
        "Będziemy przewidywać 1 dzień na podstawie poprzedniego miesiącia czyli 1 ramka będzie zawierała dane z 30 dni, każdy dzień zawiera dane z poszczególnych kolumn\n",
        "\n"
      ],
      "metadata": {
        "id": "BBU52cXVA1Js"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATA.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1xx8XOoNF2t",
        "outputId": "69854225-2aea-4681-8c5c-505590d5ca71"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2344, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def reshape_data_mlt(data, n_timesteps):\n",
        "    n_samples, n_features = data.shape\n",
        "\n",
        "    reshaped_data_X = np.zeros((n_samples - n_timesteps, n_timesteps, n_features))\n",
        "    reshaped_data_y = np.zeros((n_samples - n_timesteps, n_features))\n",
        "\n",
        "    for i in range(n_samples - n_timesteps):\n",
        "        reshaped_data_X[i] = data[i:i+n_timesteps]\n",
        "        reshaped_data_y[i] = data[i+n_timesteps]\n",
        "\n",
        "    return reshaped_data_X, reshaped_data_y\n"
      ],
      "metadata": {
        "id": "v5eOM5X6Pz6p"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_timesteps=30\n",
        "n_features=50"
      ],
      "metadata": {
        "id": "TQ_syyzyPT4d"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Zrobimy prosty model bez specjalnego przygotowania danych, użyjemy jedynie naszej funkcji do zmiany kształtu danych.\n",
        "\n",
        "Sprawdzimy czy nie będzie żadnych nieoczekiwanych błędów."
      ],
      "metadata": {
        "id": "7kOvKlR-zutS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM,Dense,Dropout\n",
        "\n",
        "\n",
        "# Reshape the data into windows\n",
        "X, y = reshape_data_mlt(DATA, n_timesteps)\n",
        "\n",
        "# Extract only the first element of each target (y) sample\n",
        "y = y[:, 3]\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "# Define the LSTM model\n",
        "model = Sequential([\n",
        "    LSTM(50, activation='relu', input_shape=(n_timesteps, n_features)),\n",
        "    Dense(1)  # Output only 1 value\n",
        "])\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "optimizer = Adam(lr=0.001)  # Adjust the learning rate as needed\n",
        "model.compile(optimizer=optimizer, loss='mse',metrics=[\"mae\"])\n",
        "\n",
        "# Add a callback to reduce learning rate on plateau\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001)\n",
        "callbacks = [reduce_lr]\n",
        "\n",
        "# Train the model with callbacks\n",
        "# history = model.fit(X, y, epochs=500, batch_size=32, validation_split=0.2, callbacks=callbacks)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABNUeMSjSatz",
        "outputId": "e3cda6b8-906b-4d3e-9c24-2fcf68290981"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model.save(\"/content/drive/MyDrive/CRYPTO/Models/OVERALL_model.h5\")"
      ],
      "metadata": {
        "id": "IY-s6q60mUew"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the saved model\n",
        "OVERALL_model = load_model(\"/content/drive/MyDrive/CRYPTO/Models/OVERALL_model.h5\")"
      ],
      "metadata": {
        "id": "jyJfaXbzmbcv"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OVERALL_model.evaluate(X,y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NHs0Oc8hf8Q",
        "outputId": "1b5fefb6-2b37-4005-e450-c20dcf73ada5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73/73 [==============================] - 2s 11ms/step - loss: 337231968.0000 - mae: 7044.8047\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[337231968.0, 7044.8046875]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model myli się o około 7-8 tysięcy. Biorąc pod uwagę że cena BTC zazwyczaj utrzymuje się między 10-60k. Oczywiście nie jest to model który można uznać za dobry ale teraz mamy pewność, że zarówna nasza funkcja jak i model działa bez żadnych błędów.\n",
        "\n",
        " Dzięki temu mamy również pogląd na czym stoimy, jakie wyniki jesteśmy w stanie uzyskać za pomocą najprostszej architektury i bez specjalnej regularyzacji.\n",
        "\n",
        "Teraz dokładniej przeanalizujemy wpływ poszczególnych danych na wynik."
      ],
      "metadata": {
        "id": "cppGb-FwmoQC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_list = [str(i) for i in range(50)]\n",
        "print(my_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5bA4Zdfq72v",
        "outputId": "c67d6b96-0acb-4361-9f14-10ac54aca654"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del my_list[4]"
      ],
      "metadata": {
        "id": "Uauu4HtQq_bW"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Algorytm sprawdzający które kolumny mają największy wpływ na target"
      ],
      "metadata": {
        "id": "QZmjBgwivz5u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_filled.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QlQMhDutkTbD",
        "outputId": "059ffd11-0d1b-4b9c-ac1c-9d96336b7a13"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2344, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Define features and target variable\n",
        "features = my_list\n",
        "\n",
        "df= data_filled\n",
        "X = df[features]\n",
        "y = df['3']\n",
        "\n",
        "# Initialize and train the RandomForestRegressor\n",
        "regressor = RandomForestRegressor()\n",
        "regressor.fit(X, y)\n",
        "\n",
        "# Plot feature importances\n",
        "importances = regressor.feature_importances_\n",
        "sorted_idx = np.argsort(importances)\n",
        "print(sorted_idx)\n",
        "padding = np.arange(len(features)) + 0.5\n",
        "plt.barh(padding, importances[sorted_idx], align='center')\n",
        "# plt.yticks(padding, features[sorted_idx])\n",
        "plt.xlabel(\"Relative Importance\")\n",
        "plt.title(\"Variable Importance\")\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "id": "qX2mORxcsau1",
        "outputId": "5c653018-c22a-451b-9e01-5166c4be4713"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[48 44 13 47 45 12 46 14 19 22 20 23 18 15 11 21 28 36  9 16 17  4  8 10\n",
            "  5  7 32  6 40 38 42 33 29  0 24 25 26 34 30 41  2  1 37 43 27 39 31 35\n",
            "  3]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_idx=np.flip(sorted_idx)"
      ],
      "metadata": {
        "id": "Jrm82bAvgI6U"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(sorted_idx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjFsJ5gJhF2b",
        "outputId": "3516b3a8-3997-48a3-f328-03809fb6b502"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "List_of_data=[\"BTC_OPEN\",\"BTC_HIGH\",\"BTC_LOW\",\"BTC_CLOSE\",\"BNB_OPEN\",\"BNB_HIGH\",\"BNB_LOW\",\"BNB_CLOSE\",\"ETH_OPEN\",\"ETH_HIGH\",\"ETH_LOW\",\"ETH_CLOSE\",\"BCH_OPEN\",\"BCH_HIGH\",\"BCH_LOW\",\"BCH_CLOSE\",\"DOGE_OPEN\",\"DOGE_HIGH\",\"DOGE_LOW\",\"DOGE_CLOSE\",\"AVAX_OPEN\",\"AVAX_HIGH\",\"AVAX_LOW\",\"AVAX_CLOSE\",\"API_DATA\",\"CAD_OPEN\",\"CAD_HIGH\",\"CAD_LOW\",\"CAD_CLOSE\",\"CNY_OPEN\",\"CNY_HIGH\",\"CNY_LOW\",\"CNY_CLOSE\",\"EUR_OPEN\",\"EUR_HIGH\",\"EUR_LOW\",\"EUR_CLOSE\",\"GBP_OPEN\",\"GBP_HIGH\",\"GBP_LOW\",\"GBP_CLOSE\",\"JPY_OPEN\",\"JPY_HIGH\",\"JPY_LOW\",\"JPY_CLOSE\",\"BTC_VOLUME\",\"NYSE\",\"NASDAQ\",\"LSE\",\"HALVING\"]"
      ],
      "metadata": {
        "id": "V9MrWlKrh7U9"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x in range(len(List_of_data)-1):\n",
        "    print(List_of_data[sorted_idx[x]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-yc2CfAjKH4",
        "outputId": "3d4edb94-9f8f-47ca-9dcf-de99a66175d1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BTC_CLOSE\n",
            "EUR_LOW\n",
            "CNY_LOW\n",
            "GBP_LOW\n",
            "CAD_LOW\n",
            "JPY_LOW\n",
            "GBP_OPEN\n",
            "BTC_HIGH\n",
            "BTC_LOW\n",
            "JPY_OPEN\n",
            "CNY_HIGH\n",
            "EUR_HIGH\n",
            "CAD_HIGH\n",
            "CAD_OPEN\n",
            "API_DATA\n",
            "BTC_OPEN\n",
            "CNY_OPEN\n",
            "EUR_OPEN\n",
            "JPY_HIGH\n",
            "GBP_HIGH\n",
            "GBP_CLOSE\n",
            "BNB_LOW\n",
            "CNY_CLOSE\n",
            "BNB_CLOSE\n",
            "BNB_HIGH\n",
            "ETH_LOW\n",
            "ETH_OPEN\n",
            "BNB_OPEN\n",
            "DOGE_HIGH\n",
            "DOGE_OPEN\n",
            "ETH_HIGH\n",
            "EUR_CLOSE\n",
            "CAD_CLOSE\n",
            "AVAX_HIGH\n",
            "ETH_CLOSE\n",
            "BCH_CLOSE\n",
            "DOGE_LOW\n",
            "AVAX_CLOSE\n",
            "AVAX_OPEN\n",
            "AVAX_LOW\n",
            "DOGE_CLOSE\n",
            "BCH_LOW\n",
            "NYSE\n",
            "BCH_OPEN\n",
            "BTC_VOLUME\n",
            "NASDAQ\n",
            "BCH_HIGH\n",
            "JPY_CLOSE\n",
            "LSE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mamy teraz pewien pogląd na to które dane mają duży wpływ na wynik. Oczywiście nie jest to ostateczny wyznacznik, jedynie zgodność korelacji, warto jednak przyjrzeć się temu dokładniej."
      ],
      "metadata": {
        "id": "_J3y8G5CgFuF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Waluty\n",
        "\n",
        "Z analizy wynika że największa korelacja jest oczywiście z cenami w przeliczeniu na inne waluty. Nie mówi to koniecznie o tym że te właśnie dane polepszają jakość modelu. Wręcz przeciwnie, korelacja oznacza że dane są do siebie podobne, oznacza to że podawanie cen w porównaniu do innych walut może być tylko niepotrzebnym wprowadzaniem danych które ostatecznie nie dodają żadnych wartościowych informacji, jedynie je powielają. Możemy więc stwierdzić że powinniśmy traktować te listę w sposób odwrotny, dane z największą korelacją mogą być tymi które wprowadzają najmniej wartościowych informacji.\n",
        "\n",
        "Nie powinniśmy ich całkime usuwać, jednak należałoby ograniczyć ich ilość, np. poprzez usunięcie Open,High,Low. Tak szczegółowa analiza samych walut sprawi tylko że model będzie działał wolniej i niekoniecznie lepiej\n",
        "\n"
      ],
      "metadata": {
        "id": "WLM7XNpQl7PY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aby sprawdzić realny wpływ na performance stworzymy kilka prostych modeli\n",
        "\n",
        "1.BTC+co-currencies\n",
        "\n",
        "2.BTC+API\n",
        "\n",
        "3.BTC+waluty\n",
        "\n",
        "4.BTC+Volume\n",
        "\n",
        "5.BTC+Markets_value\n",
        "\n",
        "*Halving traktujemy jako integralną częśc ceny BTC, jego wpływ jest zbyt oczywisty, ważny aby go rozważać"
      ],
      "metadata": {
        "id": "D92PedIcmyBl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Na początek stworzymy jednak Base model, tylko na podstawie ceny BTC aby mieć punkt odniesienia"
      ],
      "metadata": {
        "id": "WyonEGedo6x-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Zmodyfikujemy naszą funckję. Teraz będzie tworzyła ramki jedynie z kolumn których indeksy jej podamy."
      ],
      "metadata": {
        "id": "tPSMOLCx1YkZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def reshape_data_mlt_feature_changer(data, n_timesteps, feature_indices):\n",
        "\n",
        "    n_samples, n_features = data.shape\n",
        "\n",
        "    reshaped_data_X = np.zeros((n_samples - n_timesteps, n_timesteps, len(feature_indices)))\n",
        "    reshaped_data_y = np.zeros((n_samples - n_timesteps, 1))\n",
        "\n",
        "    for i in range(n_samples - n_timesteps):\n",
        "        selected_features_X = data[i:i+n_timesteps, feature_indices]\n",
        "        selected_features_y = data[i+n_timesteps, 3]\n",
        "        reshaped_data_X[i] = selected_features_X\n",
        "        reshaped_data_y[i] = selected_features_y\n",
        "\n",
        "    return reshaped_data_X, reshaped_data_y\n"
      ],
      "metadata": {
        "id": "anrHDV-MSJxD"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Base model"
      ],
      "metadata": {
        "id": "0gfMX01g7pFP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_features=[0,1,2,3,49]"
      ],
      "metadata": {
        "id": "zL7pDvAxqGbX"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wprowadzamy MinMaxScaler, skalujemy wszystkie dane do wartości między 0 a 1."
      ],
      "metadata": {
        "id": "xF7h2BHL1kkv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "\n",
        "scalers = [MinMaxScaler() for _ in range(DATA.shape[1])]\n",
        "\n",
        "\n",
        "DATA_scaled = np.hstack([scaler.fit_transform(DATA[:, [i]]) for i, scaler in enumerate(scalers)])\n",
        "\n",
        "\n",
        "reshaped_data_X, reshaped_data_y=reshape_data_mlt_feature_changer(DATA_scaled,n_timesteps,base_features)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(reshaped_data_X, reshaped_data_y, test_size=0.2, random_state=42,shuffle=False)\n",
        "\n",
        "\n",
        "base_model = Sequential()\n",
        "base_model.add(LSTM(128, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True))\n",
        "base_model.add(Dropout(0.2))\n",
        "base_model.add(LSTM(64, return_sequences=False))\n",
        "base_model.add(Dense(1))\n",
        "\n",
        "optimizer = Adam(lr=0.001)\n",
        "base_model.compile(optimizer=optimizer, loss='mse', metrics=['mae', 'mse'])\n",
        "\n",
        "history = base_model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
        "\n",
        "loss, mae, mse = base_model.evaluate(X_test, y_test)\n",
        "print(\"Test Loss:\", loss)\n",
        "print(\"Test MAE:\", mae)\n",
        "print(\"Test MSE:\", mse)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTTUyAIlqieN",
        "outputId": "13e712cd-951f-4a4b-8528-35d956cc1ed1"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "47/47 [==============================] - 11s 93ms/step - loss: 0.0063 - mae: 0.0461 - mse: 0.0063 - val_loss: 0.0011 - val_mae: 0.0243 - val_mse: 0.0011\n",
            "Epoch 2/50\n",
            "47/47 [==============================] - 4s 95ms/step - loss: 0.0013 - mae: 0.0240 - mse: 0.0013 - val_loss: 0.0025 - val_mae: 0.0405 - val_mse: 0.0025\n",
            "Epoch 3/50\n",
            "47/47 [==============================] - 4s 77ms/step - loss: 0.0011 - mae: 0.0205 - mse: 0.0011 - val_loss: 0.0013 - val_mae: 0.0271 - val_mse: 0.0013\n",
            "Epoch 4/50\n",
            "47/47 [==============================] - 3s 65ms/step - loss: 0.0011 - mae: 0.0211 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0254 - val_mse: 0.0011\n",
            "Epoch 5/50\n",
            "47/47 [==============================] - 3s 67ms/step - loss: 8.8178e-04 - mae: 0.0196 - mse: 8.8178e-04 - val_loss: 0.0021 - val_mae: 0.0384 - val_mse: 0.0021\n",
            "Epoch 6/50\n",
            "47/47 [==============================] - 5s 98ms/step - loss: 9.6804e-04 - mae: 0.0212 - mse: 9.6804e-04 - val_loss: 0.0010 - val_mae: 0.0236 - val_mse: 0.0010\n",
            "Epoch 7/50\n",
            "47/47 [==============================] - 4s 80ms/step - loss: 8.4711e-04 - mae: 0.0184 - mse: 8.4711e-04 - val_loss: 0.0013 - val_mae: 0.0288 - val_mse: 0.0013\n",
            "Epoch 8/50\n",
            "47/47 [==============================] - 3s 65ms/step - loss: 8.9091e-04 - mae: 0.0198 - mse: 8.9091e-04 - val_loss: 0.0014 - val_mae: 0.0286 - val_mse: 0.0014\n",
            "Epoch 9/50\n",
            "47/47 [==============================] - 3s 66ms/step - loss: 7.3084e-04 - mae: 0.0175 - mse: 7.3084e-04 - val_loss: 0.0010 - val_mae: 0.0237 - val_mse: 0.0010\n",
            "Epoch 10/50\n",
            "47/47 [==============================] - 5s 102ms/step - loss: 9.1820e-04 - mae: 0.0198 - mse: 9.1820e-04 - val_loss: 6.6762e-04 - val_mae: 0.0178 - val_mse: 6.6762e-04\n",
            "Epoch 11/50\n",
            "47/47 [==============================] - 4s 74ms/step - loss: 8.1191e-04 - mae: 0.0177 - mse: 8.1191e-04 - val_loss: 0.0027 - val_mae: 0.0436 - val_mse: 0.0027\n",
            "Epoch 12/50\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 6.9914e-04 - mae: 0.0165 - mse: 6.9914e-04 - val_loss: 0.0018 - val_mae: 0.0352 - val_mse: 0.0018\n",
            "Epoch 13/50\n",
            "47/47 [==============================] - 3s 72ms/step - loss: 6.0514e-04 - mae: 0.0153 - mse: 6.0514e-04 - val_loss: 7.3988e-04 - val_mae: 0.0200 - val_mse: 7.3988e-04\n",
            "Epoch 14/50\n",
            "47/47 [==============================] - 5s 114ms/step - loss: 6.2242e-04 - mae: 0.0151 - mse: 6.2242e-04 - val_loss: 5.7011e-04 - val_mae: 0.0169 - val_mse: 5.7011e-04\n",
            "Epoch 15/50\n",
            "47/47 [==============================] - 3s 68ms/step - loss: 5.7702e-04 - mae: 0.0146 - mse: 5.7702e-04 - val_loss: 6.5068e-04 - val_mae: 0.0188 - val_mse: 6.5068e-04\n",
            "Epoch 16/50\n",
            "47/47 [==============================] - 3s 71ms/step - loss: 5.7524e-04 - mae: 0.0155 - mse: 5.7524e-04 - val_loss: 9.2082e-04 - val_mae: 0.0226 - val_mse: 9.2082e-04\n",
            "Epoch 17/50\n",
            "47/47 [==============================] - 3s 68ms/step - loss: 5.5585e-04 - mae: 0.0147 - mse: 5.5585e-04 - val_loss: 5.1049e-04 - val_mae: 0.0156 - val_mse: 5.1049e-04\n",
            "Epoch 18/50\n",
            "47/47 [==============================] - 5s 114ms/step - loss: 6.9095e-04 - mae: 0.0167 - mse: 6.9095e-04 - val_loss: 6.8428e-04 - val_mae: 0.0189 - val_mse: 6.8428e-04\n",
            "Epoch 19/50\n",
            "47/47 [==============================] - 3s 66ms/step - loss: 5.6333e-04 - mae: 0.0144 - mse: 5.6333e-04 - val_loss: 7.4132e-04 - val_mae: 0.0200 - val_mse: 7.4132e-04\n",
            "Epoch 20/50\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 5.8860e-04 - mae: 0.0147 - mse: 5.8860e-04 - val_loss: 0.0019 - val_mae: 0.0373 - val_mse: 0.0019\n",
            "Epoch 21/50\n",
            "47/47 [==============================] - 3s 72ms/step - loss: 5.9109e-04 - mae: 0.0151 - mse: 5.9109e-04 - val_loss: 7.5153e-04 - val_mae: 0.0207 - val_mse: 7.5153e-04\n",
            "Epoch 22/50\n",
            "47/47 [==============================] - 5s 110ms/step - loss: 5.1884e-04 - mae: 0.0138 - mse: 5.1884e-04 - val_loss: 6.7774e-04 - val_mae: 0.0197 - val_mse: 6.7774e-04\n",
            "Epoch 23/50\n",
            "47/47 [==============================] - 3s 66ms/step - loss: 5.8471e-04 - mae: 0.0150 - mse: 5.8471e-04 - val_loss: 6.9229e-04 - val_mae: 0.0196 - val_mse: 6.9229e-04\n",
            "Epoch 24/50\n",
            "47/47 [==============================] - 3s 66ms/step - loss: 4.8722e-04 - mae: 0.0135 - mse: 4.8722e-04 - val_loss: 4.4866e-04 - val_mae: 0.0146 - val_mse: 4.4866e-04\n",
            "Epoch 25/50\n",
            "47/47 [==============================] - 3s 68ms/step - loss: 5.8165e-04 - mae: 0.0152 - mse: 5.8165e-04 - val_loss: 6.0067e-04 - val_mae: 0.0183 - val_mse: 6.0067e-04\n",
            "Epoch 26/50\n",
            "47/47 [==============================] - 6s 126ms/step - loss: 5.0841e-04 - mae: 0.0136 - mse: 5.0841e-04 - val_loss: 8.2798e-04 - val_mae: 0.0228 - val_mse: 8.2798e-04\n",
            "Epoch 27/50\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 5.3057e-04 - mae: 0.0140 - mse: 5.3057e-04 - val_loss: 7.7007e-04 - val_mae: 0.0206 - val_mse: 7.7007e-04\n",
            "Epoch 28/50\n",
            "47/47 [==============================] - 3s 68ms/step - loss: 5.0140e-04 - mae: 0.0140 - mse: 5.0140e-04 - val_loss: 0.0011 - val_mae: 0.0270 - val_mse: 0.0011\n",
            "Epoch 29/50\n",
            "47/47 [==============================] - 4s 84ms/step - loss: 4.6745e-04 - mae: 0.0134 - mse: 4.6745e-04 - val_loss: 0.0014 - val_mae: 0.0309 - val_mse: 0.0014\n",
            "Epoch 30/50\n",
            "47/47 [==============================] - 4s 94ms/step - loss: 4.8451e-04 - mae: 0.0145 - mse: 4.8451e-04 - val_loss: 7.9299e-04 - val_mae: 0.0223 - val_mse: 7.9299e-04\n",
            "Epoch 31/50\n",
            "47/47 [==============================] - 3s 68ms/step - loss: 4.3922e-04 - mae: 0.0125 - mse: 4.3922e-04 - val_loss: 4.4112e-04 - val_mae: 0.0149 - val_mse: 4.4112e-04\n",
            "Epoch 32/50\n",
            "47/47 [==============================] - 3s 68ms/step - loss: 5.2116e-04 - mae: 0.0148 - mse: 5.2116e-04 - val_loss: 4.6929e-04 - val_mae: 0.0161 - val_mse: 4.6929e-04\n",
            "Epoch 33/50\n",
            "47/47 [==============================] - 4s 84ms/step - loss: 5.0845e-04 - mae: 0.0145 - mse: 5.0845e-04 - val_loss: 7.4840e-04 - val_mae: 0.0210 - val_mse: 7.4840e-04\n",
            "Epoch 34/50\n",
            "47/47 [==============================] - 4s 88ms/step - loss: 5.8057e-04 - mae: 0.0145 - mse: 5.8057e-04 - val_loss: 7.7092e-04 - val_mae: 0.0212 - val_mse: 7.7092e-04\n",
            "Epoch 35/50\n",
            "47/47 [==============================] - 3s 67ms/step - loss: 5.1380e-04 - mae: 0.0139 - mse: 5.1380e-04 - val_loss: 7.6105e-04 - val_mae: 0.0211 - val_mse: 7.6105e-04\n",
            "Epoch 36/50\n",
            "47/47 [==============================] - 3s 65ms/step - loss: 5.1495e-04 - mae: 0.0142 - mse: 5.1495e-04 - val_loss: 4.6787e-04 - val_mae: 0.0153 - val_mse: 4.6787e-04\n",
            "Epoch 37/50\n",
            "47/47 [==============================] - 4s 78ms/step - loss: 4.4493e-04 - mae: 0.0123 - mse: 4.4493e-04 - val_loss: 5.6663e-04 - val_mae: 0.0176 - val_mse: 5.6663e-04\n",
            "Epoch 38/50\n",
            "47/47 [==============================] - 4s 94ms/step - loss: 5.4709e-04 - mae: 0.0150 - mse: 5.4709e-04 - val_loss: 5.7499e-04 - val_mae: 0.0181 - val_mse: 5.7499e-04\n",
            "Epoch 39/50\n",
            "47/47 [==============================] - 3s 68ms/step - loss: 4.4764e-04 - mae: 0.0127 - mse: 4.4764e-04 - val_loss: 4.6973e-04 - val_mae: 0.0154 - val_mse: 4.6973e-04\n",
            "Epoch 40/50\n",
            "47/47 [==============================] - 3s 65ms/step - loss: 4.4832e-04 - mae: 0.0125 - mse: 4.4832e-04 - val_loss: 3.8443e-04 - val_mae: 0.0139 - val_mse: 3.8443e-04\n",
            "Epoch 41/50\n",
            "47/47 [==============================] - 4s 76ms/step - loss: 5.8349e-04 - mae: 0.0151 - mse: 5.8349e-04 - val_loss: 8.4262e-04 - val_mae: 0.0228 - val_mse: 8.4262e-04\n",
            "Epoch 42/50\n",
            "47/47 [==============================] - 4s 94ms/step - loss: 4.6339e-04 - mae: 0.0125 - mse: 4.6339e-04 - val_loss: 4.2579e-04 - val_mae: 0.0147 - val_mse: 4.2579e-04\n",
            "Epoch 43/50\n",
            "47/47 [==============================] - 3s 65ms/step - loss: 4.3919e-04 - mae: 0.0124 - mse: 4.3919e-04 - val_loss: 3.6071e-04 - val_mae: 0.0130 - val_mse: 3.6071e-04\n",
            "Epoch 44/50\n",
            "47/47 [==============================] - 3s 68ms/step - loss: 4.2300e-04 - mae: 0.0126 - mse: 4.2300e-04 - val_loss: 3.7704e-04 - val_mae: 0.0138 - val_mse: 3.7704e-04\n",
            "Epoch 45/50\n",
            "47/47 [==============================] - 4s 76ms/step - loss: 3.7138e-04 - mae: 0.0115 - mse: 3.7138e-04 - val_loss: 5.4564e-04 - val_mae: 0.0172 - val_mse: 5.4564e-04\n",
            "Epoch 46/50\n",
            "47/47 [==============================] - 5s 99ms/step - loss: 3.8429e-04 - mae: 0.0116 - mse: 3.8429e-04 - val_loss: 4.5878e-04 - val_mae: 0.0159 - val_mse: 4.5878e-04\n",
            "Epoch 47/50\n",
            "47/47 [==============================] - 3s 68ms/step - loss: 4.6418e-04 - mae: 0.0133 - mse: 4.6418e-04 - val_loss: 3.9403e-04 - val_mae: 0.0138 - val_mse: 3.9403e-04\n",
            "Epoch 48/50\n",
            "47/47 [==============================] - 3s 68ms/step - loss: 3.7189e-04 - mae: 0.0115 - mse: 3.7189e-04 - val_loss: 3.4516e-04 - val_mae: 0.0127 - val_mse: 3.4516e-04\n",
            "Epoch 49/50\n",
            "47/47 [==============================] - 4s 80ms/step - loss: 4.0153e-04 - mae: 0.0124 - mse: 4.0153e-04 - val_loss: 7.6315e-04 - val_mae: 0.0222 - val_mse: 7.6315e-04\n",
            "Epoch 50/50\n",
            "47/47 [==============================] - 4s 91ms/step - loss: 4.3700e-04 - mae: 0.0123 - mse: 4.3700e-04 - val_loss: 4.9489e-04 - val_mae: 0.0162 - val_mse: 4.9489e-04\n",
            "15/15 [==============================] - 0s 21ms/step - loss: 3.6914e-04 - mae: 0.0149 - mse: 3.6914e-04\n",
            "Test Loss: 0.0003691406163852662\n",
            "Test MAE: 0.014907455071806908\n",
            "Test MSE: 0.0003691406163852662\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zero_model_performance=[0,0,0]\n",
        "zero_model_performance[0],zero_model_performance[1],zero_model_performance[2]=base_model.evaluate(X_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thtfyYtBX3jK",
        "outputId": "95df70f3-3536-4ed8-f07b-98ad92f44464"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 1s 49ms/step - loss: 3.6914e-04 - mae: 0.0149 - mse: 3.6914e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_scaler=scalers[3]"
      ],
      "metadata": {
        "id": "qfNIQ3TdjOpg"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "predictions = base_model.predict(X_test)\n",
        "\n",
        "predictions = y_scaler.inverse_transform(predictions)\n",
        "real_y=y_scaler.inverse_transform(y_test)\n",
        "\n",
        "# Plot the real values and predictions\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(real_y, label='Real Values')\n",
        "plt.plot(predictions, label='Predictions')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Value')\n",
        "plt.title('Real Values vs Predictions')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "HCCueBA0poxL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "outputId": "b0807c08-384d-40b6-a12d-c2f69cb9c41b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 1s 22ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.BTC + co-currencies\n",
        "\n",
        "Najpierw Stworzymy model rozszerzony który zawiera Open,High,Low prices.\n",
        "\n",
        "Potem model tylko na podstawie Close price.\n",
        "\n",
        "Ocenimy czy takie dodatkowe cechy faktycznie pomagają w trenowaniu modelu czy tylko niepotrzebnie spowalniają model"
      ],
      "metadata": {
        "id": "0eILamTm7sXa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "co_currencies_extended_indexes=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,49]"
      ],
      "metadata": {
        "id": "HnMm12sm8OG0"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reshaped_data_X, reshaped_data_y=reshape_data_mlt_feature_changer(DATA,n_timesteps,co_currencies_extended_indexes)"
      ],
      "metadata": {
        "id": "DZBBMK9U9sm-"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Assuming you have reshaped_data_X and reshaped_data_y from the previous function\n",
        "#\n",
        "scalers = [MinMaxScaler() for _ in range(DATA.shape[1])]\n",
        "\n",
        "\n",
        "DATA_scaled = np.hstack([scaler.fit_transform(DATA[:, [i]]) for i, scaler in enumerate(scalers)])\n",
        "\n",
        "\n",
        "reshaped_data_X, reshaped_data_y=reshape_data_mlt_feature_changer(DATA_scaled,n_timesteps,co_currencies_extended_indexes)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(reshaped_data_X, reshaped_data_y, test_size=0.2, random_state=42,shuffle=False)\n",
        "#\n",
        "# Define the LSTM model\n",
        "co_cur_ext_model = Sequential()\n",
        "co_cur_ext_model.add(LSTM(128, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True))\n",
        "co_cur_ext_model.add(Dropout(0.2))\n",
        "co_cur_ext_model.add(LSTM(64, return_sequences=False))\n",
        "co_cur_ext_model.add(Dense(1))\n",
        "\n",
        "# Compile the co_cur_ext_model\n",
        "optimizer = Adam(lr=0.001)\n",
        "co_cur_ext_model.compile(optimizer=optimizer, loss='mse', metrics=['mae', 'mse'])\n",
        "\n",
        "# Train the co_cur_ext_model\n",
        "history = co_cur_ext_model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluate the co_cur_ext_model on the testing data\n",
        "loss, mae, mse = co_cur_ext_model.evaluate(X_test, y_test)\n",
        "print(\"Test Loss:\", loss)\n",
        "print(\"Test MAE:\", mae)\n",
        "print(\"Test MSE:\", mse)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qm1cx6jZ90ky",
        "outputId": "498c5b56-af1f-4dbe-96d0-bdab4b23c291"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "47/47 [==============================] - 10s 100ms/step - loss: 0.0059 - mae: 0.0465 - mse: 0.0059 - val_loss: 0.0190 - val_mae: 0.1313 - val_mse: 0.0190\n",
            "Epoch 2/50\n",
            "47/47 [==============================] - 3s 67ms/step - loss: 0.0013 - mae: 0.0236 - mse: 0.0013 - val_loss: 0.0130 - val_mae: 0.1074 - val_mse: 0.0130\n",
            "Epoch 3/50\n",
            "47/47 [==============================] - 5s 114ms/step - loss: 0.0012 - mae: 0.0228 - mse: 0.0012 - val_loss: 0.0048 - val_mae: 0.0618 - val_mse: 0.0048\n",
            "Epoch 4/50\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 9.6321e-04 - mae: 0.0205 - mse: 9.6321e-04 - val_loss: 0.0092 - val_mae: 0.0907 - val_mse: 0.0092\n",
            "Epoch 5/50\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 9.3587e-04 - mae: 0.0199 - mse: 9.3587e-04 - val_loss: 0.0026 - val_mae: 0.0440 - val_mse: 0.0026\n",
            "Epoch 6/50\n",
            "47/47 [==============================] - 3s 67ms/step - loss: 9.6130e-04 - mae: 0.0211 - mse: 9.6130e-04 - val_loss: 0.0084 - val_mae: 0.0868 - val_mse: 0.0084\n",
            "Epoch 7/50\n",
            "47/47 [==============================] - 5s 104ms/step - loss: 0.0011 - mae: 0.0230 - mse: 0.0011 - val_loss: 0.0049 - val_mae: 0.0647 - val_mse: 0.0049\n",
            "Epoch 8/50\n",
            "47/47 [==============================] - 3s 72ms/step - loss: 9.0366e-04 - mae: 0.0204 - mse: 9.0366e-04 - val_loss: 0.0029 - val_mae: 0.0478 - val_mse: 0.0029\n",
            "Epoch 9/50\n",
            "47/47 [==============================] - 3s 67ms/step - loss: 9.6033e-04 - mae: 0.0203 - mse: 9.6033e-04 - val_loss: 0.0059 - val_mae: 0.0720 - val_mse: 0.0059\n",
            "Epoch 10/50\n",
            "47/47 [==============================] - 3s 67ms/step - loss: 8.0648e-04 - mae: 0.0181 - mse: 8.0648e-04 - val_loss: 0.0038 - val_mae: 0.0560 - val_mse: 0.0038\n",
            "Epoch 11/50\n",
            "47/47 [==============================] - 5s 101ms/step - loss: 9.0759e-04 - mae: 0.0192 - mse: 9.0759e-04 - val_loss: 0.0050 - val_mae: 0.0659 - val_mse: 0.0050\n",
            "Epoch 12/50\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 7.8446e-04 - mae: 0.0177 - mse: 7.8446e-04 - val_loss: 0.0039 - val_mae: 0.0575 - val_mse: 0.0039\n",
            "Epoch 13/50\n",
            "47/47 [==============================] - 3s 68ms/step - loss: 7.3946e-04 - mae: 0.0178 - mse: 7.3946e-04 - val_loss: 0.0037 - val_mae: 0.0563 - val_mse: 0.0037\n",
            "Epoch 14/50\n",
            "47/47 [==============================] - 3s 67ms/step - loss: 7.0583e-04 - mae: 0.0176 - mse: 7.0583e-04 - val_loss: 0.0028 - val_mae: 0.0477 - val_mse: 0.0028\n",
            "Epoch 15/50\n",
            "47/47 [==============================] - 5s 107ms/step - loss: 6.2172e-04 - mae: 0.0155 - mse: 6.2172e-04 - val_loss: 0.0084 - val_mae: 0.0882 - val_mse: 0.0084\n",
            "Epoch 16/50\n",
            "47/47 [==============================] - 3s 66ms/step - loss: 7.3271e-04 - mae: 0.0178 - mse: 7.3271e-04 - val_loss: 0.0026 - val_mae: 0.0457 - val_mse: 0.0026\n",
            "Epoch 17/50\n",
            "47/47 [==============================] - 3s 66ms/step - loss: 6.1708e-04 - mae: 0.0165 - mse: 6.1708e-04 - val_loss: 0.0057 - val_mae: 0.0719 - val_mse: 0.0057\n",
            "Epoch 18/50\n",
            "47/47 [==============================] - 3s 66ms/step - loss: 5.6873e-04 - mae: 0.0154 - mse: 5.6873e-04 - val_loss: 0.0030 - val_mae: 0.0496 - val_mse: 0.0030\n",
            "Epoch 19/50\n",
            "47/47 [==============================] - 5s 104ms/step - loss: 6.2758e-04 - mae: 0.0160 - mse: 6.2758e-04 - val_loss: 0.0027 - val_mae: 0.0472 - val_mse: 0.0027\n",
            "Epoch 20/50\n",
            "47/47 [==============================] - 3s 72ms/step - loss: 5.0737e-04 - mae: 0.0144 - mse: 5.0737e-04 - val_loss: 0.0046 - val_mae: 0.0634 - val_mse: 0.0046\n",
            "Epoch 21/50\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 5.8698e-04 - mae: 0.0154 - mse: 5.8698e-04 - val_loss: 0.0017 - val_mae: 0.0361 - val_mse: 0.0017\n",
            "Epoch 22/50\n",
            "47/47 [==============================] - 3s 66ms/step - loss: 5.5200e-04 - mae: 0.0148 - mse: 5.5200e-04 - val_loss: 0.0022 - val_mae: 0.0425 - val_mse: 0.0022\n",
            "Epoch 23/50\n",
            "47/47 [==============================] - 5s 113ms/step - loss: 5.4735e-04 - mae: 0.0147 - mse: 5.4735e-04 - val_loss: 0.0035 - val_mae: 0.0550 - val_mse: 0.0035\n",
            "Epoch 24/50\n",
            "47/47 [==============================] - 3s 67ms/step - loss: 5.4180e-04 - mae: 0.0149 - mse: 5.4180e-04 - val_loss: 0.0032 - val_mae: 0.0515 - val_mse: 0.0032\n",
            "Epoch 25/50\n",
            "47/47 [==============================] - 3s 66ms/step - loss: 5.3490e-04 - mae: 0.0147 - mse: 5.3490e-04 - val_loss: 0.0027 - val_mae: 0.0468 - val_mse: 0.0027\n",
            "Epoch 26/50\n",
            "47/47 [==============================] - 3s 67ms/step - loss: 5.1546e-04 - mae: 0.0142 - mse: 5.1546e-04 - val_loss: 0.0047 - val_mae: 0.0649 - val_mse: 0.0047\n",
            "Epoch 27/50\n",
            "47/47 [==============================] - 5s 108ms/step - loss: 5.2617e-04 - mae: 0.0146 - mse: 5.2617e-04 - val_loss: 0.0047 - val_mae: 0.0649 - val_mse: 0.0047\n",
            "Epoch 28/50\n",
            "47/47 [==============================] - 3s 66ms/step - loss: 5.7947e-04 - mae: 0.0145 - mse: 5.7947e-04 - val_loss: 0.0035 - val_mae: 0.0547 - val_mse: 0.0035\n",
            "Epoch 29/50\n",
            "47/47 [==============================] - 3s 67ms/step - loss: 4.9055e-04 - mae: 0.0136 - mse: 4.9055e-04 - val_loss: 0.0027 - val_mae: 0.0471 - val_mse: 0.0027\n",
            "Epoch 30/50\n",
            "47/47 [==============================] - 3s 71ms/step - loss: 5.8842e-04 - mae: 0.0163 - mse: 5.8842e-04 - val_loss: 0.0051 - val_mae: 0.0679 - val_mse: 0.0051\n",
            "Epoch 31/50\n",
            "47/47 [==============================] - 5s 110ms/step - loss: 4.5937e-04 - mae: 0.0131 - mse: 4.5937e-04 - val_loss: 0.0033 - val_mae: 0.0533 - val_mse: 0.0033\n",
            "Epoch 32/50\n",
            "47/47 [==============================] - 3s 64ms/step - loss: 4.4056e-04 - mae: 0.0128 - mse: 4.4056e-04 - val_loss: 0.0015 - val_mae: 0.0342 - val_mse: 0.0015\n",
            "Epoch 33/50\n",
            "47/47 [==============================] - 3s 67ms/step - loss: 4.3778e-04 - mae: 0.0131 - mse: 4.3778e-04 - val_loss: 0.0034 - val_mae: 0.0545 - val_mse: 0.0034\n",
            "Epoch 34/50\n",
            "47/47 [==============================] - 3s 68ms/step - loss: 5.4614e-04 - mae: 0.0149 - mse: 5.4614e-04 - val_loss: 0.0018 - val_mae: 0.0365 - val_mse: 0.0018\n",
            "Epoch 35/50\n",
            "47/47 [==============================] - 5s 107ms/step - loss: 4.8682e-04 - mae: 0.0135 - mse: 4.8682e-04 - val_loss: 0.0043 - val_mae: 0.0618 - val_mse: 0.0043\n",
            "Epoch 36/50\n",
            "47/47 [==============================] - 3s 65ms/step - loss: 4.6584e-04 - mae: 0.0132 - mse: 4.6584e-04 - val_loss: 0.0017 - val_mae: 0.0372 - val_mse: 0.0017\n",
            "Epoch 37/50\n",
            "47/47 [==============================] - 3s 68ms/step - loss: 4.5959e-04 - mae: 0.0135 - mse: 4.5959e-04 - val_loss: 0.0022 - val_mae: 0.0417 - val_mse: 0.0022\n",
            "Epoch 38/50\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 3.9111e-04 - mae: 0.0125 - mse: 3.9111e-04 - val_loss: 0.0016 - val_mae: 0.0346 - val_mse: 0.0016\n",
            "Epoch 39/50\n",
            "47/47 [==============================] - 5s 108ms/step - loss: 5.3225e-04 - mae: 0.0145 - mse: 5.3225e-04 - val_loss: 0.0016 - val_mae: 0.0357 - val_mse: 0.0016\n",
            "Epoch 40/50\n",
            "47/47 [==============================] - 3s 68ms/step - loss: 4.7520e-04 - mae: 0.0135 - mse: 4.7520e-04 - val_loss: 0.0015 - val_mae: 0.0342 - val_mse: 0.0015\n",
            "Epoch 41/50\n",
            "47/47 [==============================] - 3s 65ms/step - loss: 4.7158e-04 - mae: 0.0137 - mse: 4.7158e-04 - val_loss: 0.0041 - val_mae: 0.0606 - val_mse: 0.0041\n",
            "Epoch 42/50\n",
            "47/47 [==============================] - 3s 67ms/step - loss: 4.6099e-04 - mae: 0.0126 - mse: 4.6099e-04 - val_loss: 0.0020 - val_mae: 0.0407 - val_mse: 0.0020\n",
            "Epoch 43/50\n",
            "47/47 [==============================] - 5s 112ms/step - loss: 4.1364e-04 - mae: 0.0127 - mse: 4.1364e-04 - val_loss: 0.0037 - val_mae: 0.0569 - val_mse: 0.0037\n",
            "Epoch 44/50\n",
            "47/47 [==============================] - 3s 66ms/step - loss: 4.1539e-04 - mae: 0.0123 - mse: 4.1539e-04 - val_loss: 0.0024 - val_mae: 0.0440 - val_mse: 0.0024\n",
            "Epoch 45/50\n",
            "47/47 [==============================] - 3s 66ms/step - loss: 4.3709e-04 - mae: 0.0129 - mse: 4.3709e-04 - val_loss: 0.0024 - val_mae: 0.0450 - val_mse: 0.0024\n",
            "Epoch 46/50\n",
            "47/47 [==============================] - 3s 68ms/step - loss: 3.6205e-04 - mae: 0.0121 - mse: 3.6205e-04 - val_loss: 0.0032 - val_mae: 0.0534 - val_mse: 0.0032\n",
            "Epoch 47/50\n",
            "47/47 [==============================] - 5s 115ms/step - loss: 3.9765e-04 - mae: 0.0121 - mse: 3.9765e-04 - val_loss: 0.0017 - val_mae: 0.0368 - val_mse: 0.0017\n",
            "Epoch 48/50\n",
            "47/47 [==============================] - 3s 66ms/step - loss: 4.5593e-04 - mae: 0.0132 - mse: 4.5593e-04 - val_loss: 0.0067 - val_mae: 0.0790 - val_mse: 0.0067\n",
            "Epoch 49/50\n",
            "47/47 [==============================] - 3s 65ms/step - loss: 4.5499e-04 - mae: 0.0129 - mse: 4.5499e-04 - val_loss: 0.0023 - val_mae: 0.0443 - val_mse: 0.0023\n",
            "Epoch 50/50\n",
            "47/47 [==============================] - 3s 65ms/step - loss: 4.2875e-04 - mae: 0.0122 - mse: 4.2875e-04 - val_loss: 0.0017 - val_mae: 0.0362 - val_mse: 0.0017\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 0.0016 - mae: 0.0363 - mse: 0.0016\n",
            "Test Loss: 0.001625190139748156\n",
            "Test MAE: 0.0362958163022995\n",
            "Test MSE: 0.001625190139748156\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "co_cur_ext_model.evaluate(X_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGf6CuYmiMIH",
        "outputId": "e7e8bcf7-71d2-4c13-b986-60227a032494"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 1s 38ms/step - loss: 0.0016 - mae: 0.0363 - mse: 0.0016\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.001625190139748156, 0.0362958163022995, 0.001625190139748156]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "co_currenceis_simplified_indexes=[0,1,2,3,7,11,15,19,23,49]"
      ],
      "metadata": {
        "id": "SCwj0GKc8oh5"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Assuming you have reshaped_data_X and reshaped_data_y from the previous function\n",
        "\n",
        "scalers = [MinMaxScaler() for _ in range(DATA.shape[1])]\n",
        "\n",
        "\n",
        "DATA_scaled = np.hstack([scaler.fit_transform(DATA[:, [i]]) for i, scaler in enumerate(scalers)])\n",
        "\n",
        "\n",
        "reshaped_data_X, reshaped_data_y=reshape_data_mlt_feature_changer(DATA_scaled,n_timesteps,co_currenceis_simplified_indexes)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(reshaped_data_X, reshaped_data_y, test_size=0.2, random_state=42,shuffle=False)\n",
        "\n",
        "# Define the LSTM model\n",
        "co_cur_simp_model = Sequential()\n",
        "co_cur_simp_model.add(LSTM(128, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True))\n",
        "co_cur_simp_model.add(Dropout(0.2))\n",
        "co_cur_simp_model.add(LSTM(64, return_sequences=False))\n",
        "co_cur_simp_model.add(Dense(1))\n",
        "\n",
        "# Compile the co_cur_simp_model\n",
        "optimizer = Adam(lr=0.001)\n",
        "co_cur_simp_model.compile(optimizer=optimizer, loss='mae', metrics=['mae', 'mse'])\n",
        "\n",
        "# Train the co_cur_simp_model\n",
        "history = co_cur_simp_model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluate the co_cur_simp_model on the testing data\n",
        "loss, mae, mse = co_cur_simp_model.evaluate(X_test, y_test)\n",
        "print(\"Test Loss:\", loss)\n",
        "print(\"Test MAE:\", mae)\n",
        "print(\"Test MSE:\", mse)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4-zRmy9_QBf",
        "outputId": "1446d503-4bd5-4d5e-d637-8f4a6fa0ffb9"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "47/47 [==============================] - 9s 91ms/step - loss: 0.0486 - mae: 0.0486 - mse: 0.0066 - val_loss: 0.0617 - val_mae: 0.0617 - val_mse: 0.0046\n",
            "Epoch 2/50\n",
            "47/47 [==============================] - 3s 66ms/step - loss: 0.0224 - mae: 0.0224 - mse: 0.0014 - val_loss: 0.0390 - val_mae: 0.0390 - val_mse: 0.0020\n",
            "Epoch 3/50\n",
            "47/47 [==============================] - 5s 107ms/step - loss: 0.0192 - mae: 0.0192 - mse: 9.7528e-04 - val_loss: 0.0521 - val_mae: 0.0521 - val_mse: 0.0034\n",
            "Epoch 4/50\n",
            "47/47 [==============================] - 3s 63ms/step - loss: 0.0181 - mae: 0.0181 - mse: 8.8206e-04 - val_loss: 0.0487 - val_mae: 0.0487 - val_mse: 0.0030\n",
            "Epoch 5/50\n",
            "47/47 [==============================] - 3s 67ms/step - loss: 0.0172 - mae: 0.0172 - mse: 7.6312e-04 - val_loss: 0.0374 - val_mae: 0.0374 - val_mse: 0.0019\n",
            "Epoch 6/50\n",
            "47/47 [==============================] - 3s 64ms/step - loss: 0.0181 - mae: 0.0181 - mse: 8.1678e-04 - val_loss: 0.0460 - val_mae: 0.0460 - val_mse: 0.0027\n",
            "Epoch 7/50\n",
            "47/47 [==============================] - 5s 108ms/step - loss: 0.0168 - mae: 0.0168 - mse: 7.4533e-04 - val_loss: 0.0326 - val_mae: 0.0326 - val_mse: 0.0015\n",
            "Epoch 8/50\n",
            "47/47 [==============================] - 3s 66ms/step - loss: 0.0173 - mae: 0.0173 - mse: 7.5324e-04 - val_loss: 0.0197 - val_mae: 0.0197 - val_mse: 6.6472e-04\n",
            "Epoch 9/50\n",
            "47/47 [==============================] - 3s 63ms/step - loss: 0.0162 - mae: 0.0162 - mse: 7.0876e-04 - val_loss: 0.0345 - val_mae: 0.0345 - val_mse: 0.0016\n",
            "Epoch 10/50\n",
            "47/47 [==============================] - 3s 66ms/step - loss: 0.0151 - mae: 0.0151 - mse: 6.0383e-04 - val_loss: 0.0267 - val_mae: 0.0267 - val_mse: 0.0010\n",
            "Epoch 11/50\n",
            "47/47 [==============================] - 5s 107ms/step - loss: 0.0154 - mae: 0.0154 - mse: 6.2663e-04 - val_loss: 0.0484 - val_mae: 0.0484 - val_mse: 0.0028\n",
            "Epoch 12/50\n",
            "47/47 [==============================] - 3s 66ms/step - loss: 0.0148 - mae: 0.0148 - mse: 5.9440e-04 - val_loss: 0.0396 - val_mae: 0.0396 - val_mse: 0.0020\n",
            "Epoch 13/50\n",
            "47/47 [==============================] - 3s 65ms/step - loss: 0.0149 - mae: 0.0149 - mse: 5.6319e-04 - val_loss: 0.0174 - val_mae: 0.0174 - val_mse: 5.3400e-04\n",
            "Epoch 14/50\n",
            "47/47 [==============================] - 3s 65ms/step - loss: 0.0152 - mae: 0.0152 - mse: 6.0766e-04 - val_loss: 0.0179 - val_mae: 0.0179 - val_mse: 6.1262e-04\n",
            "Epoch 15/50\n",
            "47/47 [==============================] - 5s 97ms/step - loss: 0.0165 - mae: 0.0165 - mse: 8.0156e-04 - val_loss: 0.0317 - val_mae: 0.0317 - val_mse: 0.0013\n",
            "Epoch 16/50\n",
            "47/47 [==============================] - 3s 72ms/step - loss: 0.0137 - mae: 0.0137 - mse: 5.5068e-04 - val_loss: 0.0224 - val_mae: 0.0224 - val_mse: 7.5552e-04\n",
            "Epoch 17/50\n",
            "47/47 [==============================] - 3s 64ms/step - loss: 0.0128 - mae: 0.0128 - mse: 4.7128e-04 - val_loss: 0.0382 - val_mae: 0.0382 - val_mse: 0.0018\n",
            "Epoch 18/50\n",
            "47/47 [==============================] - 3s 64ms/step - loss: 0.0132 - mae: 0.0132 - mse: 4.6464e-04 - val_loss: 0.0374 - val_mae: 0.0374 - val_mse: 0.0018\n",
            "Epoch 19/50\n",
            "47/47 [==============================] - 5s 97ms/step - loss: 0.0135 - mae: 0.0135 - mse: 5.1094e-04 - val_loss: 0.0245 - val_mae: 0.0245 - val_mse: 8.6989e-04\n",
            "Epoch 20/50\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 0.0137 - mae: 0.0137 - mse: 5.3239e-04 - val_loss: 0.0388 - val_mae: 0.0388 - val_mse: 0.0019\n",
            "Epoch 21/50\n",
            "47/47 [==============================] - 3s 65ms/step - loss: 0.0135 - mae: 0.0135 - mse: 5.0434e-04 - val_loss: 0.0161 - val_mae: 0.0161 - val_mse: 4.5347e-04\n",
            "Epoch 22/50\n",
            "47/47 [==============================] - 3s 65ms/step - loss: 0.0123 - mae: 0.0123 - mse: 4.5952e-04 - val_loss: 0.0147 - val_mae: 0.0147 - val_mse: 4.2745e-04\n",
            "Epoch 23/50\n",
            "47/47 [==============================] - 4s 93ms/step - loss: 0.0138 - mae: 0.0138 - mse: 5.3937e-04 - val_loss: 0.0247 - val_mae: 0.0247 - val_mse: 8.6416e-04\n",
            "Epoch 24/50\n",
            "47/47 [==============================] - 4s 76ms/step - loss: 0.0128 - mae: 0.0128 - mse: 4.4156e-04 - val_loss: 0.0204 - val_mae: 0.0204 - val_mse: 6.6106e-04\n",
            "Epoch 25/50\n",
            "47/47 [==============================] - 3s 66ms/step - loss: 0.0153 - mae: 0.0153 - mse: 6.1763e-04 - val_loss: 0.0276 - val_mae: 0.0276 - val_mse: 0.0010\n",
            "Epoch 26/50\n",
            "47/47 [==============================] - 3s 65ms/step - loss: 0.0133 - mae: 0.0133 - mse: 5.1767e-04 - val_loss: 0.0305 - val_mae: 0.0305 - val_mse: 0.0012\n",
            "Epoch 27/50\n",
            "47/47 [==============================] - 4s 90ms/step - loss: 0.0131 - mae: 0.0131 - mse: 4.6033e-04 - val_loss: 0.0201 - val_mae: 0.0201 - val_mse: 6.0046e-04\n",
            "Epoch 28/50\n",
            "47/47 [==============================] - 4s 79ms/step - loss: 0.0128 - mae: 0.0128 - mse: 4.7232e-04 - val_loss: 0.0296 - val_mae: 0.0296 - val_mse: 0.0012\n",
            "Epoch 29/50\n",
            "47/47 [==============================] - 3s 67ms/step - loss: 0.0122 - mae: 0.0122 - mse: 4.5398e-04 - val_loss: 0.0198 - val_mae: 0.0198 - val_mse: 5.7866e-04\n",
            "Epoch 30/50\n",
            "47/47 [==============================] - 3s 66ms/step - loss: 0.0129 - mae: 0.0129 - mse: 4.7542e-04 - val_loss: 0.0162 - val_mae: 0.0162 - val_mse: 4.2433e-04\n",
            "Epoch 31/50\n",
            "47/47 [==============================] - 4s 85ms/step - loss: 0.0138 - mae: 0.0138 - mse: 5.1942e-04 - val_loss: 0.0170 - val_mae: 0.0170 - val_mse: 4.6766e-04\n",
            "Epoch 32/50\n",
            "47/47 [==============================] - 4s 83ms/step - loss: 0.0121 - mae: 0.0121 - mse: 4.4508e-04 - val_loss: 0.0283 - val_mae: 0.0283 - val_mse: 0.0011\n",
            "Epoch 33/50\n",
            "47/47 [==============================] - 3s 65ms/step - loss: 0.0117 - mae: 0.0117 - mse: 4.1591e-04 - val_loss: 0.0174 - val_mae: 0.0174 - val_mse: 4.8641e-04\n",
            "Epoch 34/50\n",
            "47/47 [==============================] - 3s 66ms/step - loss: 0.0114 - mae: 0.0114 - mse: 3.8147e-04 - val_loss: 0.0173 - val_mae: 0.0173 - val_mse: 4.6315e-04\n",
            "Epoch 35/50\n",
            "47/47 [==============================] - 4s 78ms/step - loss: 0.0119 - mae: 0.0119 - mse: 4.2220e-04 - val_loss: 0.0486 - val_mae: 0.0486 - val_mse: 0.0028\n",
            "Epoch 36/50\n",
            "47/47 [==============================] - 4s 94ms/step - loss: 0.0118 - mae: 0.0118 - mse: 4.0943e-04 - val_loss: 0.0282 - val_mae: 0.0282 - val_mse: 0.0011\n",
            "Epoch 37/50\n",
            "47/47 [==============================] - 3s 66ms/step - loss: 0.0127 - mae: 0.0127 - mse: 4.9300e-04 - val_loss: 0.0213 - val_mae: 0.0213 - val_mse: 6.5695e-04\n",
            "Epoch 38/50\n",
            "47/47 [==============================] - 3s 65ms/step - loss: 0.0118 - mae: 0.0118 - mse: 4.0816e-04 - val_loss: 0.0170 - val_mae: 0.0170 - val_mse: 4.5047e-04\n",
            "Epoch 39/50\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 0.0120 - mae: 0.0120 - mse: 4.5800e-04 - val_loss: 0.0283 - val_mae: 0.0283 - val_mse: 0.0010\n",
            "Epoch 40/50\n",
            "47/47 [==============================] - 4s 95ms/step - loss: 0.0119 - mae: 0.0119 - mse: 4.4632e-04 - val_loss: 0.0249 - val_mae: 0.0249 - val_mse: 8.4480e-04\n",
            "Epoch 41/50\n",
            "47/47 [==============================] - 3s 67ms/step - loss: 0.0114 - mae: 0.0114 - mse: 3.9058e-04 - val_loss: 0.0504 - val_mae: 0.0504 - val_mse: 0.0029\n",
            "Epoch 42/50\n",
            "47/47 [==============================] - 3s 65ms/step - loss: 0.0132 - mae: 0.0132 - mse: 5.1387e-04 - val_loss: 0.0298 - val_mae: 0.0298 - val_mse: 0.0011\n",
            "Epoch 43/50\n",
            "47/47 [==============================] - 3s 74ms/step - loss: 0.0113 - mae: 0.0113 - mse: 3.9478e-04 - val_loss: 0.0166 - val_mae: 0.0166 - val_mse: 4.2853e-04\n",
            "Epoch 44/50\n",
            "47/47 [==============================] - 5s 97ms/step - loss: 0.0119 - mae: 0.0119 - mse: 4.3258e-04 - val_loss: 0.0186 - val_mae: 0.0186 - val_mse: 5.2661e-04\n",
            "Epoch 45/50\n",
            "47/47 [==============================] - 3s 65ms/step - loss: 0.0122 - mae: 0.0122 - mse: 4.2098e-04 - val_loss: 0.0258 - val_mae: 0.0258 - val_mse: 9.2044e-04\n",
            "Epoch 46/50\n",
            "47/47 [==============================] - 3s 65ms/step - loss: 0.0114 - mae: 0.0114 - mse: 4.0122e-04 - val_loss: 0.0273 - val_mae: 0.0273 - val_mse: 9.7781e-04\n",
            "Epoch 47/50\n",
            "47/47 [==============================] - 3s 73ms/step - loss: 0.0113 - mae: 0.0113 - mse: 3.9469e-04 - val_loss: 0.0198 - val_mae: 0.0198 - val_mse: 5.8490e-04\n",
            "Epoch 48/50\n",
            "47/47 [==============================] - 5s 100ms/step - loss: 0.0116 - mae: 0.0116 - mse: 3.9802e-04 - val_loss: 0.0307 - val_mae: 0.0307 - val_mse: 0.0012\n",
            "Epoch 49/50\n",
            "47/47 [==============================] - 3s 66ms/step - loss: 0.0112 - mae: 0.0112 - mse: 3.6837e-04 - val_loss: 0.0152 - val_mae: 0.0152 - val_mse: 3.7326e-04\n",
            "Epoch 50/50\n",
            "47/47 [==============================] - 3s 65ms/step - loss: 0.0124 - mae: 0.0124 - mse: 4.4299e-04 - val_loss: 0.0318 - val_mae: 0.0318 - val_mse: 0.0012\n",
            "15/15 [==============================] - 0s 24ms/step - loss: 0.0306 - mae: 0.0306 - mse: 0.0011\n",
            "Test Loss: 0.030599337071180344\n",
            "Test MAE: 0.030599337071180344\n",
            "Test MSE: 0.0011268524685874581\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "co_cur_simp_model.evaluate(X_test,y_test)"
      ],
      "metadata": {
        "id": "xBVt0yzZRYbR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bd0e6ae-9872-43a2-ebb7-08a312c4d074"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 0s 22ms/step - loss: 0.0306 - mae: 0.0306 - mse: 0.0011\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.030599337071180344, 0.030599337071180344, 0.0011268524685874581]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Różnica między modelami nie jest duża.\n",
        "\n",
        "Model uproszczony wydaje się sprawować nieco lepiej jednak może to wynikać z infrastruktury obu modeli. Mimo że model rozszerzony przyjmuje kilkukrotnie więcej danych, ma on tyle samo neuronów na obliczenia co model podstawowy.\n",
        "\n",
        "Wyszkolenie go zajęło trochę dłużej niż wyszkolenie modelu podstawowego jednak nie jest to duża różnica\n",
        "\n",
        "Nie zważając na niewielka różnice w wynikach, kolejne modele będziemy testować w wersji rozszerzonej. Kiedy rozbudujemy architekturę modelu, wtedy dane z wersji rozszerzonych powinny mieć większy wpływ na wynik."
      ],
      "metadata": {
        "id": "ARY9keebiggy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loop_models_indexes=[[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,49],[0,1,2,3,24,49],[0,1,2,3,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,49],[0,1,2,3,45,49],[0,1,2,3,46,47,48,49]]"
      ],
      "metadata": {
        "id": "ZfpaWiUCRYWD"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loop_models_performance=np.empty((5,3))"
      ],
      "metadata": {
        "id": "9ewi9fYIk3in"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x in range(len(loop_models_indexes)):\n",
        "    indexes=loop_models_indexes[x]\n",
        "\n",
        "    scalers = [MinMaxScaler() for _ in range(DATA.shape[1])]\n",
        "\n",
        "    DATA_scaled = np.hstack([scaler.fit_transform(DATA[:, [i]]) for i, scaler in enumerate(scalers)])\n",
        "\n",
        "    reshaped_data_X, reshaped_data_y=reshape_data_mlt_feature_changer(DATA_scaled,n_timesteps,indexes)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(reshaped_data_X, reshaped_data_y, test_size=0.2, random_state=42,shuffle=False)\n",
        "\n",
        "    loop_model = Sequential()\n",
        "    loop_model.add(LSTM(128, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True))\n",
        "    loop_model.add(Dropout(0.2))\n",
        "    loop_model.add(LSTM(64, return_sequences=False))\n",
        "    loop_model.add(Dense(1))\n",
        "\n",
        "    optimizer = Adam(lr=0.001)\n",
        "    loop_model.compile(optimizer=optimizer, loss='mae', metrics=['mae', 'mse'])\n",
        "\n",
        "    history = loop_model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2,verbose=0)\n",
        "\n",
        "    print(x)\n",
        "    loss,mae,mse=loop_model.evaluate(X_test,y_test)\n",
        "\n",
        "    loop_models_performance[x][0]=loss\n",
        "    loop_models_performance[x][1]=mae\n",
        "    loop_models_performance[x][2]=mse\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNedCbPYlG2k",
        "outputId": "1c514381-ab9e-4f14-9354-7761d9ced936"
      },
      "execution_count": 36,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 0.0303 - mae: 0.0303 - mse: 0.0011\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n",
            "15/15 [==============================] - 0s 24ms/step - loss: 0.0203 - mae: 0.0203 - mse: 5.4877e-04\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "15/15 [==============================] - 0s 24ms/step - loss: 0.0389 - mae: 0.0389 - mse: 0.0021\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "15/15 [==============================] - 0s 21ms/step - loss: 0.0126 - mae: 0.0126 - mse: 4.4193e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n",
            "15/15 [==============================] - 0s 22ms/step - loss: 0.0156 - mae: 0.0156 - mse: 3.7441e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Porównujemy MAE wszystkich modeli"
      ],
      "metadata": {
        "id": "kxLbtQj_2NEJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Base model: {zero_model_performance[1]}\")\n",
        "print(f\"BTC+co-currencies: {loop_models_performance[0][1]}\")\n",
        "print(f\"BTC+API: {loop_models_performance[1][1]}\")\n",
        "print(f\"BTC+world-currencies: {loop_models_performance[2][1]}\")\n",
        "print(f\"BTC+Volume: {loop_models_performance[3][1]}\")\n",
        "print(f\"BTC+Markets: {loop_models_performance[4][1]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGT-XNv10SiF",
        "outputId": "6e334c75-25b0-4cd7-81cc-012d729782d8"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Base model: 0.014907455071806908\n",
            "BTC+co-currencies: 0.03027386963367462\n",
            "BTC+API: 0.02028595469892025\n",
            "BTC+world-currencies: 0.038922782987356186\n",
            "BTC+Volume: 0.01261178683489561\n",
            "BTC+Markets: 0.015608582645654678\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prawie wszystkie modele okazały się lepsze niż base model.\n",
        "Jedynie modele przetwarzające znacznie większa ilość danych spisują się gorzej. Tak jak pisałem wcześniej, może to wynikać z architektury modelu a nie z danych.\n",
        "Sprawdzimy to jeszcze raz podczas trenowania ostatecznego modelu, który będzie bardziej rozbudowany niż modele trenowane przez nas teraz.\n",
        "\n",
        "Z modeli przetwarzającyh mniejszą ilość danych najlepiej spisał się BTC+Markets a najgorzej BTC+Volume. Mimo że model nie jest zły to warto się mu dokładniej przyjrzeć"
      ],
      "metadata": {
        "id": "G4_4ittC1nPC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Porównamy ilość NaN'ów w Volume oraz giełdach, model z giełdami spisał się dobrze mimo że duża część danych to NaN. Czy to znaczy że w Volume NaN'ów jest o wiele więcej?"
      ],
      "metadata": {
        "id": "xpAPYmWK3EcM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "count_nan_volume = data['45'].isna().sum()\n",
        "count_nan_nyse= data['46'].isna().sum()\n",
        "count_nan_nasdaq = data['47'].isna().sum()\n",
        "count_nan_lse = data['48'].isna().sum()\n",
        "\n",
        "\n",
        "print(f\"Volume: {count_nan_volume}\")\n",
        "print(f\"Nyse: {count_nan_nyse}\")\n",
        "print(f\"Nasdaq: {count_nan_nasdaq}\")\n",
        "print(f\"Lse: {count_nan_lse}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxPBWEuBa-gl",
        "outputId": "26a23be4-710d-42cd-d0bf-c9b1a326b84b"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Volume: 770\n",
            "Nyse: 961\n",
            "Nasdaq: 961\n",
            "Lse: 961\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Okazuje się że w Volume brakujących wartości jest MNIEJ niż w giełdach, skąd więc taka duża różnica w wynikach modelu?"
      ],
      "metadata": {
        "id": "kqYrijFI3-aP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Warto pamiętać że brakujące wartości zastąpiliśmy średnią wartością danych z danej kolumny, co oczywiście nie jest idealnym rozwiązaniem jednak w większości przypadków absolutnie wystarczającym"
      ],
      "metadata": {
        "id": "5VbcJNdl4ayx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "min_value = df['45'].min()\n",
        "max_value = df['45'].max()\n",
        "\n",
        "print(\"Min Volume value :\", min_value)\n",
        "print(\"Max Volume value :\", max_value)\n",
        "\n",
        "min_value = df['46'].min()\n",
        "max_value = df['46'].max()\n",
        "\n",
        "print(\"Min NYSE:\", min_value)\n",
        "print(\"Max NYSE:\", max_value)\n",
        "\n",
        "min_value = df['47'].min()\n",
        "max_value = df['47'].max()\n",
        "\n",
        "print(\"Min NASDAQ:\", min_value)\n",
        "print(\"Max NASDAQ:\", max_value)\n",
        "\n",
        "min_value = df['48'].min()\n",
        "max_value = df['48'].max()\n",
        "\n",
        "print(\"Min LSE:\", min_value)\n",
        "print(\"Max LSE:\", max_value)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCyA4OQi4YxP",
        "outputId": "01a11d4e-ad26-43b9-86aa-c569f7abcc31"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Min Volume value : 7326.81\n",
            "Max Volume value : 1446125474.0765376\n",
            "Min NYSE: 8777.3798828125\n",
            "Max NYSE: 17353.759765625\n",
            "Min NASDAQ: 6192.919921875\n",
            "Max NASDAQ: 16057.4404296875\n",
            "Min LSE: 3649.0\n",
            "Max LSE: 9910.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean_value = df['45'].mean()\n",
        "\n",
        "print(\"mean Volume value :\", mean_value)\n",
        "\n",
        "mean_value = df['46'].mean()\n",
        "\n",
        "print(\"mean NYSE:\", mean_value)\n",
        "\n",
        "mean_value = df['47'].mean()\n",
        "\n",
        "print(\"mean NASDAQ:\", mean_value)\n",
        "\n",
        "mean_value = df['48'].mean()\n",
        "\n",
        "print(\"mean LSE:\", mean_value)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JEv2Oaj5_iz",
        "outputId": "c49e2509-244c-417c-f726-4cc5b6e4988b"
      },
      "execution_count": 41,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mean Volume value : 102721105.78741343\n",
            "mean NYSE: 14104.88804413526\n",
            "mean NASDAQ: 10582.317238058116\n",
            "mean LSE: 6849.880587166147\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"MIN wartość volume jest {int(1446125474.0765376/7326.81)} razy mniejsza niż MAX\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tm1n33fr6o7Z",
        "outputId": "054dae5f-7a38-4a4e-98bb-d51bf1e21a7e"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MIN wartość volume jest 197374 razy mniejsza niż MAX\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"MIN wartość NASDAQ jest {int(16057.4404296875/6192.919921875)} razy mniejsza niż MAX\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LISx4b8Rt2GI",
        "outputId": "99588215-d5f4-4cba-8661-ddc85f7960fa"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MIN wartość NASDAQ jest 2 raza mniejsza niż MAX\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_filled.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVWR_8vi8eWG",
        "outputId": "354ff323-3076-4612-b6a8-bf4eac075928"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2344, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(data_filled['45'])\n",
        "plt.xlabel('Index')\n",
        "plt.ylabel('Value')\n",
        "plt.title('Volume value')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "D8rUGU1I-BKQ",
        "outputId": "40458104-1572-423e-de90-06755db4dcd4"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(data_filled['46'])\n",
        "plt.xlabel('Index')\n",
        "plt.ylabel('Value')\n",
        "plt.title('NYSE value')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "nSQgAuvD8RMw",
        "outputId": "e4bfc61d-bf2e-4a8f-cdfc-a8fccd422f6f"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk0AAAHHCAYAAACiOWx7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABY4ElEQVR4nO3dd3gU1cIG8Hdr+qYQQgiGJl16DwKC5BKa0kRAsKLoFQREEVQEr/d6KYpeVBTRT7Gj3CsoqGikBSUgvXdDT6Glty3z/REz7G52N7PJ7s6W9/c8eR525uzsmdmw++acM+coBEEQQEREREQOKeWuABEREZEvYGgiIiIikoChiYiIiEgChiYiIiIiCRiaiIiIiCRgaCIiIiKSgKGJiIiISAKGJiIiIiIJGJqIiIiIJGBoIiKS2UMPPYTGjRvLXQ0iqgZDExF51MqVK6FQKBAcHIxLly5V2d+vXz+0bdsWAJCeng6lUonnn3/e5rEWLVoEhUKBH374AQBgMpnw6aefokePHoiJiUFERARatGiBBx54ADt27BCft2XLFigUCrs/q1atcsOZE5GvU8tdASIKTGVlZVi4cCHefvttu2WSkpLw+OOPY8mSJZg4cSJuu+02cd+5c+fwyiuvYMyYMRg6dCgAYNq0aVi2bBmGDx+OCRMmQK1W48SJE/jpp5/QtGlT9OzZ0+L406ZNQ7du3Wy+LhGRNYYmIpJFx44d8cEHH+D5559HQkKC3XILFy7Ed999h8cffxzbtm2DQqEAADz11FPQaDRYunQpACA7OxvvvvsuHnvsMaxYscLiGP/5z39w5cqVKsfu06cP7rnnHheeFRH5M3bPEZEsXnjhBRiNRixcuNBhucjISCxduhS///47PvzwQwDAmjVrsG7dOixcuBD169cHAGRkZEAQBNx+++1VjqFQKBAXF+eSek+dOhXh4eEoLi6usm/8+PGIj4+H0WgEAHz33XcYOnQoEhISEBQUhFtvvRX//Oc/xf32VHYfbtmyxWL72bNnoVAosHLlSovtx48fxz333IOYmBgEBweja9eu+P7772t1nkRUFUMTEcmiSZMmeOCBB/DBBx/g8uXLDstWdsHNnj0bf/75J6ZPn45evXrh8ccfF8s0atQIALB69WqbgcaWgoICXL16tcqPIAh2nzN27FgUFRWJ46gqFRcXY926dbjnnnugUqkAVIzfCg8Px8yZM7F06VJ06dIF8+bNw5w5cyTVT4ojR46gZ8+eOHbsGObMmYMlS5YgLCwMI0aMwJo1a1z2OkQEQCAi8qCPP/5YACDs2rVLOHPmjKBWq4Vp06aJ+++44w7htttuq/K8s2fPCmFhYUJMTIyg0WiEQ4cOVSnzwAMPCACE6OhoYeTIkcLrr78uHDt2rEq5zZs3CwDs/mRmZtqtv8lkEho0aCCMHj3aYvs333wjABDS0tLEbcXFxVWe//jjjwuhoaFCaWmpuO3BBx8UGjVqVKV+mzdvtnhuRkaGAED4+OOPxW0DBgwQ2rVrZ3E8k8kk9OrVS2jevLnd8yAi57GliYhk07RpU9x///1YsWIFMjMzHZZt1KgR5s+fj+vXr2PmzJniHXbmPv74Y7zzzjto0qQJ1qxZg2effRatW7fGgAEDbN6pN2/ePKSmplb5iYmJsVsPhUKBMWPG4Mcff0RhYaG4/euvv0aDBg3Qu3dvcVtISIj478pWrT59+qC4uBjHjx93eL5SXL9+HZs2bcK9995r0Wp27do1pKSk4NSpUzbPm4hqhqGJiGQ1d+5cGAyGasc2ARDvdOvatavN/UqlElOmTMGePXtw9epVfPfddxg8eDA2bdqEcePGVSnfrl07JCcnV/nRarUO6zF27FiUlJSI44YKCwvx448/YsyYMeJAdaCi62zkyJGIjIyETqdD3bp1MXHiRABAXl5etedbndOnT0MQBLz00kuoW7euxc/8+fMBADk5ObV+HSKqwLvniEhWTZs2xcSJE7FixQqXjvWpU6cO7r77btx9993o168ftm7dinPnzoljn2qjZ8+eaNy4Mb755hvcd999WLduHUpKSjB27FixTG5uLu644w7odDq88soruPXWWxEcHIy9e/di9uzZMJlMdo9vHrzMWQ8grzzGs88+i5SUFJvPadasmbOnR0R2MDQRkezmzp2Lzz//HIsWLXLL8bt27YqtW7ciMzPTJaEJAO69914sXboU+fn5+Prrr9G4cWOLeaC2bNmCa9eu4dtvv0Xfvn3F7RkZGdUeOzo6GkBF8DJ37tw5i8dNmzYFAGg0GiQnJ9f0VIhIInbPEZHsbr31VkycOBHvv/8+srKyanSMrKwsHD16tMr28vJybNy4EUql0qWtLmPHjkVZWRk++eQTbNiwAffee6/F/so76ASzO/HKy8vx7rvvVnvsRo0aQaVSIS0tzWK79XPj4uLQr18/vP/++zbHhNmam4qIao4tTUTkFV588UV89tlnOHHihMXM31JdvHgR3bt3x5133okBAwYgPj4eOTk5+Oqrr3DgwAHMmDEDsbGxFs/Ztm0bSktLqxyrffv2aN++vcPX69y5M5o1a4YXX3wRZWVlFl1zANCrVy9ER0fjwQcfxLRp06BQKPDZZ585nM6gUmRkJMaMGYO3334bCoUCt956K9avX29zfNKyZcvQu3dvtGvXDo899hiaNm2K7OxspKen4+LFizhw4EC1r0dE0jA0EZFXaNasGSZOnIhPPvmkRs9v2bIl/vOf/+DHH3/Eu+++i+zsbAQHB6Nt27b44IMPMGnSpCrPeeutt2wea/78+dWGJqCitenVV19Fs2bN0LlzZ4t9derUwfr16/HMM89g7ty5iI6OxsSJEzFgwAC744/Mvf3229Dr9Vi+fDmCgoJw77334rXXXqty12CbNm2we/du/OMf/8DKlStx7do1xMXFoVOnTpg3b161r0NE0ikEKX/2EBEREQU4jmkiIiIikoChiYiIiEgChiYiIiIiCRiaiIiIiCRgaCIiIiKSgKGJiIiISALO0+QiJpMJly9fRkREhN11o4iIiMi7CIKAgoICJCQkQKl03JbE0OQily9fRmJiotzVICIiohq4cOECbrnlFodlGJpcJCIiAkDFRdfpdDLXhoiIiKTIz89HYmKi+D3uCEOTi1R2yel0OoYmIiIiHyNlaA0HghMRERFJwNBEREREJAFDExEREZEEDE1EREREEjA0EREREUnA0EREREQkAUMTERERkQQMTUREREQSMDQRERERScDQRERERCQBQxMRERGRBAxNRERERBIwNBERkdNKyo1yV4HI4xiaiIhIEkEQ8NOhTEz+dDfa/+NnHMvMl7tKRB7F0EREFMAEQcDmEzk4f60YxeUGh2V/PpKNv3+xF78czYbeKODN1JMeqiWRd1DLXQEiIpLPgYt5ePjjXeLjtVNuR8fEKJtl089ctXgcpFG5s2pEXoctTUREAezijWKLx6v+OG+3bLlRsHisVircUicib8XQREQUwHb8ec3icbnBZLeswWi5z1FZIn/E0EREFMA+32HZslTkYFyT3io0XSsqc0udiLwVQxMRUYDafyG3yrZiB1MJKBSW3XGFZY4HjhP5Gw4EJyIKQAt+Oob3t/5ZZbu9+Zf0RhPW7LtksU2r4t/dFFj4G09EFIBsBSbAfkvT5E93V9mmYWiiAMPfeCKiAPPLkSy7+0r0tkPT5hNXqmxT8e45CjAMTUREAWbyZ3vs7rM3wSWnFyBiaCIiIjP2uucaRIdU2SaYTdt04Xoxbl+4Cf/3W4a7qkYkO4YmIiISFZQa8O3ei04/b+FPx3EptwT/XH/UDbUi8g4MTUREAcRoEqotM/ObA5KOJeDmscokTHQpCAKe+eYAXv/5hKTjE3kbhiYiogBS3aK87nQyuxD/23sR72w+DZOE8EbkbRiaiIgCiL274xzZc+4Gzl0rrrJ919kb4izhCifHiRfKGN6IaoqhiYjIjxy5nIfzNgJOJXuTVzoy+r3tNrcbTQIW/XRc8nHMb8ArKGVoIt/D0ERE5CeuFZZh6Fu/oe9rm6ssrltJakuTwWjCzj+vobSa8h/+loEL14uRejS72mPqjTe75Iq4BAv5IIYmIiIfZTIJSDt5BVcLKxbOvZRbIu4z/7e5G0V6Scd+e9NpjF2xA89/e6jasn97c6ukY5ov+Gu9+C+RL2BoIiLyUZtP5OCBj/7AgCVbYTCacOnGzaAk2BlnPf6DHZKOvXTjKQCost6cLaV6aQHIPCgZjBwITr6HoYmIyEedv14xdimvRI+X1x3B37/YK+7zxkhSbhaaPt9xTsaaENUMQxMRkY/KK7nZ1fb5jvMW+45l5nu6OtUyn8tp9Z6LOJldIGNtiJzH0ERE5KPMQ5O1J81anTwtO7/U5vaHP95l8djeuCsib8XQRETkgwRBwPqDmXJXw6Ye/95Y7V13AKA3mLD011O4d3m6pPJEcmNoIiLyQf/bewlXCsoclrEOIoK90eE2tIqPqFG9Kt0oLrd4bKsrrtxowpu/nsQfZ6/j+wOXa/V6RJ7A0ERE5AXOXClE4zk/oPGcHxxOTgkAF64X49nV1a8PZz2BpMGJpUukrFHniPXTbXUXluk5BQH5FoYmIiIvMGDJzbmO+r62Wfz3xmPZ2HryCtJOXsHRyxWDu/ss3lzl+bbkl1qOeSqXsKhupVM5hZLL2mK0mlLAfDqESs+YBT+10sl1WIhkoJa7AkREVNUbqSexevcFZOZZDqo+u3Co5GPkl9Q8NNWW3mT5WtXNRK5S8m948n78LSUikpmtJU/e2niqSmACnBuXNPLd7bhedHNsUZkHQ5Oz3XtsaSJfwNBERORh5QYTcgpuBiK9E7NjS519u9I9723H8q1ncORynmdbmsyCYOUyL46oGJrIBzA0ERF52OClaej+6kZkXC0CAAhOzN9tfVdadf68WoSFPx3H0Ld+Q7nRc7f1m7c0fbP7QrXllQqGJvJ+DE1ERB525kpFWPr1aDYA4Ks/qg8VlXot3FTj1/Vk95x561lpefVhzWDi3XPk/RiaiIhkUmaoCBP/XH/UI6+373yuR14HsGxpKpUQ1riAL/kChiYiIpm8/stJj77e3LWHPfZa5oPbpcz2zZYm8gUMTUREHmSyuqvMX5cP0Zu3NEkKTWxpIu/H0ERE5EHW44pmrNovT0XcrKT85mzkUu7asw6TRN6IoYmIyIOKyy2XNtlwJEummrjXE5/vxZc7zwMApAxXqu2yLUSewNBERORB1c2M7U9eWHMIAGCUMF6J48DJFzA0ERF5SE5+Kcat2CF3NTzqrY2nJN0Zx+458gUMTUREHvLi2sO4aGPhWn/2RupJSV1vJieWhyGSC0MTEZGHnMoukLsKsjBKCERSyhDJjaGJiMhD8kr0cldBFpJamtg9Rz6AoYmIyENuFAdmaJIypsnIuS3JBzA0ERGRW0mZ7Zvdc+QLGJqIiMitpEyzwO458gVquStAROTvLt4oxms/n5C7GrIpLpMQmtjSRD6AoYmIyM16L9osdxVkVWQ1C7ot7J4jX8DuOSIicqvicnbPkX9gaCIiciOBLSiSQpPBJOD5bw/hi53nPFAjz9h68gqGv/Mb0k5ekbsq5CLsniMicqNAWmvOHinzNP16LBsXrlfMlj6hRyN3V8kjpn21D3kleryy/ih+nXmH3NUhF5C1pSktLQ133XUXEhISoFAosHbt2ipljh07hrvvvhuRkZEICwtDt27dcP78eXF/aWkppkyZgjp16iA8PByjR49Gdna2xTHOnz+PoUOHIjQ0FHFxcZg1axYMBss+9i1btqBz584ICgpCs2bNsHLlSnecMhEFmMKy6sfzEMTA5E8qJzM9nVOIojIDWx39gKyhqaioCB06dMCyZcts7j9z5gx69+6NVq1aYcuWLTh48CBeeuklBAcHi2WefvpprFu3DqtXr8bWrVtx+fJljBo1StxvNBoxdOhQlJeXY/v27fjkk0+wcuVKzJs3TyyTkZGBoUOHon///ti/fz9mzJiBRx99FD///LP7Tp6IAkJhKUMTAZ1eScXs/x2UuxpUSwrBS6KvQqHAmjVrMGLECHHbuHHjoNFo8Nlnn9l8Tl5eHurWrYsvv/wS99xzDwDg+PHjaN26NdLT09GzZ0/89NNPGDZsGC5fvox69eoBAJYvX47Zs2fjypUr0Gq1mD17Nn744QccPnzY4rVzc3OxYcMGSfXPz89HZGQk8vLyoNPpangViMjfHLqYh7ve+U3uaviUswuHWjzeduoKlm0+jQWj2qNJbJhMtXJe4zk/VNn257+HQKlUyFAbsseZ72+vHQhuMpnwww8/oEWLFkhJSUFcXBx69Ohh0YW3Z88e6PV6JCcni9tatWqFhg0bIj09HQCQnp6Odu3aiYEJAFJSUpCfn48jR46IZcyPUVmm8hi2lJWVIT8/3+KHiMhaQWlgLp3iSvf/3x/Y8ed1TF+1T+6qSHYs0/Z3woUbxR6uCbmS14amnJwcFBYWYuHChRg0aBB++eUXjBw5EqNGjcLWrVsBAFlZWdBqtYiKirJ4br169ZCVlSWWMQ9Mlfsr9zkqk5+fj5IS2/3sCxYsQGRkpPiTmJhY63MmIv9z34c75a6CT8vOL7X5b2837G3brYtS7iQk7+W1ocn011pFw4cPx9NPP42OHTtizpw5GDZsGJYvXy5z7YDnn38eeXl54s+FCxfkrhIReZldZ6/LXQWftu7AZfT490a5q1Ej9u4YLOXdlD7Na0NTbGws1Go12rRpY7G9devW4t1z8fHxKC8vR25urkWZ7OxsxMfHi2Ws76arfFxdGZ1Oh5CQEJv1CwoKgk6ns/ghIjKXejS7+kJk11Nf+U53HADkFesxZvl2h3NNlRmqX7yYvJfXhiatVotu3brhxAnL9ZpOnjyJRo0q5vDo0qULNBoNNm68+ZfIiRMncP78eSQlJQEAkpKScOjQIeTk5IhlUlNTodPpxECWlJRkcYzKMpXHICKqifPXOH7FlRTw7gHUb/56ErvO3sCLaw7bLePulqaiMgOuF5W79TUCmayTWxYWFuL06dPi44yMDOzfvx8xMTFo2LAhZs2ahbFjx6Jv377o378/NmzYgHXr1mHLli0AgMjISEyaNAkzZ85ETEwMdDodnnrqKSQlJaFnz54AgIEDB6JNmza4//77sXjxYmRlZWHu3LmYMmUKgoKCAABPPPEE3nnnHTz33HN45JFHsGnTJnzzzTf44Yeqdz4QEUm14UiW3FXwSYIgQKGofUAyGE1QKRUuOZYUUsZcuTs0tXv5Z5gE4NDLAxERrHHrawUiWVuadu/ejU6dOqFTp04AgJkzZ6JTp07iHEojR47E8uXLsXjxYrRr1w4ffvgh/ve//6F3797iMd58800MGzYMo0ePRt++fREfH49vv/1W3K9SqbB+/XqoVCokJSVh4sSJeOCBB/DKK6+IZZo0aYIffvgBqamp6NChA5YsWYIPP/wQKSkpHroSRORvuJZazbni0hWWGdBn8WZM/mxP7Q8mUYGEObky81w/mL2gVI8zVwohCIJ47f68UuTy1yGZW5r69etX7QypjzzyCB555BG7+4ODg7Fs2TK7E2QCQKNGjfDjjz9WW5d9+3yr/5yIvBcjU80ZTQJUNuYyMjkxreC7m08jM6/ULSHFngIJs79fKShz+euOfm87TmYX4tsne4nbgjUql78OefGYJiIiX5OVV4qsv76kvWTeYJ9kLxw50wL17pYz4r9d9V5cuF6Mtfsu2T1eoYQ5udzxW3EyuxAA8Fn6zQHoQWp+vbsDryoRkQuUG0zouWAjei7YiHKDCTeKOallTdkLTTUNP1cKXdO6c9c7v2HG1/vtzsEkZZ1Bd2Zp8wHgtlrqqPYYmoiIXKDEbNLCCzeKMWDJFvkq4+PszXFkrGHi+Oi3s7WozU25fwXhI5dtz/YtdZ1Bo0lwy0zx9q4buQ5DExGRC2w6cXNOpld/OIZ8LtRbYyY7UxlJDQXWg/CjQz1zF1mxhDvjBAi4Z/l2tHv5F7Er11UMZheOvcPuwdBEROQCT399QPz3puM5DkpSdex3z0l7frnRMnXFhgfVtkoW7PV8SaqfAOw7nwsA6LnA/mznH277E++ZjcuSwjxsCrwVwS1kvXuOiIjImr1uOKktTXqr0OTqWbjVSve2N1zOLcG/fjgGABjeMQEJUbZXpgAs78b7g8v2uB1bmoiIyKvUdkyT3mhZrtzg2gkla5OZpJzBR79liP8+e9XxfEs/25lAld1z7sHQREREXsXeXWhS754rt2pZyrhaVOvJRg9dzBP/razFDONSzuFDs9D0/JpDDuteN8J21yMzk3swNBERkVcpLDXYDBdSu+eslyr5JP0cZv/vYK3qdNc7N6cZUNUiNH2wLcPhfuuuxXPXirH+UKbd8va6HjlPmHswNBER1QK/nFyvoNSA/JKqrU1SG4uu2piXafWei7Wtlqiw3IDBS7fhnU2nXHbMSiU27sDbd/6G/fLlvEvTkxiaiIhq6MNtf6LTP1NxIqtA7qr4lX+sO4IOr/xS4+dfM5vk0RWuWx1PEIBjmfl4/ZeT4rbPdpyzflqNlJZXDU0f/34WO/68ZrN8iY3yALvn3IWhiYiohv71wzHkFusx77vDclfFr5zKKazV8627uGrrwIXcasu8tNY1vwP2BnaPW7GjyjZBEPB+2p82y7MB1D045QARUS1ZzwtE8jIYXZsYbhTbb7kymQQoXbRkyZz/HcSqXRcklz9wMc+jCxITW5qIiGrN1S0bVDsGFy8nUuBgdne9venLa8CZwAQAZxy2yLGpyR0YmoiInCQIAtYduCw+tr7FneRlcHGIdRSKa9uqdaMW469yS+yvX8fuOfdgaCIictLe87l46qt94mOGJu/i6pYmR8erbSvjpdwSyWWLrOavsn5sjpnJPRiaiIictP30VYvHDE3exZUtTdtOXcHCn47b3W89+7izKueektLidNv8ny0eF3G6AY9jaCIicoLBaMKS1JMW21y9thnVjqOWoVV/nMfSX6XNr3SloAz3/98f1bxW7d77yufP/Ga/pPKbjmfjwvViGE0C1uy9ZLccu+fcg3fPERE5Ic/GOBJXzwtENXPgQi4+/j0DUaFau2XmfHsIADCobTxaxkc4PN4cCbOI6w1ClRnInVE5JmrLySuSyj+ycjcAYPagVsgpqDqJZyWBHXRuwdBEROSEfAd3UpG8hi/73e6+OmGWQcpW+LV25HJ+tWX0JlOtppyobBVztmVo0Qb7XYbkPuyeIyJygq0lOsj76UI0Fo+lLH9ja0kTawajUKsxbe6aroLdc+7B0ERE5ITjXDLFJ5msUoSUG+ykhCa90YS95+yvDVcdqYsQO4uhyT3YPUdE5ISDEpbUIO9jHZqkjPmR0oI0678HcSyz+m48e2p79509HNPkHmxpIiJyQm3XRSN5mEywHLDtokxRm8AEuK+lidyDoYmIyAlSxsKQ9xEEweJuOG/JKrWdssAe/pq6B0MTEZET+F3km0wCsHb/zaVvvKX7yl3dc+QeDE1ERE6wHhtDnlXTlr6s/FKLx97S0mR0U0sTuQdDExGRAzn5pXjuvwdw8GIuAHZ7yM1VYcdbulndNhDcO07P7zA0ERE58OLaw/hm90Xc/c7vKCk3SprwkNzHVQOnvSVTuG3KAa85Q//C0EREZMfZq0VIPZotPn4j9YSMtSHAdWHAe1qaOBDclzA0ERHZ0e/1LRaP93OOJtm5Kgx4S6jglAO+haGJiEiiUj0H7crNXthxtuXIW0JTucGE9DPXXH5cLzk9v8MZwYmIbNh99nqVbVKW1SD3stc9Z3CyxcZb7oL86PcMLEk96fLjekv3o79hSxMRkQ33LE+vso2L9crPXhZw19ggd7tRrJe7CuQEhiYiIoly+QUnO3stRHqDk91zrqiMF/P385MLQxMREfkMe2HgWJZzU0H4e/eVn5+ebBiaiIis+PsXqi+z9dYYjCaMW7Gj1scx5/t3tfl6/b0TQxMRkZUyg2+OjwkEgiDgwvVi/HgoUwy3aaeuOH2cP68WOdxfWGqoUf3IvzE0ERFZKeVdcl6r3GBCn8Wb8eQXe/H9gYoFeIvLnX+/XvvZ8USl+aW+PX6NjaXuwdBERGSF8zF5r/e2nhH//fvpqwAApULh9HHaNtDZ3G4yCZjw4Q70Wby5ZhX0EsxM7sHQRERkpczAliZvZT4RpOGvxW5r0pXWNiHS5vYDF3Px+2nXTzZJ/oGhiYjIiq/O+RMIzKccKP/rfTqZXeD0cex1wfpLKyO759yDoYmIyIreyG8cb2V+U1tluHV2NnDA/mB/379rrgLvAHUPhiYiIitsafJeJrNQU1BqQGZeCQwm598ve7O71+RY3oiRyT0YmoiIrLClyXsZzVpQtp+5hqQFm3Ayq9Dp4+w6ewPrD16uenw/aWki92BoIiKywpYm72VrGZU/bCyuLMXctYerbKtJV583Yu+cezA0ERFZMbClyWu5svfMaON9NvlLaGIHnVswNBERWWFLk/e6lFvismPZalXyl5Ymcg+GJiIiKwxNgcFoow/LVvefT/KT0/A2DE1ERFaOZubLXQXyAFtdcdcKy2WoiesxM7mHWu4KEBF5g2lf7UNWfimmD2iO//x6Su7qkAfY6orLzi+VoSau5y8NZt6GoYmIAp7JJIiLv9q6o4oCh71JL4kAds8REaHYbEmN89eLZawJya3cT8az8e4592BoIqKAZjCaUFx+c8FXTm4Y2Mr9pKWJ3XPuwe45IgpYW07k4KGPd0GtVMhdFfIS/hKayD3Y0kREAWvyp3sAcG4euslfppvgb7R7MDQRUcDymzl5yGX8paVJ4O+2WzA0EVHAsjW5IQUWvdGE89duDv73n4Hg5A4MTUQUsJiZ6InP9qDva5ux+XgOAKDU7E5KImsMTUREFLA2/hWWlm89A8CP5mniHwRuwbvniCjglOqN+HbvJbmrQV7kRnHF8illev8ITZynyT0Ymogo4CzbfBpvbzotdzXIixSXV3TLlRn8o3uOXc/uwe45Igo4v52+KncVyMtUTmpa6ictTeQeDE1EhONZ+RiydBt+PZotd1U8IjyIjexkqXKurhI/GQjOlib3YGgiIkz/aj+OZubj0U93W2z3lzlrrIVqVXJXgbyMwWiC3mhCXole7qq4BDOTezA0EREy80qqbNt+5irazv8ZH/+eIUON3CuMLU1kxWAUsHzLGbmrQV5OIXDaUJfIz89HZGQk8vLyoNPpXHbco5fzMW3VPsnlT+cUAgDqhGlxrajibhCFAkiIDMGVwjKx5UD111pbRpOAYI0SdcKCcCm34oszTKuCLkSDzLxSAEBUqAZalRI5BWUAgNjwIAACrhZWHF+rUiJEqxL/QkuIDMblv54LAA2iQnC1sAxlBhNUSgXidcHIzi+FwSRAq1aibngQLueVQBAqjhUbrhWfrwtWI0SrQnZ+mXheSqUCV/6qS1xEkFgvKRpEheBKQRnKjSZoVArERQQjK7/U5iKtEUFqhAerxesQHaqBxuw6xIRpoQDE61xPF4SSciPySysWf9WoFNCqlCgqN4rvQeU1rqxL5XUIUisRG37zPQgPUkMXrBavg1atRHSoRrwOseFaABDfg7iIIJQbTcgtrngP6kcGo7DUgIKymwvRBmuUKNVXvAfVLUpr/R6as34P6kYEIa9EL/5u1Y8MRlGZQbwODaJCcKO4XBxoq1YqoFQqUG4wQatSom5EkPgeWP8uWr8H1r+L4UFqFJqdYz1dEEr1JovfxbwSPYr+em3z30Uif1Y/Mtgv/zhoU1+Ht8Z3cukxnfn+ljU0paWl4bXXXsOePXuQmZmJNWvWYMSIETbLPvHEE3j//ffx5ptvYsaMGeL269ev46mnnsK6deugVCoxevRoLF26FOHh4WKZgwcPYsqUKdi1axfq1q2Lp556Cs8995zF8VevXo2XXnoJZ8+eRfPmzbFo0SIMGTJE8rm4KzTtPX8Do97d7rLjERER+arODaPw7ZO3u/SYznx/yxpDi4qK0KFDBzzyyCMYNWqU3XJr1qzBjh07kJCQUGXfhAkTkJmZidTUVOj1ejz88MOYPHkyvvzySwAVF2PgwIFITk7G8uXLcejQITzyyCOIiorC5MmTAQDbt2/H+PHjsWDBAgwbNgxffvklRowYgb1796Jt27buOXmJmseFY9XkntWWM5oETPhwpwdqROR/ts+5EyV6I8oNJpgEAUFqFQABBpOAMK0apfqK1sLKxwoFcK2wHEEaJcKD1BCEilvWlQogNEgNk0lAYZkBBqOAOuFaGIwCisoN0KqVCNWqUKY3oURvRLBGhSC1EqV6IwrLDAjRqBAWpBbrEqZVQ61S4GphGTSqitdSKhUoLjPAJFSMzVIoKl5bgZuvfb2oHMEaFSKC1TAYBRTrDdColAjRqKA3mlBcbkSQuqKFuFRvQqneiBCNClq1ElcKylBQakBiTAg0KiWKy40wmCpa5iKCNSgpN8Boqnht80HToVqVeB0UCkCpUCBIrURRuQFqZcV5m792sEaFojIDSvRGRARrxOtQZjAhVKuCRqVEid6IknIjgjVKhGjVOHo5H8cy83FnqzhEhWrE9yBMW/FVZv0emL+2wSjgRnHFdSnVGzF82e92fx86JkZhyb0dqrwHucV6NIkNq/IeVNYzSKNERLAGhX+1sqqUQIhWDeNf74FaWTEiRqNSWFyHMsPN98BgEqBQVIwnrLwOle9BmLbi/S8pN6DMYBKfX1xuhNEkQKNSIkittNt67g/kvonDa7rnFAqFzZamS5cuoUePHvj5558xdOhQzJgxQ2xpOnbsGNq0aYNdu3aha9euAIANGzZgyJAhuHjxIhISEvDee+/hxRdfRFZWFrTaii6NOXPmYO3atTh+/DgAYOzYsSgqKsL69evF1+3Zsyc6duyI5cuXS6q/u1qapDIYTWj24k8ef10if3B24VC5q0AedKOoHJ3+mWp3/+C28XhvYhcP1ojk5Mz3t1cPBDeZTLj//vsxa9Ys3HbbbVX2p6enIyoqSgxMAJCcnAylUomdO3eKZfr27SsGJgBISUnBiRMncOPGDbFMcnKyxbFTUlKQnp5ut25lZWXIz8+3+JGTQqGQ9fWJiHyFRu34q09v9Iq2BPJCXh2aFi1aBLVajWnTptncn5WVhbi4OIttarUaMTExyMrKEsvUq1fPokzl4+rKVO63ZcGCBYiMjBR/EhMTnTs5F2NkotpKua1e9YX80OjOt8hdBfIwjcrxJ6beyBsFyDavHVq/Z88eLF26FHv37vXKVpTnn38eM2fOFB/n5+fLGpy88BKRj0mMDpW7Ch53YP5A6IK99mOQ3ESjrK6liaGJbPPalqZt27YhJycHDRs2hFqthlqtxrlz5/DMM8+gcePGAID4+Hjk5ORYPM9gMOD69euIj48Xy2RnW85yXPm4ujKV+20JCgqCTqez+JGTNwZL8i2T72iK5NZVW5tW3O+/YzsiQzT8vxOAlEq2NFHNeG1ouv/++3Hw4EHs379f/ElISMCsWbPw888/AwCSkpKQm5uLPXv2iM/btGkTTCYTevToIZZJS0uDXn9zltfU1FS0bNkS0dHRYpmNGzdavH5qaiqSkpLcfZpEXiMuIhgxYRqLbQ8mNfLLuV6IHCnnmCayQ9ZPw8LCQpw+fXOl8YyMDOzfvx8xMTFo2LAh6tSpY1Feo9EgPj4eLVu2BAC0bt0agwYNwmOPPYbly5dDr9dj6tSpGDdunDg9wX333Yd//OMfmDRpEmbPno3Dhw9j6dKlePPNN8XjTp8+HXfccQeWLFmCoUOHYtWqVdi9ezdWrFjhgatAJL+kphX/165YTRT68O1NxIkliQKFnpOfkh2yhqbdu3ejf//+4uPKMUIPPvggVq5cKekYX3zxBaZOnYoBAwaIk1u+9dZb4v7IyEj88ssvmDJlCrp06YLY2FjMmzdPnKMJAHr16oUvv/wSc+fOxQsvvIDmzZtj7dq1ss/RROQJ707ojD7NYwEAm09csdinVSvF2eOJAgW758geWUNTv3794Mw0UWfPnq2yLSYmRpzI0p727dtj27ZtDsuMGTMGY8aMkVwXIl/32+z+CNWqEROmtVtGq1aCmYkCTcfEKLmrQF6KgxWIAlRCZEi1A2K1amW1ZYj8zdxhbeSuAnkprx0ITkTu0yExSlIYClIrofTTu8u+m+La9avIP0zt3wyRIZrqC1JAYmgiCkCfPNzN5vbx3RtaPNaqlFD5YWh6+PbG6MAumID2zxG2x6yyYZUcYWgiCjBalRJRobbHMc2/y7JbQqFQoJp5AH2Sd6y4SXKKDmVrEjnPDz8OicghB39JB2tUVbb5Y/fcqZwCuatAMrPXgso8TY4wNBEFmHIn56DxxykHtCp+9AU6ezPBm9gMSQ7wk4MowHRrHO1UeX9saeLXItn7tTbxl4McYGgiCjC6YGljOUZ0rJhV3w8bmvjFSHbHtbGliRxhaCIKMEEaaf/te/y1tIo/ds85M6ku+Sd7vwNxEcEergn5Ek5uSRRggtRVB3ub2/Zcf+w5dwN3dahsafK/0ERkr7VxYs+GtncQgaGJKOAkRDn+SzoxJhSJMaHiY3+cETxU6zg4kv+LsjPlQHV/VFBgY2giCjAjOjZwqrw/Tm75EpfJCHhtEyItHodoVOj918LVRPYwNBEFkNmDWqF5vQinnuNvDU2fPtIdt0SHVl+Q/FqkVUvT/vl/41QUVK0a/YYYDAb8+uuveP/991FQUDFJ3OXLl1FYWOjSyhGRa9WPdH6Qq791z/lhwxm5QJBaZXfuJqJKToemc+fOoV27dhg+fDimTJmCK1euAAAWLVqEZ5991uUVJCLXaVo3zOnn+Fv3HAe2U6XPJ/VAZIgG707oLHdVyEc4HZqmT5+Orl274saNGwgJCRG3jxw5Ehs3bnRp5YjItWLDg5x+jr+FDP86G6qN3s1jsX/e3zCkXX25q0I+wukxTdu2bcP27duh1Vou+Nm4cWNcunTJZRUjItcLD3Z+GKO/LdjLLhgyx98HcobTH4cmkwlGo7HK9osXLyIiwrkBpkTkXoNui8fie9qLj8O0zocmf5vckt+RRFRTToemgQMH4j//+Y/4WKFQoLCwEPPnz8eQIUNcWTdygY6JUXJXgWTy2aTuWH5/F7HrIS4iqEYBiN1zREQVnP6zc8mSJUhJSUGbNm1QWlqK++67D6dOnUJsbCy++uord9SRakGj4ldEIHrmby3Qp3ldAEB4kBoHXx5Y49up/S00+dvdgETkOU6HpltuuQUHDhzAqlWrcPDgQRQWFmLSpEmYMGGCxcBw8g7PDGyJcSt2yF0N8qAgtRJT72xmsU3qIr22+FvG8LPTISIPqtHklmq1GhMnTnR1XcgNujaKlrsK5GHN4sJdOrjV/8Y0+df5EJHnOB2aPv30U4f7H3jggRpXhlxPzRluA86Ry/kuPZ6/hQw/Ox0i8iCnQ9P06dMtHuv1ehQXF0Or1SI0NJShyYs8fHtjuatA5HWYmYioppxuhrhx44bFT2FhIU6cOIHevXtzILiXeWkoFyUlspYQxbGXRFQzLum7ad68ORYuXFilFYrkxbuEiKqKi3B+VnQiIsBFoQmoGBx++fJlVx2OiGpo9RNJclfBq/nbGC0i8hynxzR9//33Fo8FQUBmZibeeecd3H777S6rGBE5b+m4jujWOEbuahAR+SWnQ9OIESMsHisUCtStWxd33nknlixZ4qp6US21rq+TuwpkR0yYFpuf7YeHP/4De8/nuvTYtzeLdenxiIjoJqdDk8lkckc9yMW+eLSH3FUgO+7ukIDIEA2+ffJ25BSU4nhmAR746A+XHDs2nON1iIjchZP4+CFdsBoxYVrx8Rv3dpCxNjX32+z+clfBLcyH1MRFBKNRnVDJz70l2v6dXy8MaVWbahERUTUktTTNnDlT8gHfeOONGleGXEMXYrlkhq9OcHlLtPQw4UvCgyz/24VoVZKfe/FGid19A1rXq3GdiIioepJC0759+yQdjHeleIfoUK3FY198V7bPuVPuKrhNRLDlf7tQbY1WM6qCt9JbevyOpjiTU4Rfj2XLXRUi8hOSPq03b97s7nqQC0WFWrY0+UKW1aqVKDfcHC9XOQHhW+M7YdpX0kK7r4iwWjw3RCO9penLx3rgvg92SjpuoKsbHoTnB7dG4zk/yF0VIvITvtlvQw5VbWny/tTUol64ze13d0jwcE3cL9oq1EpdEPelYW3Q69ZY9LZxh1ynhlGuqJrPuL1ZHQRrHH98qTm5KxG5WI36BXbv3o1vvvkG58+fR3l5ucW+b7/91iUVo5qz/lL29pamuIggTO3fHE98vgcAMLrzLTLXyL2C1NJblsw93KsxAGBM11vw2+mrFvucaa3yB4Pa1seT/Zphwoe2W90AwCh4sEJEFBCcbmlatWoVevXqhWPHjmHNmjXQ6/U4cuQINm3ahMjISHfUkSSqDEtD2tWXuSbOSXuuP+5sFYfbEnSICtXg36Payl0lpzhzm3+r+Aj0bFqnRq9TuSyOxsbA/q6Nomt0TF8l5e8AI6dHISIXc7ql6d///jfefPNNTJkyBREREVi6dCmaNGmCxx9/HPXr+9aXtb/Z+Ew/nL9ejI6JURbbvbyhCcF/tZKsf6o3AN+4oWBIu3i8Pb4zVEoFnl19AP/dc1HS8zbM6Fvr17YVmp7s36zWx/UlCgVQUGpwWEbPpiYicjGnW5rOnDmDoUOHAgC0Wi2KioqgUCjw9NNPY8WKFS6vIEkXE6atEpgA7+qemzu0NbrYaRVRKBQ+EZgAYNqA5uJYJFshxhapY5eqo1Vbvt7ITg3E4Bko8kr0EATHoSjQrgkRuZ/ToSk6OhoFBQUAgAYNGuDw4cMAgNzcXBQXF7u2duQi3hNE6oRr8e6EznJXo1a+eLQHWsXfXKYmSC3tv5GjcuO7J0p+fY3K8v10Zp6nmvK2LCsIQLnRcfdb5TV1VVglIpIcmirDUd++fZGamgoAGDNmDKZPn47HHnsM48ePx4ABA9xTS6oVb/rCax4XgXq6YLmrUWP/92DXKuu7WYcYexy1fAzv2EByHbRWLVthHghNSi/4JbqzVRxmJDdH3YggDGgdB4OD7rdn/tZCnP+Kd9ERkatIHtPUvn17dOvWDSNGjMCYMWMAAC+++CI0Gg22b9+O0aNHY+7cuW6rKNWct3xljO+eiLYNfPtmga6NY6psqyNxIPijfZrY3efMe2TdPVfTu/GcoVQARre/SvV1mJHcAtMHNIdCocB+B4sdm2c888DHAEVEtSE5NG3duhUff/wxFixYgFdffRWjR4/Go48+ijlz5rizfuQCOQVlclcBIRoVFoxqL3c1as1Wg0vjOmEOnzPtzma4o2WczfFmN48r/cvcegyVWmJLV21UzPUl78DquhEVLZSV10pvsl8f81Y985wkdfwZEZEtkj9B+vTpg48++giZmZl4++23cfbsWdxxxx1o0aIFFi1ahKysLHfWk2qhVC93G0HFtALm7uvREEDFIGZfYiue3NGirsPn1AkPQpdG0bUaW2P+VOuWJk+0nnhB71yVOugN9sc03ZZws0XTvKVJalcqEZEtTv/ZFRYWhocffhhbt27FyZMnMWbMGCxbtgwNGzbE3Xff7Y46Ui1Vc5NRlQVka+ouB7N317VaF23esDZY+XA3LBjVziWv7Sm2WipCtCq8OtL+3FJSrm91ocS85cR6TJMnFmT2hjFNw9pbTmlivlzQ39pYLlbc3GyGeaVZqLQOnEREzqjVJ0izZs3wwgsvYO7cuYiIiMAPP3CNJ29kfZfRLdEhFo+X1eButs42lu2w97X6xB23VtkWrFGhX8s4n7st3F59VQ5ChfUCvbZUF0nMx4JV6Z7zQEuTNwwFsl7Y+O4OCRjXLRH/GduxSig3v+bmdW9a1/ZyPUREUtQ4NKWlpeGhhx5CfHw8Zs2ahVGjRuH33393Zd3IRcqtujGSW9/8qzwuIggdbnF+cHbr+jqLx+O6JSKnoNRm2TmDWzl9fF/jaKJFqQPFHXlrXCfx33J0z3lDS5P1UjFqlRILR7fHiE4NqrS+mQ+ON+8W/c/Yjm6tIxH5N6dC0+XLl/Hvf/8bLVq0QL9+/XD69Gm89dZbuHz5Mj744AP07NnTXfWkWrBuaQoyW+hUbzQhymqB3+qolQo8N8gyCD01oDkm9mxU80r6uEu5JXb3xYZXf32tg625xfe0R3zkzWkarFu1PNE95wWZCaEOplZwFBzNB9knRIXYLUdEVB3Jn7aDBw9Go0aN8Pbbb2PkyJE4duwYfvvtNzz88MMIC3N89xDJy3rArPlf4TVZaiJEq0JkiOWiwOFaNepH+v4X0k/T+2BER/tjs+wpLKtdS1OZg9BkPSlmZKgG47rdnAzzVg90OXnDTO2OujnNg2Or+AiLfY66TomInCF5BLBGo8F///tfDBs2DCqVb41DCXRD29fHh79liI8bxYSK/3bUwmFPmLbqr01YkAphQVV/L8Z0ucXp48updX0dwuwM3L69mf2FdoschCYpk086usPR1jxMC0e3x+gut+BUdiGSbq3ZAsDO8IYxTRHBGrv7zO+KWz6xi8U+b6g7EfkHyS1N33//PYYPH87A5IM6NbRc622E2W3+toJOdWx1k6hVSrSsF4E4qwG5PZu6/wvd1czvdksyq3/vZvanFigqtx96pLTSlBrsP9/e3XfdGseIUze4mzcsReKoDuaD460vtze0khGRf+D9twGmad0wqJQKsdXk0T5NHZbv3qTqDNhjutpeJ02hUGBCD98f12Te0vT+A13QrXE0ujeJwSO9G9t9zvODWyFUq7J5V6EUpXr7LX5S7r5zN+uB1p4WrHH8+uYTfCqs7kV0NN6MiMgZ8n8ak0eZ/ppF+d0JXbD33A30aR7rsPyHD3bFN7su4F8/HBO3PeZgOZCLNywXbY7T1f7OMU8zD00hGhVWP9Gr2ue0rq/DwfkDoVYp8e8fj2FF2p9Ovaaj98Eb7lyTe36jAa3rOdyvUdpvaSIichW2NAWYypUnIkM06N8qrto7r8K0aovWqNhwrcPnPNm/mfjvlvUi0LuZ41Amhae/BCPMQpMzL115XXQ1aBm6JToUf7wwAJ1stFSZT9QoF7lDU9dG0Q73m7c0BVXTKkVEVFP8dAkwpuqmB7diPY7E/G67yju4RnW+OUYq0WzizKf/1sIl40k83XBgPtN0TTgasOxInC64yq3zd7byjglA5QxNr93TvtrpLMyXobOez4mIyFXYPRdgTA4WOZUir0Qv/vsfw2/DsPYJ6Nr4ZiuAeStU07qumYqillWWbHDbeACwWFi3Jl1jjuYTqk651RQQQ9rVt1PSs+Qa0zTtzmZ2x9CZM5jNRWYdmro2isbuczdcXjciCjwMTQFGVcMFS+/v2Qif7TiHp+682f0WpFaht42xOJ880h1XCsrQol5ElX3erFlcRTdYnC4Yq59IglqpsFi3TKrarOV3taBM/Pcnj3RHHxd0b7pCozph2Hs+1+Ovm9zG8VimSuYD6a27j//voW747dRVDGgd59K6EVHgYWgKMPZaDJQKxy06Lw1rg2Ht66NzNWNLAOCOFvZvzfdm5t1g3RpXvWtQql61CDqP9WmCl9cdxchODbzqOs4d2hrXi8qx9eQVj75u+1uiJJVzNO4rMkSDoe29o8WOiHwbxzQFGOvFXivZGty9+dl+4r+1aiV6NK1j9/nu9OEDXVEnTIuRZvNLuYP1zNs1VZvuuQd7Ncb6p3pj0ej2LqmLq9QJD8Inj3T36Gs+N6il5LJ3torDlP634n9/r/5ORyKimmJoCjD2BvTaWrurSax3LI+T3KYeds9NxlA3j+9xVWgyD5bv3NfJQcmqFAoF2jaIlP1uNXummt0d6W7dnWjtC9aoMCulFbpIaAklIqop7/xkJrex29LkBTM+O6JQKBBqNXv5E3fc6tLXGOGGlixvv67erCbjyYiI3ImhKUBUthDMHdra5v7q5mvyBtbjsWLDtS4Zq7L+qd44/ergGk8V4EireJ3LjxkouNAuEXkbDgQPEM+mtMTUO5vZnfPHG9YWq451HYM0Kiwd2xE/HMys1XHbNois1fNt2fH8AFwtLENjL+nidBVP5hhf+J0kosDC0BRAHE2SqLH6gnr8Dsdr0slBrbRsaQpWK732izU+MhjxkcFyV8Oneet7S0SBi6GJAAC3xoXjcl4pAOD3OXciwQu/8K0yEyKCNVzB3sM8ebUZmojI23j/QBbyiNfHdMDwjgn43997oUFUiFeGEeuWJl0IM78/Y2giIm/Dbx0CANTTBWPpOOduj/c06y9RnRsGblM1PBimORCciLyNrC1NaWlpuOuuu5CQkACFQoG1a9eK+/R6PWbPno127dohLCwMCQkJeOCBB3D58mWLY1y/fh0TJkyATqdDVFQUJk2ahMLCQosyBw8eRJ8+fRAcHIzExEQsXry4Sl1Wr16NVq1aITg4GO3atcOPP/7olnOmmrO+fT+Yq9n7NbY0EZG3kfVbp6ioCB06dMCyZcuq7CsuLsbevXvx0ksvYe/evfj2229x4sQJ3H333RblJkyYgCNHjiA1NRXr169HWloaJk+eLO7Pz8/HwIED0ahRI+zZswevvfYaXn75ZaxYsUIss337dowfPx6TJk3Cvn37MGLECIwYMQKHDx9238mT06y/RLUqrmbvaRzTRESBTNbuucGDB2Pw4ME290VGRiI1NdVi2zvvvIPu3bvj/PnzaNiwIY4dO4YNGzZg165d6Nq1KwDg7bffxpAhQ/D6668jISEBX3zxBcrLy/HRRx9Bq9Xitttuw/79+/HGG2+I4Wrp0qUYNGgQZs2aBQD45z//idTUVLzzzjtYvny5G68AOUNttdiwRl37L9UFo9rV+hjkHgxNRORtfKp/Iy8vDwqFAlFRUQCA9PR0REVFiYEJAJKTk6FUKrFz506xTN++faHVasUyKSkpOHHiBG7cuCGWSU5OtnitlJQUpKenu/mMyBlVW5oqfn1H/TWTd2x4kNPHHN+9Ye0rFkA8OcxIyTFNRORlfGYgeGlpKWbPno3x48dDp6uYZTkrKwtxcXEW5dRqNWJiYpCVlSWWadKkiUWZevXqifuio6ORlZUlbjMvU3kMW8rKylBWViY+zs/Pr/nJUY1Urs/2xtiOeLL/rUiICkGbeT9Lfv6QdvHuqhq5QFQoB/oTkXfxiZYmvV6Pe++9F4Ig4L333pO7OgCABQsWIDIyUvxJTEyUu0oBx3wdvWZxEQjVSv8bQKtSYuHo9u6oFrnA55N62F0nkYhILl7/qVQZmM6dO4fU1FSxlQkA4uPjkZOTY1HeYDDg+vXriI+PF8tkZ2dblKl8XF2Zyv22PP/888jLyxN/Lly4UPOTJEniIoIRYjarufVadM74v4e6csqCGlB4aCh4EO+MJCIv5NWfTJWB6dSpU/j1119Rp04di/1JSUnIzc3Fnj17xG2bNm2CyWRCjx49xDJpaWnQ6/VimdTUVLRs2RLR0dFimY0bN1ocOzU1FUlJSXbrFhQUBJ1OZ/FD7nfkHyno3SwWIzomQGljoPDyiZ0lHSc6VFt9IZJNvM77ZqQnIpJ1TFNhYSFOnz4tPs7IyMD+/fsRExOD+vXr45577sHevXuxfv16GI1GcYxRTEwMtFotWrdujUGDBuGxxx7D8uXLodfrMXXqVIwbNw4JCQkAgPvuuw//+Mc/MGnSJMyePRuHDx/G0qVL8eabb4qvO336dNxxxx1YsmQJhg4dilWrVmH37t0W0xKQd1AqFfj80R529/+tjbRxStFhDE014e6x2WqlAssmdEZiTKh7X4iIqAZkbWnavXs3OnXqhE6dKmainjlzJjp16oR58+bh0qVL+P7773Hx4kV07NgR9evXF3+2b98uHuOLL75Aq1atMGDAAAwZMgS9e/e2CDuRkZH45ZdfkJGRgS5duuCZZ57BvHnzLOZy6tWrF7788kusWLECHTp0wH//+1+sXbsWbdu29dzFIJeQepd6NAcZe6WJPRsh5TYO0Cci7yRrS1O/fv0gCILd/Y72VYqJicGXX37psEz79u2xbds2h2XGjBmDMWPGVPt65N2krplnPjaKpHNVQ1Ob+joczax6x6kuhGGWiLyXV49pIqqJR25vUm0Zb1yQOJAYTbb/IArVMswSkfdiaCK/wzXp3MdW61BNhNgJR2wBJCJvxm8X8jvVze+zdsrtHqqJ//n5iP0JX53RNDbM5vaOiVEuOT4RkTswNJHf+Vubeg7384tZfgY73XMd+N4QkRdjaCK/07ZBJJrHhctdDXLAYDLJXQUiIqcxNJFfurUuQ5M30xurvzOWiMjbMDSRX+LNcd7N/O45ldTJtYiIZMbQREQe98KQVogIUuPp5BZQMzQRkY+QdXJLInex19LE6Qi8Q7O4COyfPxAqpQIr0s6gTO4KERFJwG8QCihLxnSUuwoBb2i7+gBudsvNHdYGADCpd/WTkhIRyYktTeSXFHYW/Bjavr6Ha0LWlo7raPF4fPeG6N8yDvV0QfJUiIhIIoYmIpKstve8KRSA2sbko/GRwbU8MhGR+7F7jvxSZCgXfiUiItdiaCK/lBgdKncViIjIzzA0kV/iXXJERORq/GYhvxSkVsldBbJB4ETgROTDGJrIL7GliYiIXI3fLOSX2NJERESuxtBEfilIzV9tIiJyLX6zkF8KYvccERG5GL9ZyC+xe46IiFyNoYn8Ervn3OOFwa1r9fzx3RNdVBMiIs/jNwv5JXbPucfIzg1q9XxOOUBEvozfLOSX2D3nHkqF7YWQpXq0TxMX1YSIyPMYmsgvsXvOPZS1yEz39WiIZnERrqsMEZGH8ZuF/JKt0JQYEyJDTfyLohYtTWFatv4RkW9Ty10BIncI1lh+QS+f2AXdGkfLVBv/UcveOSIin8bQRH7JuqVpUNt4mWriX5iZiCiQsXuO/JJaxV9td6hN91xtnktE5A34zUJEkjH2EFEgY2giIslq01jEwEVEvo6hiYgkUzD6EFEAY2giv9Xhlki5q+B3nGlpUtVmUiciIi/E0ER+69a64XJXwe84E5qmD2iOFvVuvgdGE9dQISLfxtBERJI50z0XHxmMNU/eLj7WG03uqBIRkccwNJH/Yu+QyznT0hQepIbGbOqH2PAgN9SIiMhzGJqISDJncmhCVAg0qpvPqKcLdn2FiIg8iKGJiCRzZoLKhjGhFuW1XESZiHwcP8WISDJnWprMW5kAhiYi8n38FCMiyZwZ06SxWsqmYUyoi2tDRORZXLCXiCRzpntO+1do+nxSD1zKLUbbBpw3i4h8G0MT+a0wLX+9Pa1/y7rYfOIKAED51+SWvZvHylklIiKX4bcK+a0Zyc1x6FIe7u2aKHdVAoZKyR5/IvJfDE3kt+qEB2HtlNurL0guU5sFfYmIvB3/LCQil2mbwHFLROS/2NJERC7Tol44/vf3XqjL2b+JyA8xNBGRy6iUCnRpFC13NYiI3ILdc0TkMmoVBzURkf9iaCIil1FyJDgR+TGGJiJyGTWnHCAiP8ZPOCJyGZWSLU1E5L8YmojIZerpeNccEfkvhiYicpkmsWFyV4GIyG0YmojIJWaltHRqQV8iIl/D0EREREQkAUMTERERkQQMTUREREQSMDQRkUtwOBMR+TuGJiIiIiIJGJqIiIiIJGBoIiIiIpKAoYmIXEIBDmoiIv/G0EREREQkAUMTERERkQQMTUTkEpxygIj8HUMTERERkQQMTUREREQSMDQRkUuwd46I/J2soSktLQ133XUXEhISoFAosHbtWov9giBg3rx5qF+/PkJCQpCcnIxTp05ZlLl+/TomTJgAnU6HqKgoTJo0CYWFhRZlDh48iD59+iA4OBiJiYlYvHhxlbqsXr0arVq1QnBwMNq1a4cff/zR5edL5M8EuStARORmsoamoqIidOjQAcuWLbO5f/HixXjrrbewfPly7Ny5E2FhYUhJSUFpaalYZsKECThy5AhSU1Oxfv16pKWlYfLkyeL+/Px8DBw4EI0aNcKePXvw2muv4eWXX8aKFSvEMtu3b8f48eMxadIk7Nu3DyNGjMCIESNw+PBh9508kZ/ZdDxH7ioQEbmVQhAEr/gDUaFQYM2aNRgxYgSAilamhIQEPPPMM3j22WcBAHl5eahXrx5WrlyJcePG4dixY2jTpg127dqFrl27AgA2bNiAIUOG4OLFi0hISMB7772HF198EVlZWdBqtQCAOXPmYO3atTh+/DgAYOzYsSgqKsL69evF+vTs2RMdO3bE8uXLJdU/Pz8fkZGRyMvLg06nc9VlIfI6K3/PwMvrjlbZrlUpcfLVwTLUiIio5pz5/vbaMU0ZGRnIyspCcnKyuC0yMhI9evRAeno6ACA9PR1RUVFiYAKA5ORkKJVK7Ny5UyzTt29fMTABQEpKCk6cOIEbN26IZcxfp7JM5evYUlZWhvz8fIsfokDwt9vi5a4CEZEsvDY0ZWVlAQDq1atnsb1evXrivqysLMTFxVnsV6vViImJsShj6xjmr2GvTOV+WxYsWIDIyEjxJzEx0dlTJPIrRu9otCYichuvDU3e7vnnn0deXp74c+HCBbmrRCQro4mhiYj8m9eGpvj4ii6A7Oxsi+3Z2dnivvj4eOTkWA4+NRgMuH79ukUZW8cwfw17ZSr32xIUFASdTmfxQ0RERP7La0NTkyZNEB8fj40bN4rb8vPzsXPnTiQlJQEAkpKSkJubiz179ohlNm3aBJPJhB49eohl0tLSoNfrxTKpqalo2bIloqOjxTLmr1NZpvJ1iOgmzsdERIFK1tBUWFiI/fv3Y//+/QAqBn/v378f58+fh0KhwIwZM/Cvf/0L33//PQ4dOoQHHngACQkJ4h12rVu3xqBBg/DYY4/hjz/+wO+//46pU6di3LhxSEhIAADcd9990Gq1mDRpEo4cOYKvv/4aS5cuxcyZM8V6TJ8+HRs2bMCSJUtw/PhxvPzyy9i9ezemTp3q6UtC5LMaRIXIXQUiIrdSy/niu3fvRv/+/cXHlUHmwQcfxMqVK/Hcc8+hqKgIkydPRm5uLnr37o0NGzYgODhYfM4XX3yBqVOnYsCAAVAqlRg9ejTeeustcX9kZCR++eUXTJkyBV26dEFsbCzmzZtnMZdTr1698OWXX2Lu3Ll44YUX0Lx5c6xduxZt27b1wFUg8g9L7u0gdxWIiNzKa+Zp8nWcp4kCxeXcEvRauMliW5hWhf3zB0Kj8toefyIim5z5/pa1pYmIfF9EsBq7XkxmYCIiv8dPOSJyivXUAiEaFYI1KplqQ0TkOQxNROQU6w59lZL30xFRYGBoIiKnmKxSE0MTEQUKhiYicor1cikcy0REgYKfdkTkFOsbbtnSRESBgqGJiJxivcQcMxMRBQqGJiJyivWYJqWCqYmIAgNDExE5xXrKASKiQMHQREROsZ5ygC1NRBQoGJqIyCmt61suM8DMRESBgqGJiJxifbccQxMRBQqGJiKqFQWYmogoMDA0EVGtsKWJiAIFQxMR1YqCqYmIAgRDExHVCiMTEQUKhiYiqhU2NBFRoGBoIqJaYWYiokDB0ERETuuYGCX+m5NbElGgYGgiIqepzeZqYmYiokDB0ERETjOf4JLzNBFRoGBoIiKnWcwKzsxERAGCoYmInGYempQMTUQUIBiaiMhp7J4jokDE0ERETlOzeYmIAhBDExE5zaJ7jp8iRBQg+HFHRE5Tq25+dLB7jogCBUMTETltzqBW4r85TxMRBQqGJiJyWmJMqPhvBVMTEQUIhiYiqhVGJiIKFAxNRFQrbGgiokDB0EREtcIFe4koUDA0EVGtMDIRUaBgaCIiIiKSgKGJiGqFd88RUaBgaCKiWmFmIqJAwdBERLXCzEREgYKhiYhqhS1NRBQoGJqIqFY45QARBQqGJiKqFWYmIgoUDE1EVCtBapXcVSAi8giGJiKqkZfvaoOmdcPw3KCWcleFiMgjFIIgCHJXwh/k5+cjMjISeXl50Ol0cleHiIiIJHDm+5stTUREREQSMDQRERERScDQRERERCQBQxMRERGRBAxNRERERBIwNBERERFJwNBEREREJAFDExEREZEEDE1EREREEjA0EREREUnA0EREREQkAUMTERERkQQMTUREREQSMDQRERERSaCWuwL+QhAEAEB+fr7MNSEiIiKpKr+3K7/HHWFocpGCggIAQGJiosw1ISIiImcVFBQgMjLSYRmFICVaUbVMJhMuX76MiIgIKBQKlx47Pz8fiYmJuHDhAnQ6nUuPTdXj9ZcXr7+8eP3lx/fAvQRBQEFBARISEqBUOh61xJYmF1Eqlbjlllvc+ho6nY7/YWTE6y8vXn958frLj++B+1TXwlSJA8GJiIiIJGBoIiIiIpKAockHBAUFYf78+QgKCpK7KgGJ119evP7y4vWXH98D78GB4EREREQSsKWJiIiISAKGJiIiIiIJGJqIiIiIJGBoIiIiIpKAocnLLVu2DI0bN0ZwcDB69OiBP/74Q+4q+YWXX34ZCoXC4qdVq1bi/tLSUkyZMgV16tRBeHg4Ro8ejezsbItjnD9/HkOHDkVoaCji4uIwa9YsGAwGT5+KT0hLS8Ndd92FhIQEKBQKrF271mK/IAiYN28e6tevj5CQECQnJ+PUqVMWZa5fv44JEyZAp9MhKioKkyZNQmFhoUWZgwcPok+fPggODkZiYiIWL17s7lPzCdVd/4ceeqjK/4dBgwZZlOH1r7kFCxagW7duiIiIQFxcHEaMGIETJ05YlHHVZ86WLVvQuXNnBAUFoVmzZli5cqW7Ty+gMDR5sa+//hozZ87E/PnzsXfvXnTo0AEpKSnIycmRu2p+4bbbbkNmZqb489tvv4n7nn76aaxbtw6rV6/G1q1bcfnyZYwaNUrcbzQaMXToUJSXl2P79u345JNPsHLlSsybN0+OU/F6RUVF6NChA5YtW2Zz/+LFi/HWW29h+fLl2LlzJ8LCwpCSkoLS0lKxzIQJE3DkyBGkpqZi/fr1SEtLw+TJk8X9+fn5GDhwIBo1aoQ9e/bgtddew8svv4wVK1a4/fy8XXXXHwAGDRpk8f/hq6++stjP619zW7duxZQpU7Bjxw6kpqZCr9dj4MCBKCoqEsu44jMnIyMDQ4cORf/+/bF//37MmDEDjz76KH7++WePnq9fE8hrde/eXZgyZYr42Gg0CgkJCcKCBQtkrJV/mD9/vtChQweb+3JzcwWNRiOsXr1a3Hbs2DEBgJCeni4IgiD8+OOPglKpFLKyssQy7733nqDT6YSysjK31t3XARDWrFkjPjaZTEJ8fLzw2muvidtyc3OFoKAg4auvvhIEQRCOHj0qABB27dollvnpp58EhUIhXLp0SRAEQXj33XeF6Ohoi+s/e/ZsoWXLlm4+I99iff0FQRAefPBBYfjw4Xafw+vvWjk5OQIAYevWrYIguO4z57nnnhNuu+02i9caO3askJKS4u5TChhsafJS5eXl2LNnD5KTk8VtSqUSycnJSE9Pl7Fm/uPUqVNISEhA06ZNMWHCBJw/fx4AsGfPHuj1eotr36pVKzRs2FC89unp6WjXrh3q1asnlklJSUF+fj6OHDni2RPxcRkZGcjKyrK43pGRkejRo4fF9Y6KikLXrl3FMsnJyVAqldi5c6dYpm/fvtBqtWKZlJQUnDhxAjdu3PDQ2fiuLVu2IC4uDi1btsTf//53XLt2TdzH6+9aeXl5AICYmBgArvvMSU9PtzhGZRl+Z7gOQ5OXunr1KoxGo8V/EACoV68esrKyZKqV/+jRowdWrlyJDRs24L333kNGRgb69OmDgoICZGVlQavVIioqyuI55tc+KyvL5ntTuY+kq7xejn7Xs7KyEBcXZ7FfrVYjJiaG74kLDBo0CJ9++ik2btyIRYsWYevWrRg8eDCMRiMAXn9XMplMmDFjBm6//Xa0bdsWAFz2mWOvTH5+PkpKStxxOgFHLXcFiOQwePBg8d/t27dHjx490KhRI3zzzTcICQmRsWZEnjdu3Djx3+3atUP79u1x6623YsuWLRgwYICMNfM/U6ZMweHDhy3GUJLvYEuTl4qNjYVKpapy90R2djbi4+NlqpX/ioqKQosWLXD69GnEx8ejvLwcubm5FmXMr318fLzN96ZyH0lXeb0c/a7Hx8dXuQHCYDDg+vXrfE/coGnTpoiNjcXp06cB8Pq7ytSpU7F+/Xps3rwZt9xyi7jdVZ859srodDr+MegiDE1eSqvVokuXLti4caO4zWQyYePGjUhKSpKxZv6psLAQZ86cQf369dGlSxdoNBqLa3/ixAmcP39evPZJSUk4dOiQxRdJamoqdDod2rRp4/H6+7ImTZogPj7e4nrn5+dj586dFtc7NzcXe/bsEcts2rQJJpMJPXr0EMukpaVBr9eLZVJTU9GyZUtER0d76Gz8w8WLF3Ht2jXUr18fAK9/bQmCgKlTp2LNmjXYtGkTmjRpYrHfVZ85SUlJFseoLMPvDBeSeyQ62bdq1SohKChIWLlypXD06FFh8uTJQlRUlMXdE1QzzzzzjLBlyxYhIyND+P3334Xk5GQhNjZWyMnJEQRBEJ544gmhYcOGwqZNm4Tdu3cLSUlJQlJSkvh8g8EgtG3bVhg4cKCwf/9+YcOGDULdunWF559/Xq5T8moFBQXCvn37hH379gkAhDfeeEPYt2+fcO7cOUEQBGHhwoVCVFSU8N133wkHDx4Uhg8fLjRp0kQoKSkRjzFo0CChU6dOws6dO4XffvtNaN68uTB+/Hhxf25urlCvXj3h/vvvFw4fPiysWrVKCA0NFd5//32Pn6+3cXT9CwoKhGeffVZIT08XMjIyhF9//VXo3Lmz0Lx5c6G0tFQ8Bq9/zf39738XIiMjhS1btgiZmZniT3FxsVjGFZ85f/75pxAaGirMmjVLOHbsmLBs2TJBpVIJGzZs8Oj5+jOGJi/39ttvCw0bNhS0Wq3QvXt3YceOHXJXyS+MHTtWqF+/vqDVaoUGDRoIY8eOFU6fPi3uLykpEZ588kkhOjpaCA0NFUaOHClkZmZaHOPs2bPC4MGDhZCQECE2NlZ45plnBL1e7+lT8QmbN28WAFT5efDBBwVBqJh24KWXXhLq1asnBAUFCQMGDBBOnDhhcYxr164J48ePF8LDwwWdTic8/PDDQkFBgUWZAwcOCL179xaCgoKEBg0aCAsXLvTUKXo1R9e/uLhYGDhwoFC3bl1Bo9EIjRo1Eh577LEqf5zx+tecrWsPQPj444/FMq76zNm8ebPQsWNHQavVCk2bNrV4Dao9hSAIgqdbt4iIiIh8Dcc0EREREUnA0EREREQkAUMTERERkQQMTUREREQSMDQRERERScDQRERERCQBQxMRERGRBAxNREQSKBQKrF27Vu5qEJGMGJqIyO899NBDGDFihNzVICIfx9BEREREJAFDExEFlH79+mHatGl47rnnEBMTg/j4eLz88ssWZU6dOoW+ffsiODgYbdq0QWpqapXjXLhwAffeey+ioqIQExOD4cOH4+zZswCA48ePIzQ0FF9++aVY/ptvvkFISAiOHj3qztMjIjdiaCKigPPJJ58gLCwMO3fuxOLFi/HKK6+IwchkMmHUqFHQarXYuXMnli9fjtmzZ1s8X6/XIyUlBREREdi2bRt+//13hIeHY9CgQSgvL0erVq3w+uuv48knn8T58+dx8eJFPPHEE1i0aBHatGkjxykTkQtwwV4i8nsPPfQQcnNzsXbtWvTr1w9GoxHbtm0T93fv3h133nknFi5ciF9++QVDhw7FuXPnkJCQAADYsGEDBg8ejDVr1mDEiBH4/PPP8a9//QvHjh2DQqEAAJSXlyMqKgpr167FwIEDAQDDhg1Dfn4+tFotVCoVNmzYIJYnIt+jlrsCRESe1r59e4vH9evXR05ODgDg2LFjSExMFAMTACQlJVmUP3DgAE6fPo2IiAiL7aWlpThz5oz4+KOPPkKLFi2gVCpx5MgRBiYiH8fQREQBR6PRWDxWKBQwmUySn19YWIguXbrgiy++qLKvbt264r8PHDiAoqIiKJVKZGZmon79+jWvNBHJjqGJiMhM69atceHCBYuQs2PHDosynTt3xtdff424uDjodDqbx7l+/ToeeughvPjii8jMzMSECROwd+9ehISEuP0ciMg9OBCciMhMcnIyWrRogQcffBAHDhzAtm3b8OKLL1qUmTBhAmJjYzF8+HBs27YNGRkZ2LJlC6ZNm4aLFy8CAJ544gkkJiZi7ty5eOONN2A0GvHss8/KcUpE5CIMTUREZpRKJdasWYOSkhJ0794djz76KF599VWLMqGhoUhLS0PDhg0xatQotG7dGpMmTUJpaSl0Oh0+/fRT/Pjjj/jss8+gVqsRFhaGzz//HB988AF++uknmc6MiGqLd88RERERScCWJiIiIiIJGJqIiIiIJGBoIiIiIpKAoYmIiIhIAoYmIiIiIgkYmoiIiIgkYGgiIiIikoChiYiIiEgChiYiIiIiCRiaiIiIiCRgaCIiIiKSgKGJiIiISIL/B2Xf+jMrMJfDAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Teraz dobrze widać gdzie jest problem.\n",
        "\n",
        "W rozpatrywanym przez nas czasie Volume zwiększa się niemal 200 000 krotnie, podczas gdy wartość giełd 2-3 krotnie.\n",
        "\n",
        "W przypadku giełd zastosowanie średniej wartości nie jest złym wyjściem gdyż nie zmienia się ona drastycznie na przestrzeni czasu.\n",
        "\n",
        "W przypadku Volume sprawa jest inna, model wariuje kiedy widzi że w ciągu np. miesiąca wartość kilkukrotnie skacze od 20 tysięcy do np. 2 milionów a następnie na długi czas zatrzymuje się na jednej wartości"
      ],
      "metadata": {
        "id": "VWkC2Blr6Rda"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Musimy Zastąpić puste rekordy w inny sposób.\n",
        "\n",
        "Zastąpienie sąsiednim rekordem w tym przypadku również nie zadziała, brakujące dane występują w dwóch długich seriach więc sytuacja będzię taka sama jak przy zaastąpieniu średnią wartością - duże wahania a nastepnie brak zmian.\n",
        "\n"
      ],
      "metadata": {
        "id": "TBq01iBd7mde"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Najlepsze efekty da nam zbudowanie prostego modelu który na podstawie znanej korelacji Volume oraz ceny BTC, uzupełni brakujące dane bazując na właśnie na zmianie ceny BTC.\n",
        "\n",
        "Niestety znowu nie jest to rozwiązanie idealne, w tego typu przypadku jedynym idealnym rozwiązaniem jest posiadanie pełnych danych, jednak nie zawsze możemy na to liczyć. Istnieje możliwość że przewidując Volume na podstawie BTC, a następnie na odwrót, BTC na podstawie Volume, właściwie nie wprowadzimy żadnych nowych danych gdyż po wygenerowaniu takich danych będą one niejako tożsame.\n",
        "\n",
        "Jednakże ze szkolenia modeli w pętli wynikło, że dawanie modelowi danych, niejako tożsamych np. cen różnych walut które ostatecznie i tak są odpowiednio przeliczane na USD, przynosi efekty i poprawia działanie modelu, jest on w stanie wyciągnąć z nich to co potrzebne.\n",
        "\n",
        "Stowrzymy model do Volume a następnie sprawdzimy czy faktycznie, wygenerowane dane sprawią że model BTC+Volume będzie lepszy niż jego poprzednik\n",
        "\n"
      ],
      "metadata": {
        "id": "6abgsyaOBorp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Zrobimy to jednak w oddzielnym pliku - CRYPTO_volume_model"
      ],
      "metadata": {
        "id": "Fn2EfpYrDMGE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pobieramy uzupełnione dane Volume"
      ],
      "metadata": {
        "id": "yalrZ0UDOybQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Volume_df= pd.read_csv(\"/content/drive/MyDrive/CRYPTO/Preprocessed_data/Volume.csv\")"
      ],
      "metadata": {
        "id": "73z82iFMDLAh"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Volume_data = Volume_df.to_numpy()"
      ],
      "metadata": {
        "id": "IERwysvqWjyM"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Volume_model_indicies=[0,1,2,3,4,5]"
      ],
      "metadata": {
        "id": "7Xx2dms02wTC"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BTC_base_data=np.empty((2344,4))\n",
        "vol_data=np.empty((2344,1))\n",
        "halving_data=np.empty((2344,1))\n",
        "\n",
        "Volume_model_full_data=np.empty((2344,6))\n",
        "for x in range(2344):\n",
        "\n",
        "\n",
        "    BTC_base_data[x][0]=DATA[x][0]\n",
        "    BTC_base_data[x][1]=DATA[x][1]\n",
        "    BTC_base_data[x][2]=DATA[x][2]\n",
        "    BTC_base_data[x][3]=DATA[x][3]\n",
        "\n",
        "    vol_data[x][0]=Volume_data[x]\n",
        "\n",
        "    halving_data[x][0]=DATA[x][49]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4boZCx_P7YB",
        "outputId": "833c1b57-2487-4aa8-807e-7e908e128b98"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-50-aaace3589f43>:14: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  vol_data[x][0]=Volume_data[x]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATA.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luSiDHeqcLIR",
        "outputId": "7dee1eb3-368f-4976-d36f-f7d854aeb77c"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2344, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_scaler = MinMaxScaler()\n",
        "halving_scaler = MinMaxScaler()\n",
        "vol_scaler=MinMaxScaler()\n",
        "\n",
        "\n",
        "BTC_base_data_scaled = base_scaler.fit_transform(BTC_base_data)\n",
        "halving_data_scaled = halving_scaler.fit_transform(halving_data)\n",
        "vol_data_scaled = vol_scaler.fit_transform(vol_data)\n",
        "\n",
        "Volume_model_full_data=np.empty((2344,6))\n",
        "\n",
        "for x in range(2344):\n",
        "    Volume_model_full_data[x][0]=BTC_base_data_scaled[x][0]\n",
        "    Volume_model_full_data[x][1]=BTC_base_data_scaled[x][1]\n",
        "    Volume_model_full_data[x][2]=BTC_base_data_scaled[x][2]\n",
        "    Volume_model_full_data[x][3]=BTC_base_data_scaled[x][3]\n",
        "    Volume_model_full_data[x][4]=vol_data_scaled[x]\n",
        "    Volume_model_full_data[x][5]=halving_data_scaled[x]\n",
        "\n",
        "\n",
        "reshaped_data_X, reshaped_data_y=reshape_data_mlt_feature_changer(Volume_model_full_data, n_timesteps, Volume_model_indicies)\n",
        "\n",
        "y_scaler = MinMaxScaler()\n",
        "y_scaled = y_scaler.fit_transform(reshaped_data_y.reshape(-1, 1))\n",
        "y_scaled = y_scaled.reshape(reshaped_data_y.shape)\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(reshaped_data_X, y_scaled, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# Define the LSTM model\n",
        "volume_model = Sequential()\n",
        "volume_model.add(LSTM(128, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True))\n",
        "volume_model.add(Dropout(0.2))\n",
        "volume_model.add(LSTM(64, return_sequences=False))\n",
        "volume_model.add(Dense(1))\n",
        "\n",
        "# Compile the volume_model\n",
        "optimizer = Adam(lr=0.001)\n",
        "volume_model.compile(optimizer=optimizer, loss='mse', metrics=['mae', 'mse'])\n",
        "\n",
        "# Train the volume_model\n",
        "history = volume_model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
        "\n",
        "loss,mae,mse=volume_model.evaluate(X_test,y_test)\n",
        "\n",
        "loop_models_performance[3][0]=loss\n",
        "loop_models_performance[3][1]=mae\n",
        "loop_models_performance[3][2]=mse"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYTtlrmYPkFW",
        "outputId": "e6d6947a-607e-4b0b-950d-b5fe4ea5fa92"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-52-51a3564b16f8>:17: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  Volume_model_full_data[x][4]=vol_data_scaled[x]\n",
            "<ipython-input-52-51a3564b16f8>:18: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  Volume_model_full_data[x][5]=halving_data_scaled[x]\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "47/47 [==============================] - 10s 99ms/step - loss: 0.0082 - mae: 0.0561 - mse: 0.0082 - val_loss: 0.0013 - val_mae: 0.0223 - val_mse: 0.0013\n",
            "Epoch 2/50\n",
            "47/47 [==============================] - 3s 71ms/step - loss: 0.0014 - mae: 0.0253 - mse: 0.0014 - val_loss: 0.0011 - val_mae: 0.0214 - val_mse: 0.0011\n",
            "Epoch 3/50\n",
            "47/47 [==============================] - 4s 94ms/step - loss: 0.0012 - mae: 0.0234 - mse: 0.0012 - val_loss: 0.0011 - val_mae: 0.0197 - val_mse: 0.0011\n",
            "Epoch 4/50\n",
            "47/47 [==============================] - 4s 83ms/step - loss: 0.0011 - mae: 0.0224 - mse: 0.0011 - val_loss: 9.3903e-04 - val_mae: 0.0192 - val_mse: 9.3903e-04\n",
            "Epoch 5/50\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.0011 - mae: 0.0223 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0223 - val_mse: 0.0011\n",
            "Epoch 6/50\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.0010 - mae: 0.0213 - mse: 0.0010 - val_loss: 8.5376e-04 - val_mae: 0.0177 - val_mse: 8.5376e-04\n",
            "Epoch 7/50\n",
            "47/47 [==============================] - 5s 108ms/step - loss: 9.6667e-04 - mae: 0.0212 - mse: 9.6667e-04 - val_loss: 9.9530e-04 - val_mae: 0.0209 - val_mse: 9.9530e-04\n",
            "Epoch 8/50\n",
            "47/47 [==============================] - 3s 71ms/step - loss: 9.1414e-04 - mae: 0.0206 - mse: 9.1414e-04 - val_loss: 7.7074e-04 - val_mae: 0.0179 - val_mse: 7.7074e-04\n",
            "Epoch 9/50\n",
            "47/47 [==============================] - 3s 72ms/step - loss: 8.4027e-04 - mae: 0.0198 - mse: 8.4027e-04 - val_loss: 9.7940e-04 - val_mae: 0.0223 - val_mse: 9.7940e-04\n",
            "Epoch 10/50\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 8.3213e-04 - mae: 0.0198 - mse: 8.3213e-04 - val_loss: 7.2385e-04 - val_mae: 0.0184 - val_mse: 7.2385e-04\n",
            "Epoch 11/50\n",
            "47/47 [==============================] - 5s 107ms/step - loss: 7.4976e-04 - mae: 0.0186 - mse: 7.4976e-04 - val_loss: 9.0243e-04 - val_mae: 0.0187 - val_mse: 9.0243e-04\n",
            "Epoch 12/50\n",
            "47/47 [==============================] - 5s 103ms/step - loss: 6.9574e-04 - mae: 0.0179 - mse: 6.9574e-04 - val_loss: 6.6924e-04 - val_mae: 0.0159 - val_mse: 6.6924e-04\n",
            "Epoch 13/50\n",
            "47/47 [==============================] - 4s 76ms/step - loss: 7.5185e-04 - mae: 0.0183 - mse: 7.5185e-04 - val_loss: 6.2038e-04 - val_mae: 0.0152 - val_mse: 6.2038e-04\n",
            "Epoch 14/50\n",
            "47/47 [==============================] - 5s 105ms/step - loss: 8.0524e-04 - mae: 0.0195 - mse: 8.0524e-04 - val_loss: 5.9992e-04 - val_mae: 0.0158 - val_mse: 5.9992e-04\n",
            "Epoch 15/50\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 6.7846e-04 - mae: 0.0178 - mse: 6.7846e-04 - val_loss: 6.1157e-04 - val_mae: 0.0155 - val_mse: 6.1157e-04\n",
            "Epoch 16/50\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 6.6651e-04 - mae: 0.0175 - mse: 6.6651e-04 - val_loss: 5.6396e-04 - val_mae: 0.0154 - val_mse: 5.6396e-04\n",
            "Epoch 17/50\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 6.0318e-04 - mae: 0.0165 - mse: 6.0318e-04 - val_loss: 5.2942e-04 - val_mae: 0.0146 - val_mse: 5.2942e-04\n",
            "Epoch 18/50\n",
            "47/47 [==============================] - 5s 109ms/step - loss: 6.3203e-04 - mae: 0.0172 - mse: 6.3203e-04 - val_loss: 5.2591e-04 - val_mae: 0.0148 - val_mse: 5.2591e-04\n",
            "Epoch 19/50\n",
            "47/47 [==============================] - 4s 77ms/step - loss: 5.6759e-04 - mae: 0.0160 - mse: 5.6759e-04 - val_loss: 8.1955e-04 - val_mae: 0.0189 - val_mse: 8.1955e-04\n",
            "Epoch 20/50\n",
            "47/47 [==============================] - 3s 72ms/step - loss: 6.2554e-04 - mae: 0.0166 - mse: 6.2554e-04 - val_loss: 5.5824e-04 - val_mae: 0.0149 - val_mse: 5.5824e-04\n",
            "Epoch 21/50\n",
            "47/47 [==============================] - 4s 87ms/step - loss: 5.2596e-04 - mae: 0.0155 - mse: 5.2596e-04 - val_loss: 5.5856e-04 - val_mae: 0.0151 - val_mse: 5.5856e-04\n",
            "Epoch 22/50\n",
            "47/47 [==============================] - 5s 102ms/step - loss: 5.5461e-04 - mae: 0.0158 - mse: 5.5461e-04 - val_loss: 4.6817e-04 - val_mae: 0.0135 - val_mse: 4.6817e-04\n",
            "Epoch 23/50\n",
            "47/47 [==============================] - 3s 73ms/step - loss: 5.5407e-04 - mae: 0.0155 - mse: 5.5407e-04 - val_loss: 6.8575e-04 - val_mae: 0.0172 - val_mse: 6.8575e-04\n",
            "Epoch 24/50\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 5.0227e-04 - mae: 0.0154 - mse: 5.0227e-04 - val_loss: 4.7567e-04 - val_mae: 0.0135 - val_mse: 4.7567e-04\n",
            "Epoch 25/50\n",
            "47/47 [==============================] - 5s 108ms/step - loss: 5.2140e-04 - mae: 0.0149 - mse: 5.2140e-04 - val_loss: 4.4647e-04 - val_mae: 0.0133 - val_mse: 4.4647e-04\n",
            "Epoch 26/50\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 5.7901e-04 - mae: 0.0161 - mse: 5.7901e-04 - val_loss: 5.0554e-04 - val_mae: 0.0154 - val_mse: 5.0554e-04\n",
            "Epoch 27/50\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 4.5689e-04 - mae: 0.0141 - mse: 4.5689e-04 - val_loss: 4.3709e-04 - val_mae: 0.0132 - val_mse: 4.3709e-04\n",
            "Epoch 28/50\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 5.4381e-04 - mae: 0.0154 - mse: 5.4381e-04 - val_loss: 6.7119e-04 - val_mae: 0.0187 - val_mse: 6.7119e-04\n",
            "Epoch 29/50\n",
            "47/47 [==============================] - 5s 108ms/step - loss: 5.7974e-04 - mae: 0.0164 - mse: 5.7974e-04 - val_loss: 4.3102e-04 - val_mae: 0.0131 - val_mse: 4.3102e-04\n",
            "Epoch 30/50\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 4.8361e-04 - mae: 0.0143 - mse: 4.8361e-04 - val_loss: 4.2757e-04 - val_mae: 0.0128 - val_mse: 4.2757e-04\n",
            "Epoch 31/50\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 5.3357e-04 - mae: 0.0151 - mse: 5.3357e-04 - val_loss: 4.6418e-04 - val_mae: 0.0135 - val_mse: 4.6418e-04\n",
            "Epoch 32/50\n",
            "47/47 [==============================] - 4s 79ms/step - loss: 5.2264e-04 - mae: 0.0150 - mse: 5.2264e-04 - val_loss: 6.8811e-04 - val_mae: 0.0178 - val_mse: 6.8811e-04\n",
            "Epoch 33/50\n",
            "47/47 [==============================] - 5s 97ms/step - loss: 4.9104e-04 - mae: 0.0147 - mse: 4.9104e-04 - val_loss: 3.9909e-04 - val_mae: 0.0125 - val_mse: 3.9909e-04\n",
            "Epoch 34/50\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 4.6052e-04 - mae: 0.0141 - mse: 4.6052e-04 - val_loss: 4.0345e-04 - val_mae: 0.0130 - val_mse: 4.0345e-04\n",
            "Epoch 35/50\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 5.6156e-04 - mae: 0.0153 - mse: 5.6156e-04 - val_loss: 3.8060e-04 - val_mae: 0.0122 - val_mse: 3.8060e-04\n",
            "Epoch 36/50\n",
            "47/47 [==============================] - 4s 88ms/step - loss: 7.3283e-04 - mae: 0.0182 - mse: 7.3283e-04 - val_loss: 3.9264e-04 - val_mae: 0.0126 - val_mse: 3.9264e-04\n",
            "Epoch 37/50\n",
            "47/47 [==============================] - 4s 89ms/step - loss: 4.6013e-04 - mae: 0.0138 - mse: 4.6013e-04 - val_loss: 3.8691e-04 - val_mae: 0.0120 - val_mse: 3.8691e-04\n",
            "Epoch 38/50\n",
            "47/47 [==============================] - 4s 76ms/step - loss: 4.4108e-04 - mae: 0.0142 - mse: 4.4108e-04 - val_loss: 5.0657e-04 - val_mae: 0.0144 - val_mse: 5.0657e-04\n",
            "Epoch 39/50\n",
            "47/47 [==============================] - 3s 74ms/step - loss: 4.3944e-04 - mae: 0.0136 - mse: 4.3944e-04 - val_loss: 4.5111e-04 - val_mae: 0.0146 - val_mse: 4.5111e-04\n",
            "Epoch 40/50\n",
            "47/47 [==============================] - 6s 132ms/step - loss: 4.1946e-04 - mae: 0.0134 - mse: 4.1946e-04 - val_loss: 6.2641e-04 - val_mae: 0.0172 - val_mse: 6.2641e-04\n",
            "Epoch 41/50\n",
            "47/47 [==============================] - 4s 76ms/step - loss: 5.7432e-04 - mae: 0.0157 - mse: 5.7432e-04 - val_loss: 6.5082e-04 - val_mae: 0.0179 - val_mse: 6.5082e-04\n",
            "Epoch 42/50\n",
            "47/47 [==============================] - 3s 72ms/step - loss: 4.5308e-04 - mae: 0.0141 - mse: 4.5308e-04 - val_loss: 5.0244e-04 - val_mae: 0.0148 - val_mse: 5.0244e-04\n",
            "Epoch 43/50\n",
            "47/47 [==============================] - 4s 86ms/step - loss: 4.1017e-04 - mae: 0.0135 - mse: 4.1017e-04 - val_loss: 3.5609e-04 - val_mae: 0.0114 - val_mse: 3.5609e-04\n",
            "Epoch 44/50\n",
            "47/47 [==============================] - 5s 100ms/step - loss: 3.9561e-04 - mae: 0.0130 - mse: 3.9561e-04 - val_loss: 3.6679e-04 - val_mae: 0.0118 - val_mse: 3.6679e-04\n",
            "Epoch 45/50\n",
            "47/47 [==============================] - 3s 71ms/step - loss: 4.1686e-04 - mae: 0.0134 - mse: 4.1686e-04 - val_loss: 3.5041e-04 - val_mae: 0.0114 - val_mse: 3.5041e-04\n",
            "Epoch 46/50\n",
            "47/47 [==============================] - 3s 73ms/step - loss: 4.1879e-04 - mae: 0.0132 - mse: 4.1879e-04 - val_loss: 3.4016e-04 - val_mae: 0.0115 - val_mse: 3.4016e-04\n",
            "Epoch 47/50\n",
            "47/47 [==============================] - 5s 99ms/step - loss: 3.9241e-04 - mae: 0.0129 - mse: 3.9241e-04 - val_loss: 4.9115e-04 - val_mae: 0.0142 - val_mse: 4.9115e-04\n",
            "Epoch 48/50\n",
            "47/47 [==============================] - 4s 79ms/step - loss: 4.1826e-04 - mae: 0.0134 - mse: 4.1826e-04 - val_loss: 3.3867e-04 - val_mae: 0.0113 - val_mse: 3.3867e-04\n",
            "Epoch 49/50\n",
            "47/47 [==============================] - 3s 71ms/step - loss: 4.5573e-04 - mae: 0.0140 - mse: 4.5573e-04 - val_loss: 6.3231e-04 - val_mae: 0.0165 - val_mse: 6.3231e-04\n",
            "Epoch 50/50\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 4.4354e-04 - mae: 0.0136 - mse: 4.4354e-04 - val_loss: 5.7750e-04 - val_mae: 0.0162 - val_mse: 5.7750e-04\n",
            "15/15 [==============================] - 0s 22ms/step - loss: 4.9297e-04 - mae: 0.0149 - mse: 4.9297e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Base model  -  loss:{zero_model_performance[0]},  mae:{zero_model_performance[1]},  mse:{zero_model_performance[2]}\")\n",
        "print(f\"Volume model  -  loss:{loop_models_performance[3][0]},  mae:{loop_models_performance[3][1]},  mse:{loop_models_performance[3][2]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "le45yQYXPkDn",
        "outputId": "bccd86b7-e163-4dd6-f7a9-e68b573a2bf5"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Base model  -  loss:0.0003691406163852662,  mae:0.014907455071806908,  mse:0.0003691406163852662\n",
            "Volume model  -  loss:0.00049297307850793,  mae:0.014925513416528702,  mse:0.00049297307850793\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wyniki nie są znacząco lepsze. Musimy jednak brać pod uwagę pewien czynnik losowości. Kiedy trenujemy kilka razy ten sam model, zawsze dostaniemy lekko inne wyniki."
      ],
      "metadata": {
        "id": "kr7yJZjfZi8W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podsumowując. Ustaliliśmy że wszystkie dane poprawiają wyniki modelu.\n",
        "\n",
        "Teraz zostało nam tylko wyszkolić ostateczny model, który będzie trenowany na wszystkich dostępnych nam danych.\n",
        "\n"
      ],
      "metadata": {
        "id": "qQprDQ5SvuBq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vol_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "haDsLgqnqGUq",
        "outputId": "be307a39-66a3-4e0c-e1a5-7c6617e617cd"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2344, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for x in range(len(DATA)):\n",
        "    DATA[x][45]=vol_data[x][0]"
      ],
      "metadata": {
        "id": "HqLBFSg7i_K6"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA.shape"
      ],
      "metadata": {
        "id": "vFPh2q6lPkAV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96442370-cf8e-42f2-f06a-0d7ea61d9222"
      },
      "execution_count": 56,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2344, 50)"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_indexes=np.arange(0,50)"
      ],
      "metadata": {
        "id": "iqcLyU2e6eaf"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Co trzeba wytestować\n",
        "\n",
        "BATCH_SIZE\n",
        "\n",
        "n_timesteps\n",
        "\n",
        "Nurony\n",
        "\n",
        "Różne warstwy\n",
        "    -BiDirectional(Raczej zawsze powinno być)\n",
        "    -LSTM\n",
        "    -CONV\n",
        "    -GRU\n",
        "\n",
        "Różne funckje aktywacyjne\n",
        "    -Różne Liniowe\n",
        "    -Jakieś nieliniowe\n",
        "\n",
        "Loss value\n",
        "    -mae\n",
        "    -mse\n",
        "DODATKI tzn:\n",
        "\n",
        "DROPUT,\n",
        "L-REgularization\n",
        "\n",
        "\n",
        "Pomyśleć nad ensemble learning\n"
      ],
      "metadata": {
        "id": "DbvPeDO9D6ZL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Najpierw sprawdzimy jakie będzie najlepsze rozbudowanie modelu tzn. czy powinniśmy stworzyć prosty model z niewielką ilością neuronów czy jednak coś bardziej kompleksowego"
      ],
      "metadata": {
        "id": "-2BcVLJ44hLt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Na początek prosty model Bidirectional LSTM + DENSE(relu)\n",
        "\n",
        "Mała ilość neuronów\n",
        "\n"
      ],
      "metadata": {
        "id": "7l-sMlwgFMDE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM,Dense,Dropout,Bidirectional\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "\n",
        "scalers = [MinMaxScaler() for _ in range(DATA.shape[1])]\n",
        "\n",
        "DATA_scaled = np.hstack([scaler.fit_transform(DATA[:, [i]]) for i, scaler in enumerate(scalers)])\n",
        "\n",
        "reshaped_data_X, reshaped_data_y=reshape_data_mlt_feature_changer(DATA_scaled,n_timesteps,final_indexes)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(reshaped_data_X, reshaped_data_y, test_size=0.2, random_state=42,shuffle=False)\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE)\n",
        "\n",
        "# Use AUTOTUNE for optimization\n",
        "train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "test_dataset = test_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "\n",
        "# Define the LSTM model\n",
        "\n",
        "zero_final_model = Sequential([\n",
        "    Bidirectional(LSTM(128, return_sequences=True, dropout=0.2)),\n",
        "    LSTM(64, activation='relu', dropout=0.2, kernel_regularizer=l2(0.01)),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1)  # Output only 1 value\n",
        "])\n",
        "\n",
        "\n",
        "# Compile the zero_final_model with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.001)  # Adjust the learning rate as needed\n",
        "zero_final_model.compile(optimizer=optimizer, loss='mse',metrics=[\"mae\"])\n",
        "\n",
        "# Add a callback to reduce learning rate on plateau\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=8, min_lr=0.00001)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
        "callbacks = [reduce_lr,early_stopping]\n",
        "\n",
        "# Train the zero_final_model with callbacks\n",
        "history = zero_final_model.fit(train_dataset, epochs=500, batch_size=32, validation_data=test_dataset, callbacks=callbacks)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l711JEAtm6xK",
        "outputId": "3559b61c-003c-47d1-ad5f-eb4ea37343fb"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "58/58 [==============================] - 23s 289ms/step - loss: 1.2548 - mae: 0.0647 - val_loss: 0.5075 - val_mae: 0.2346 - lr: 0.0010\n",
            "Epoch 2/500\n",
            "58/58 [==============================] - 8s 141ms/step - loss: 0.2065 - mae: 0.0730 - val_loss: 0.1526 - val_mae: 0.2391 - lr: 0.0010\n",
            "Epoch 3/500\n",
            "58/58 [==============================] - 17s 290ms/step - loss: 0.0513 - mae: 0.0716 - val_loss: 0.1397 - val_mae: 0.2927 - lr: 0.0010\n",
            "Epoch 4/500\n",
            "58/58 [==============================] - 14s 249ms/step - loss: 0.0366 - mae: 0.0802 - val_loss: 0.1229 - val_mae: 0.2750 - lr: 0.0010\n",
            "Epoch 5/500\n",
            "58/58 [==============================] - 16s 270ms/step - loss: 0.0327 - mae: 0.0912 - val_loss: 0.1007 - val_mae: 0.2294 - lr: 0.0010\n",
            "Epoch 6/500\n",
            "58/58 [==============================] - 14s 243ms/step - loss: 0.0325 - mae: 0.0934 - val_loss: 0.0568 - val_mae: 0.1712 - lr: 0.0010\n",
            "Epoch 7/500\n",
            "58/58 [==============================] - 9s 147ms/step - loss: 0.0350 - mae: 0.1068 - val_loss: 0.0821 - val_mae: 0.2069 - lr: 0.0010\n",
            "Epoch 8/500\n",
            "58/58 [==============================] - 9s 164ms/step - loss: 0.0445 - mae: 0.1278 - val_loss: 0.0730 - val_mae: 0.1779 - lr: 0.0010\n",
            "Epoch 9/500\n",
            "58/58 [==============================] - 7s 120ms/step - loss: 0.0478 - mae: 0.1315 - val_loss: 0.1637 - val_mae: 0.3296 - lr: 0.0010\n",
            "Epoch 10/500\n",
            "58/58 [==============================] - 9s 160ms/step - loss: 0.0355 - mae: 0.0928 - val_loss: 0.1008 - val_mae: 0.2243 - lr: 0.0010\n",
            "Epoch 11/500\n",
            "58/58 [==============================] - 8s 139ms/step - loss: 0.0620 - mae: 0.1600 - val_loss: 0.0411 - val_mae: 0.1075 - lr: 0.0010\n",
            "Epoch 12/500\n",
            "58/58 [==============================] - 7s 121ms/step - loss: 0.0535 - mae: 0.1372 - val_loss: 0.0445 - val_mae: 0.1175 - lr: 0.0010\n",
            "Epoch 13/500\n",
            "58/58 [==============================] - 8s 142ms/step - loss: 0.0453 - mae: 0.1191 - val_loss: 0.0391 - val_mae: 0.1507 - lr: 0.0010\n",
            "Epoch 14/500\n",
            "58/58 [==============================] - 9s 161ms/step - loss: 0.0264 - mae: 0.1038 - val_loss: 0.0218 - val_mae: 0.1145 - lr: 0.0010\n",
            "Epoch 15/500\n",
            "58/58 [==============================] - 7s 124ms/step - loss: 0.0117 - mae: 0.0592 - val_loss: 0.0412 - val_mae: 0.1717 - lr: 0.0010\n",
            "Epoch 16/500\n",
            "58/58 [==============================] - 9s 162ms/step - loss: 0.0085 - mae: 0.0506 - val_loss: 0.0483 - val_mae: 0.1949 - lr: 0.0010\n",
            "Epoch 17/500\n",
            "58/58 [==============================] - 8s 135ms/step - loss: 0.0090 - mae: 0.0562 - val_loss: 0.0203 - val_mae: 0.1232 - lr: 0.0010\n",
            "Epoch 18/500\n",
            "58/58 [==============================] - 7s 126ms/step - loss: 0.0083 - mae: 0.0558 - val_loss: 0.0085 - val_mae: 0.0600 - lr: 0.0010\n",
            "Epoch 19/500\n",
            "58/58 [==============================] - 8s 144ms/step - loss: 0.0060 - mae: 0.0490 - val_loss: 0.0064 - val_mae: 0.0419 - lr: 0.0010\n",
            "Epoch 20/500\n",
            "58/58 [==============================] - 10s 165ms/step - loss: 0.0059 - mae: 0.0476 - val_loss: 0.0050 - val_mae: 0.0463 - lr: 0.0010\n",
            "Epoch 21/500\n",
            "58/58 [==============================] - 8s 144ms/step - loss: 0.0046 - mae: 0.0395 - val_loss: 0.0133 - val_mae: 0.0936 - lr: 0.0010\n",
            "Epoch 22/500\n",
            "58/58 [==============================] - 10s 166ms/step - loss: 0.0047 - mae: 0.0436 - val_loss: 0.0342 - val_mae: 0.1669 - lr: 0.0010\n",
            "Epoch 23/500\n",
            "58/58 [==============================] - 9s 151ms/step - loss: 0.0080 - mae: 0.0572 - val_loss: 0.0208 - val_mae: 0.1260 - lr: 0.0010\n",
            "Epoch 24/500\n",
            "58/58 [==============================] - 9s 148ms/step - loss: 0.0076 - mae: 0.0516 - val_loss: 0.0075 - val_mae: 0.0399 - lr: 0.0010\n",
            "Epoch 25/500\n",
            "58/58 [==============================] - 9s 163ms/step - loss: 0.0050 - mae: 0.0477 - val_loss: 0.0088 - val_mae: 0.0473 - lr: 0.0010\n",
            "Epoch 26/500\n",
            "58/58 [==============================] - 7s 125ms/step - loss: 0.0076 - mae: 0.0535 - val_loss: 0.0074 - val_mae: 0.0447 - lr: 0.0010\n",
            "Epoch 27/500\n",
            "58/58 [==============================] - 7s 127ms/step - loss: 0.0070 - mae: 0.0426 - val_loss: 0.0163 - val_mae: 0.1059 - lr: 0.0010\n",
            "Epoch 28/500\n",
            "58/58 [==============================] - 9s 153ms/step - loss: 0.0049 - mae: 0.0434 - val_loss: 0.0392 - val_mae: 0.1666 - lr: 0.0010\n",
            "Epoch 29/500\n",
            "58/58 [==============================] - 9s 162ms/step - loss: 0.0084 - mae: 0.0549 - val_loss: 0.0063 - val_mae: 0.0408 - lr: 2.0000e-04\n",
            "Epoch 30/500\n",
            "58/58 [==============================] - 7s 120ms/step - loss: 0.0047 - mae: 0.0401 - val_loss: 0.0075 - val_mae: 0.0711 - lr: 2.0000e-04\n",
            "Epoch 31/500\n",
            "58/58 [==============================] - 9s 154ms/step - loss: 0.0031 - mae: 0.0301 - val_loss: 0.0055 - val_mae: 0.0576 - lr: 2.0000e-04\n",
            "Epoch 32/500\n",
            "58/58 [==============================] - 9s 162ms/step - loss: 0.0029 - mae: 0.0298 - val_loss: 0.0057 - val_mae: 0.0601 - lr: 2.0000e-04\n",
            "Epoch 33/500\n",
            "58/58 [==============================] - 8s 135ms/step - loss: 0.0027 - mae: 0.0286 - val_loss: 0.0050 - val_mae: 0.0548 - lr: 2.0000e-04\n",
            "Epoch 34/500\n",
            "58/58 [==============================] - 11s 195ms/step - loss: 0.0026 - mae: 0.0277 - val_loss: 0.0050 - val_mae: 0.0551 - lr: 2.0000e-04\n",
            "Epoch 35/500\n",
            "58/58 [==============================] - 9s 163ms/step - loss: 0.0024 - mae: 0.0270 - val_loss: 0.0047 - val_mae: 0.0533 - lr: 2.0000e-04\n",
            "Epoch 36/500\n",
            "58/58 [==============================] - 7s 122ms/step - loss: 0.0024 - mae: 0.0266 - val_loss: 0.0047 - val_mae: 0.0530 - lr: 2.0000e-04\n",
            "Epoch 37/500\n",
            "58/58 [==============================] - 7s 123ms/step - loss: 0.0023 - mae: 0.0261 - val_loss: 0.0046 - val_mae: 0.0528 - lr: 2.0000e-04\n",
            "Epoch 38/500\n",
            "58/58 [==============================] - 9s 164ms/step - loss: 0.0022 - mae: 0.0257 - val_loss: 0.0042 - val_mae: 0.0488 - lr: 2.0000e-04\n",
            "Epoch 39/500\n",
            "58/58 [==============================] - 7s 123ms/step - loss: 0.0022 - mae: 0.0255 - val_loss: 0.0043 - val_mae: 0.0500 - lr: 2.0000e-04\n",
            "Epoch 40/500\n",
            "58/58 [==============================] - 8s 129ms/step - loss: 0.0021 - mae: 0.0253 - val_loss: 0.0040 - val_mae: 0.0476 - lr: 2.0000e-04\n",
            "Epoch 41/500\n",
            "58/58 [==============================] - 9s 159ms/step - loss: 0.0021 - mae: 0.0248 - val_loss: 0.0041 - val_mae: 0.0481 - lr: 2.0000e-04\n",
            "Epoch 42/500\n",
            "58/58 [==============================] - 8s 144ms/step - loss: 0.0020 - mae: 0.0244 - val_loss: 0.0039 - val_mae: 0.0471 - lr: 2.0000e-04\n",
            "Epoch 43/500\n",
            "58/58 [==============================] - 11s 178ms/step - loss: 0.0019 - mae: 0.0233 - val_loss: 0.0040 - val_mae: 0.0476 - lr: 2.0000e-04\n",
            "Epoch 44/500\n",
            "58/58 [==============================] - 11s 190ms/step - loss: 0.0019 - mae: 0.0225 - val_loss: 0.0040 - val_mae: 0.0482 - lr: 2.0000e-04\n",
            "Epoch 45/500\n",
            "58/58 [==============================] - 14s 241ms/step - loss: 0.0018 - mae: 0.0224 - val_loss: 0.0041 - val_mae: 0.0490 - lr: 2.0000e-04\n",
            "Epoch 46/500\n",
            "58/58 [==============================] - 11s 180ms/step - loss: 0.0017 - mae: 0.0215 - val_loss: 0.0040 - val_mae: 0.0480 - lr: 2.0000e-04\n",
            "Epoch 47/500\n",
            "58/58 [==============================] - 9s 151ms/step - loss: 0.0017 - mae: 0.0218 - val_loss: 0.0037 - val_mae: 0.0462 - lr: 2.0000e-04\n",
            "Epoch 48/500\n",
            "58/58 [==============================] - 7s 122ms/step - loss: 0.0017 - mae: 0.0215 - val_loss: 0.0044 - val_mae: 0.0514 - lr: 2.0000e-04\n",
            "Epoch 49/500\n",
            "58/58 [==============================] - 8s 139ms/step - loss: 0.0017 - mae: 0.0217 - val_loss: 0.0040 - val_mae: 0.0486 - lr: 2.0000e-04\n",
            "Epoch 50/500\n",
            "58/58 [==============================] - 9s 160ms/step - loss: 0.0017 - mae: 0.0218 - val_loss: 0.0042 - val_mae: 0.0501 - lr: 2.0000e-04\n",
            "Epoch 51/500\n",
            "58/58 [==============================] - 7s 123ms/step - loss: 0.0016 - mae: 0.0211 - val_loss: 0.0043 - val_mae: 0.0514 - lr: 2.0000e-04\n",
            "Epoch 52/500\n",
            "58/58 [==============================] - 9s 163ms/step - loss: 0.0016 - mae: 0.0211 - val_loss: 0.0044 - val_mae: 0.0519 - lr: 2.0000e-04\n",
            "Epoch 53/500\n",
            "58/58 [==============================] - 9s 157ms/step - loss: 0.0016 - mae: 0.0209 - val_loss: 0.0040 - val_mae: 0.0493 - lr: 2.0000e-04\n",
            "Epoch 54/500\n",
            "58/58 [==============================] - 7s 121ms/step - loss: 0.0016 - mae: 0.0207 - val_loss: 0.0046 - val_mae: 0.0540 - lr: 2.0000e-04\n",
            "Epoch 55/500\n",
            "58/58 [==============================] - 9s 146ms/step - loss: 0.0015 - mae: 0.0204 - val_loss: 0.0045 - val_mae: 0.0528 - lr: 2.0000e-04\n",
            "Epoch 56/500\n",
            "58/58 [==============================] - 10s 168ms/step - loss: 0.0015 - mae: 0.0196 - val_loss: 0.0037 - val_mae: 0.0469 - lr: 4.0000e-05\n",
            "Epoch 57/500\n",
            "58/58 [==============================] - 7s 121ms/step - loss: 0.0014 - mae: 0.0190 - val_loss: 0.0039 - val_mae: 0.0491 - lr: 4.0000e-05\n",
            "Epoch 58/500\n",
            "58/58 [==============================] - 9s 163ms/step - loss: 0.0014 - mae: 0.0191 - val_loss: 0.0039 - val_mae: 0.0486 - lr: 4.0000e-05\n",
            "Epoch 59/500\n",
            "58/58 [==============================] - 14s 235ms/step - loss: 0.0014 - mae: 0.0188 - val_loss: 0.0039 - val_mae: 0.0490 - lr: 4.0000e-05\n",
            "Epoch 60/500\n",
            "58/58 [==============================] - 14s 246ms/step - loss: 0.0014 - mae: 0.0186 - val_loss: 0.0039 - val_mae: 0.0495 - lr: 4.0000e-05\n",
            "Epoch 61/500\n",
            "58/58 [==============================] - 10s 172ms/step - loss: 0.0014 - mae: 0.0185 - val_loss: 0.0038 - val_mae: 0.0487 - lr: 4.0000e-05\n",
            "Epoch 62/500\n",
            "58/58 [==============================] - 8s 137ms/step - loss: 0.0014 - mae: 0.0186 - val_loss: 0.0039 - val_mae: 0.0493 - lr: 4.0000e-05\n",
            "Epoch 63/500\n",
            "58/58 [==============================] - 9s 165ms/step - loss: 0.0013 - mae: 0.0185 - val_loss: 0.0040 - val_mae: 0.0499 - lr: 4.0000e-05\n",
            "Epoch 64/500\n",
            "58/58 [==============================] - 8s 136ms/step - loss: 0.0013 - mae: 0.0181 - val_loss: 0.0039 - val_mae: 0.0489 - lr: 1.0000e-05\n",
            "Epoch 65/500\n",
            "58/58 [==============================] - 9s 149ms/step - loss: 0.0014 - mae: 0.0187 - val_loss: 0.0038 - val_mae: 0.0487 - lr: 1.0000e-05\n",
            "Epoch 66/500\n",
            "58/58 [==============================] - 9s 160ms/step - loss: 0.0014 - mae: 0.0185 - val_loss: 0.0038 - val_mae: 0.0486 - lr: 1.0000e-05\n",
            "Epoch 67/500\n",
            "58/58 [==============================] - 7s 121ms/step - loss: 0.0013 - mae: 0.0182 - val_loss: 0.0038 - val_mae: 0.0483 - lr: 1.0000e-05\n",
            "Epoch 68/500\n",
            "58/58 [==============================] - 9s 164ms/step - loss: 0.0014 - mae: 0.0185 - val_loss: 0.0038 - val_mae: 0.0485 - lr: 1.0000e-05\n",
            "Epoch 69/500\n",
            "58/58 [==============================] - 8s 147ms/step - loss: 0.0014 - mae: 0.0185 - val_loss: 0.0038 - val_mae: 0.0483 - lr: 1.0000e-05\n",
            "Epoch 70/500\n",
            "58/58 [==============================] - 8s 135ms/step - loss: 0.0014 - mae: 0.0184 - val_loss: 0.0038 - val_mae: 0.0485 - lr: 1.0000e-05\n",
            "Epoch 71/500\n",
            "58/58 [==============================] - 9s 160ms/step - loss: 0.0014 - mae: 0.0185 - val_loss: 0.0038 - val_mae: 0.0488 - lr: 1.0000e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zero_final_model.save(\"/content/drive/MyDrive/CRYPTO/Models/zero_final_model.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekoOe0Pinpd7",
        "outputId": "ca41b27d-b743-463b-f937-15b79f1caa35"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zero_final_model_loaded=load_model(\"/content/drive/MyDrive/CRYPTO/Models/zero_final_model.h5\")"
      ],
      "metadata": {
        "id": "swGzVPxpMIen"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zero_final_model_loaded.evaluate(X_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVjNqM-xMWl-",
        "outputId": "136fd644-9499-4dbe-c2ee-7a04b80ed837"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 2s 38ms/step - loss: 0.0037 - mae: 0.0469\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0037072766572237015, 0.04694398120045662]"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kolejny prosty model ale z dropoutem"
      ],
      "metadata": {
        "id": "7TAJsrKwouhZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM,Dense,Dropout,Bidirectional\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "\n",
        "scalers = [MinMaxScaler() for _ in range(DATA.shape[1])]\n",
        "\n",
        "DATA_scaled = np.hstack([scaler.fit_transform(DATA[:, [i]]) for i, scaler in enumerate(scalers)])\n",
        "\n",
        "reshaped_data_X, reshaped_data_y=reshape_data_mlt_feature_changer(DATA_scaled,n_timesteps,final_indexes)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(reshaped_data_X, reshaped_data_y, test_size=0.2, random_state=42,shuffle=False)\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE)\n",
        "\n",
        "# Use AUTOTUNE for optimization\n",
        "train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "test_dataset = test_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "\n",
        "# Define the LSTM model\n",
        "\n",
        "zero_dropout_final_model = Sequential([\n",
        "    Bidirectional(LSTM(128, return_sequences=True, dropout=0.2)),\n",
        "    LSTM(64, activation='relu', dropout=0.2, kernel_regularizer=l2(0.01)),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(1)  # Output only 1 value\n",
        "])\n",
        "\n",
        "\n",
        "# Compile the zero_dropout_final_model with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.001)  # Adjust the learning rate as needed\n",
        "zero_dropout_final_model.compile(optimizer=optimizer, loss='mse',metrics=[\"mae\"])\n",
        "\n",
        "# Add a callback to reduce learning rate on plateau\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=8, min_lr=0.00001)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
        "callbacks = [reduce_lr,early_stopping]\n",
        "\n",
        "# Train the zero_dropout_final_model with callbacks\n",
        "history = zero_dropout_final_model.fit(train_dataset, epochs=500, batch_size=32, validation_data=test_dataset, callbacks=callbacks)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kqy2YNj3otfk",
        "outputId": "85a9ea4d-83d1-4293-d86e-061fe17db65d"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "58/58 [==============================] - 17s 138ms/step - loss: 1.2618 - mae: 0.1031 - val_loss: 0.5117 - val_mae: 0.2534 - lr: 0.0010\n",
            "Epoch 2/500\n",
            "58/58 [==============================] - 9s 159ms/step - loss: 0.2089 - mae: 0.0828 - val_loss: 0.1426 - val_mae: 0.2332 - lr: 0.0010\n",
            "Epoch 3/500\n",
            "58/58 [==============================] - 7s 122ms/step - loss: 0.0551 - mae: 0.0903 - val_loss: 0.0792 - val_mae: 0.1960 - lr: 0.0010\n",
            "Epoch 4/500\n",
            "58/58 [==============================] - 7s 121ms/step - loss: 0.0339 - mae: 0.0856 - val_loss: 0.0827 - val_mae: 0.2108 - lr: 0.0010\n",
            "Epoch 5/500\n",
            "58/58 [==============================] - 9s 156ms/step - loss: 0.0274 - mae: 0.0812 - val_loss: 0.1126 - val_mae: 0.2654 - lr: 0.0010\n",
            "Epoch 6/500\n",
            "58/58 [==============================] - 8s 137ms/step - loss: 0.0276 - mae: 0.0845 - val_loss: 0.0775 - val_mae: 0.2082 - lr: 0.0010\n",
            "Epoch 7/500\n",
            "58/58 [==============================] - 8s 140ms/step - loss: 0.0539 - mae: 0.1391 - val_loss: 0.0363 - val_mae: 0.1122 - lr: 0.0010\n",
            "Epoch 8/500\n",
            "58/58 [==============================] - 9s 159ms/step - loss: 0.0322 - mae: 0.1016 - val_loss: 0.0530 - val_mae: 0.1441 - lr: 0.0010\n",
            "Epoch 9/500\n",
            "58/58 [==============================] - 7s 129ms/step - loss: 0.0380 - mae: 0.1129 - val_loss: 0.1214 - val_mae: 0.2815 - lr: 0.0010\n",
            "Epoch 10/500\n",
            "58/58 [==============================] - 9s 162ms/step - loss: 0.0328 - mae: 0.0953 - val_loss: 0.0366 - val_mae: 0.0970 - lr: 0.0010\n",
            "Epoch 11/500\n",
            "58/58 [==============================] - 8s 135ms/step - loss: 0.0373 - mae: 0.1200 - val_loss: 0.0237 - val_mae: 0.1122 - lr: 0.0010\n",
            "Epoch 12/500\n",
            "58/58 [==============================] - 9s 148ms/step - loss: 0.0338 - mae: 0.1152 - val_loss: 0.0241 - val_mae: 0.1214 - lr: 0.0010\n",
            "Epoch 13/500\n",
            "58/58 [==============================] - 9s 161ms/step - loss: 0.0188 - mae: 0.0793 - val_loss: 0.0202 - val_mae: 0.1171 - lr: 0.0010\n",
            "Epoch 14/500\n",
            "58/58 [==============================] - 7s 121ms/step - loss: 0.0142 - mae: 0.0708 - val_loss: 0.0247 - val_mae: 0.1314 - lr: 0.0010\n",
            "Epoch 15/500\n",
            "58/58 [==============================] - 9s 160ms/step - loss: 0.0108 - mae: 0.0618 - val_loss: 0.0492 - val_mae: 0.1970 - lr: 0.0010\n",
            "Epoch 16/500\n",
            "58/58 [==============================] - 7s 128ms/step - loss: 0.0116 - mae: 0.0661 - val_loss: 0.0251 - val_mae: 0.1406 - lr: 0.0010\n",
            "Epoch 17/500\n",
            "58/58 [==============================] - 7s 125ms/step - loss: 0.0106 - mae: 0.0607 - val_loss: 0.0100 - val_mae: 0.0619 - lr: 0.0010\n",
            "Epoch 18/500\n",
            "58/58 [==============================] - 9s 158ms/step - loss: 0.0078 - mae: 0.0553 - val_loss: 0.0053 - val_mae: 0.0421 - lr: 0.0010\n",
            "Epoch 19/500\n",
            "58/58 [==============================] - 7s 121ms/step - loss: 0.0070 - mae: 0.0508 - val_loss: 0.0110 - val_mae: 0.0802 - lr: 0.0010\n",
            "Epoch 20/500\n",
            "58/58 [==============================] - 7s 123ms/step - loss: 0.0075 - mae: 0.0544 - val_loss: 0.0495 - val_mae: 0.2061 - lr: 0.0010\n",
            "Epoch 21/500\n",
            "58/58 [==============================] - 12s 201ms/step - loss: 0.0130 - mae: 0.0721 - val_loss: 0.0150 - val_mae: 0.1004 - lr: 0.0010\n",
            "Epoch 22/500\n",
            "58/58 [==============================] - 9s 153ms/step - loss: 0.0092 - mae: 0.0594 - val_loss: 0.0161 - val_mae: 0.0790 - lr: 0.0010\n",
            "Epoch 23/500\n",
            "58/58 [==============================] - 9s 159ms/step - loss: 0.0129 - mae: 0.0696 - val_loss: 0.0088 - val_mae: 0.0497 - lr: 0.0010\n",
            "Epoch 24/500\n",
            "58/58 [==============================] - 7s 121ms/step - loss: 0.0093 - mae: 0.0578 - val_loss: 0.0171 - val_mae: 0.1059 - lr: 0.0010\n",
            "Epoch 25/500\n",
            "58/58 [==============================] - 8s 138ms/step - loss: 0.0077 - mae: 0.0527 - val_loss: 0.0266 - val_mae: 0.1433 - lr: 0.0010\n",
            "Epoch 26/500\n",
            "58/58 [==============================] - 9s 160ms/step - loss: 0.0091 - mae: 0.0562 - val_loss: 0.0074 - val_mae: 0.0390 - lr: 0.0010\n",
            "Epoch 27/500\n",
            "58/58 [==============================] - 7s 126ms/step - loss: 0.0071 - mae: 0.0517 - val_loss: 0.0060 - val_mae: 0.0477 - lr: 2.0000e-04\n",
            "Epoch 28/500\n",
            "58/58 [==============================] - 8s 145ms/step - loss: 0.0061 - mae: 0.0471 - val_loss: 0.0053 - val_mae: 0.0433 - lr: 2.0000e-04\n",
            "Epoch 29/500\n",
            "58/58 [==============================] - 9s 158ms/step - loss: 0.0059 - mae: 0.0460 - val_loss: 0.0050 - val_mae: 0.0421 - lr: 2.0000e-04\n",
            "Epoch 30/500\n",
            "58/58 [==============================] - 7s 121ms/step - loss: 0.0052 - mae: 0.0431 - val_loss: 0.0046 - val_mae: 0.0417 - lr: 2.0000e-04\n",
            "Epoch 31/500\n",
            "58/58 [==============================] - 8s 129ms/step - loss: 0.0054 - mae: 0.0433 - val_loss: 0.0045 - val_mae: 0.0428 - lr: 2.0000e-04\n",
            "Epoch 32/500\n",
            "58/58 [==============================] - 9s 161ms/step - loss: 0.0051 - mae: 0.0429 - val_loss: 0.0042 - val_mae: 0.0437 - lr: 2.0000e-04\n",
            "Epoch 33/500\n",
            "58/58 [==============================] - 9s 153ms/step - loss: 0.0052 - mae: 0.0427 - val_loss: 0.0039 - val_mae: 0.0387 - lr: 2.0000e-04\n",
            "Epoch 34/500\n",
            "58/58 [==============================] - 8s 130ms/step - loss: 0.0047 - mae: 0.0407 - val_loss: 0.0039 - val_mae: 0.0404 - lr: 2.0000e-04\n",
            "Epoch 35/500\n",
            "58/58 [==============================] - 8s 144ms/step - loss: 0.0047 - mae: 0.0409 - val_loss: 0.0038 - val_mae: 0.0387 - lr: 2.0000e-04\n",
            "Epoch 36/500\n",
            "58/58 [==============================] - 9s 162ms/step - loss: 0.0045 - mae: 0.0411 - val_loss: 0.0038 - val_mae: 0.0415 - lr: 2.0000e-04\n",
            "Epoch 37/500\n",
            "58/58 [==============================] - 7s 123ms/step - loss: 0.0049 - mae: 0.0414 - val_loss: 0.0037 - val_mae: 0.0409 - lr: 2.0000e-04\n",
            "Epoch 38/500\n",
            "58/58 [==============================] - 9s 157ms/step - loss: 0.0043 - mae: 0.0396 - val_loss: 0.0034 - val_mae: 0.0364 - lr: 2.0000e-04\n",
            "Epoch 39/500\n",
            "58/58 [==============================] - 9s 163ms/step - loss: 0.0044 - mae: 0.0394 - val_loss: 0.0033 - val_mae: 0.0387 - lr: 2.0000e-04\n",
            "Epoch 40/500\n",
            "58/58 [==============================] - 7s 126ms/step - loss: 0.0048 - mae: 0.0410 - val_loss: 0.0032 - val_mae: 0.0387 - lr: 2.0000e-04\n",
            "Epoch 41/500\n",
            "58/58 [==============================] - 8s 141ms/step - loss: 0.0044 - mae: 0.0401 - val_loss: 0.0031 - val_mae: 0.0368 - lr: 2.0000e-04\n",
            "Epoch 42/500\n",
            "58/58 [==============================] - 9s 159ms/step - loss: 0.0042 - mae: 0.0387 - val_loss: 0.0029 - val_mae: 0.0354 - lr: 2.0000e-04\n",
            "Epoch 43/500\n",
            "58/58 [==============================] - 7s 120ms/step - loss: 0.0042 - mae: 0.0391 - val_loss: 0.0029 - val_mae: 0.0348 - lr: 2.0000e-04\n",
            "Epoch 44/500\n",
            "58/58 [==============================] - 9s 159ms/step - loss: 0.0043 - mae: 0.0390 - val_loss: 0.0032 - val_mae: 0.0390 - lr: 2.0000e-04\n",
            "Epoch 45/500\n",
            "58/58 [==============================] - 7s 120ms/step - loss: 0.0040 - mae: 0.0379 - val_loss: 0.0031 - val_mae: 0.0363 - lr: 2.0000e-04\n",
            "Epoch 46/500\n",
            "58/58 [==============================] - 7s 121ms/step - loss: 0.0042 - mae: 0.0383 - val_loss: 0.0031 - val_mae: 0.0386 - lr: 2.0000e-04\n",
            "Epoch 47/500\n",
            "58/58 [==============================] - 9s 163ms/step - loss: 0.0043 - mae: 0.0384 - val_loss: 0.0028 - val_mae: 0.0354 - lr: 2.0000e-04\n",
            "Epoch 48/500\n",
            "58/58 [==============================] - 7s 121ms/step - loss: 0.0042 - mae: 0.0396 - val_loss: 0.0033 - val_mae: 0.0413 - lr: 2.0000e-04\n",
            "Epoch 49/500\n",
            "58/58 [==============================] - 8s 131ms/step - loss: 0.0042 - mae: 0.0395 - val_loss: 0.0027 - val_mae: 0.0333 - lr: 2.0000e-04\n",
            "Epoch 50/500\n",
            "58/58 [==============================] - 11s 198ms/step - loss: 0.0043 - mae: 0.0392 - val_loss: 0.0036 - val_mae: 0.0443 - lr: 2.0000e-04\n",
            "Epoch 51/500\n",
            "58/58 [==============================] - 10s 166ms/step - loss: 0.0044 - mae: 0.0390 - val_loss: 0.0027 - val_mae: 0.0332 - lr: 2.0000e-04\n",
            "Epoch 52/500\n",
            "58/58 [==============================] - 8s 144ms/step - loss: 0.0040 - mae: 0.0381 - val_loss: 0.0035 - val_mae: 0.0437 - lr: 2.0000e-04\n",
            "Epoch 53/500\n",
            "58/58 [==============================] - 8s 138ms/step - loss: 0.0043 - mae: 0.0395 - val_loss: 0.0030 - val_mae: 0.0390 - lr: 2.0000e-04\n",
            "Epoch 54/500\n",
            "58/58 [==============================] - 9s 161ms/step - loss: 0.0041 - mae: 0.0382 - val_loss: 0.0026 - val_mae: 0.0336 - lr: 2.0000e-04\n",
            "Epoch 55/500\n",
            "58/58 [==============================] - 7s 120ms/step - loss: 0.0039 - mae: 0.0374 - val_loss: 0.0033 - val_mae: 0.0413 - lr: 2.0000e-04\n",
            "Epoch 56/500\n",
            "58/58 [==============================] - 9s 161ms/step - loss: 0.0038 - mae: 0.0370 - val_loss: 0.0031 - val_mae: 0.0405 - lr: 2.0000e-04\n",
            "Epoch 57/500\n",
            "58/58 [==============================] - 9s 161ms/step - loss: 0.0041 - mae: 0.0381 - val_loss: 0.0025 - val_mae: 0.0340 - lr: 2.0000e-04\n",
            "Epoch 58/500\n",
            "58/58 [==============================] - 7s 122ms/step - loss: 0.0038 - mae: 0.0371 - val_loss: 0.0037 - val_mae: 0.0446 - lr: 2.0000e-04\n",
            "Epoch 59/500\n",
            "58/58 [==============================] - 9s 164ms/step - loss: 0.0039 - mae: 0.0379 - val_loss: 0.0029 - val_mae: 0.0389 - lr: 2.0000e-04\n",
            "Epoch 60/500\n",
            "58/58 [==============================] - 7s 124ms/step - loss: 0.0037 - mae: 0.0374 - val_loss: 0.0026 - val_mae: 0.0354 - lr: 2.0000e-04\n",
            "Epoch 61/500\n",
            "58/58 [==============================] - 9s 161ms/step - loss: 0.0037 - mae: 0.0374 - val_loss: 0.0027 - val_mae: 0.0371 - lr: 2.0000e-04\n",
            "Epoch 62/500\n",
            "58/58 [==============================] - 9s 156ms/step - loss: 0.0037 - mae: 0.0370 - val_loss: 0.0033 - val_mae: 0.0427 - lr: 2.0000e-04\n",
            "Epoch 63/500\n",
            "58/58 [==============================] - 7s 122ms/step - loss: 0.0039 - mae: 0.0386 - val_loss: 0.0029 - val_mae: 0.0389 - lr: 4.0000e-05\n",
            "Epoch 64/500\n",
            "58/58 [==============================] - 9s 160ms/step - loss: 0.0040 - mae: 0.0383 - val_loss: 0.0028 - val_mae: 0.0380 - lr: 4.0000e-05\n",
            "Epoch 65/500\n",
            "58/58 [==============================] - 8s 139ms/step - loss: 0.0037 - mae: 0.0363 - val_loss: 0.0028 - val_mae: 0.0375 - lr: 4.0000e-05\n",
            "Epoch 66/500\n",
            "58/58 [==============================] - 9s 149ms/step - loss: 0.0038 - mae: 0.0368 - val_loss: 0.0028 - val_mae: 0.0377 - lr: 4.0000e-05\n",
            "Epoch 67/500\n",
            "58/58 [==============================] - 9s 163ms/step - loss: 0.0038 - mae: 0.0374 - val_loss: 0.0029 - val_mae: 0.0389 - lr: 4.0000e-05\n",
            "Epoch 68/500\n",
            "58/58 [==============================] - 7s 122ms/step - loss: 0.0036 - mae: 0.0362 - val_loss: 0.0029 - val_mae: 0.0387 - lr: 4.0000e-05\n",
            "Epoch 69/500\n",
            "58/58 [==============================] - 9s 163ms/step - loss: 0.0037 - mae: 0.0357 - val_loss: 0.0029 - val_mae: 0.0385 - lr: 4.0000e-05\n",
            "Epoch 70/500\n",
            "58/58 [==============================] - 8s 132ms/step - loss: 0.0036 - mae: 0.0362 - val_loss: 0.0028 - val_mae: 0.0376 - lr: 4.0000e-05\n",
            "Epoch 71/500\n",
            "58/58 [==============================] - 7s 123ms/step - loss: 0.0035 - mae: 0.0368 - val_loss: 0.0027 - val_mae: 0.0370 - lr: 1.0000e-05\n",
            "Epoch 72/500\n",
            "58/58 [==============================] - 8s 143ms/step - loss: 0.0033 - mae: 0.0348 - val_loss: 0.0027 - val_mae: 0.0370 - lr: 1.0000e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zero_dropout_final_model.save(\"/content/drive/MyDrive/CRYPTO/Models/zero_dropout_final_model.h5\")"
      ],
      "metadata": {
        "id": "mfvCKMtdpXq9"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zero_dropout_final_model_loaded=load_model(\"/content/drive/MyDrive/CRYPTO/Models/zero_dropout_final_model.h5\")"
      ],
      "metadata": {
        "id": "dNwq7iSfMn6u"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zero_dropout_final_model_loaded.evaluate(X_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0ePLqhdM_Gi",
        "outputId": "186e6d86-ace9-4685-8142-f9dd05d10ad6"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 2s 73ms/step - loss: 0.0025 - mae: 0.0340\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0025142463855445385, 0.033994052559137344]"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Troche więcej neuronów"
      ],
      "metadata": {
        "id": "WfN55uMxn9a7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM,Dense,Dropout,Bidirectional\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "\n",
        "scalers = [MinMaxScaler() for _ in range(DATA.shape[1])]\n",
        "\n",
        "DATA_scaled = np.hstack([scaler.fit_transform(DATA[:, [i]]) for i, scaler in enumerate(scalers)])\n",
        "\n",
        "reshaped_data_X, reshaped_data_y=reshape_data_mlt_feature_changer(DATA_scaled,n_timesteps,final_indexes)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(reshaped_data_X, reshaped_data_y, test_size=0.2, random_state=42,shuffle=False)\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE)\n",
        "\n",
        "# Use AUTOTUNE for optimization\n",
        "train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "test_dataset = test_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "\n",
        "# Define the LSTM model\n",
        "first_final_model = Sequential([\n",
        "    Bidirectional(LSTM(256, return_sequences=True, dropout=0.2, kernel_regularizer=l2(0.01)),\n",
        "                  input_shape=(n_timesteps, n_features)),\n",
        "    Bidirectional(LSTM(128, return_sequences=True, dropout=0.2, kernel_regularizer=l2(0.01))),\n",
        "    LSTM(64, activation='relu', dropout=0.2, kernel_regularizer=l2(0.01), return_sequences=True),\n",
        "    LSTM(32, activation='relu', dropout=0.2, kernel_regularizer=l2(0.01)),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1)  # Output only 1 value\n",
        "])\n",
        "\n",
        "# Compile the first_final_model with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.001)  # Adjust the learning rate as needed\n",
        "first_final_model.compile(optimizer=optimizer, loss='mse',metrics=[\"mae\"])\n",
        "\n",
        "# Add a callback to reduce learning rate on plateau\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=8, min_lr=0.00001)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
        "callbacks = [reduce_lr,early_stopping]\n",
        "\n",
        "# Train the first_final_model with callbacks\n",
        "# history = first_final_model.fit(train_dataset, epochs=500, batch_size=32, validation_data=test_dataset, callbacks=callbacks)\n"
      ],
      "metadata": {
        "id": "IlgS9gzmPj-x"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mae-0.0112\n",
        "# val_mae-0.0432"
      ],
      "metadata": {
        "id": "0UNOBum7PCpF"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# first_final_model.save(\"/content/drive/MyDrive/CRYPTO/Models/first_final_model.h5\")"
      ],
      "metadata": {
        "id": "t9bwhtE3ai9w"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_final_model_lodaed=load_model(\"/content/drive/MyDrive/CRYPTO/Models/first_final_model.h5\")"
      ],
      "metadata": {
        "id": "NEaXr_3Ijgvd"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_final_model_lodaed.evaluate(X_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SgrdxJ8cjuHF",
        "outputId": "2a04d8a4-572a-42d2-8ce1-c3351b644f44"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 8s 195ms/step - loss: 0.0595 - mae: 0.1621\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.05950476601719856, 0.1620994210243225]"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wyniki na danych testowych są znacznie gorsze niż na danych treningowych.\n",
        "\n",
        "Znowu powinniśmy dodać Droput"
      ],
      "metadata": {
        "id": "lqCjRqkAC9Rw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM,Dense,Dropout,Bidirectional\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "\n",
        "scalers = [MinMaxScaler() for _ in range(DATA.shape[1])]\n",
        "\n",
        "DATA_scaled = np.hstack([scaler.fit_transform(DATA[:, [i]]) for i, scaler in enumerate(scalers)])\n",
        "\n",
        "reshaped_data_X, reshaped_data_y=reshape_data_mlt_feature_changer(DATA_scaled,n_timesteps,final_indexes)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(reshaped_data_X, reshaped_data_y, test_size=0.2, random_state=42,shuffle=False)\n",
        "\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE)\n",
        "\n",
        "# Use AUTOTUNE for optimization\n",
        "train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "test_dataset = test_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "\n",
        "# Define the LSTM model\n",
        "first_dropout_final_model = Sequential([\n",
        "    Bidirectional(LSTM(512, return_sequences=True, dropout=0.2, kernel_regularizer=l2(0.01)),\n",
        "                  input_shape=(n_timesteps, n_features)),\n",
        "    Bidirectional(LSTM(256, return_sequences=True, dropout=0.2, kernel_regularizer=l2(0.01))),\n",
        "    Bidirectional(LSTM(128, return_sequences=True, dropout=0.2, kernel_regularizer=l2(0.01))),\n",
        "    LSTM(64, activation='relu', dropout=0.2, kernel_regularizer=l2(0.01), return_sequences=True),\n",
        "    LSTM(32, activation='relu', dropout=0.2, kernel_regularizer=l2(0.01)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(1)  # Output only 1 value\n",
        "])\n",
        "\n",
        "\n",
        "# Compile the first_dropout_final_model with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.001)  # Adjust the learning rate as needed\n",
        "first_dropout_final_model.compile(optimizer=optimizer, loss='mse',metrics=[\"mae\"])\n",
        "\n",
        "# Add a callback to reduce learning rate on plateau\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=8, min_lr=0.00001)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
        "callbacks = [reduce_lr,early_stopping]\n",
        "\n",
        "# Train the first_dropout_final_model with callbacks\n",
        "# history = first_dropout_final_model.fit(train_dataset, epochs=500, batch_size=32, validation_data=test_dataset, callbacks=callbacks)\n"
      ],
      "metadata": {
        "id": "uFtx-fM6Pj7-"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# first_dropout_final_model.save(\"/content/drive/MyDrive/CRYPTO/Models/first_dropout_final_model.h5\")"
      ],
      "metadata": {
        "id": "5zk0MQW3DOcK"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_dropout_final_model_lodaed=load_model(\"/content/drive/MyDrive/CRYPTO/Models/first_dropout_final_model.h5\")"
      ],
      "metadata": {
        "id": "h6ullw8ZTHtx"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_dropout_final_model_lodaed.evaluate(X_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sS9QbIW6TcWq",
        "outputId": "8dfb9af6-f6f8-49da-c612-a920d973b8c1"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 10s 497ms/step - loss: 0.0746 - mae: 0.2000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.07459024339914322, 0.20000162720680237]"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Teraz wiadomo jak rozbudowany powinien byc model, zbyt skomplikowany zamiast dostrzegac nowe cechy będzie nauczy się tożsamości danych treningowych (overfitting)\n",
        "\n",
        "Teraz budujemy model o podobnej kompleksowości co najlepiej sprawujący sie model.\n",
        "\n",
        "\n",
        "Teraz powinniśmy sprawdzić jaki BATCH_SIZE będzie najefektywniejszy."
      ],
      "metadata": {
        "id": "8t4tT9ZLsOpP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Duża liczba neuronów niestety nie pomogła z użytkowaniem danych z modeli rozszerzonych, w takim wypadku powinniśmy zrezygnować z używania tych danych"
      ],
      "metadata": {
        "id": "uwYjsQ0qIxak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_indexes=[0,1,2,3,7,11,15,19,23,24,28,32,36,40,44,45,46,47,48,49]"
      ],
      "metadata": {
        "id": "MPIIfCfKPj6R"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "\n",
        "scalers = [MinMaxScaler() for _ in range(DATA.shape[1])]\n",
        "\n",
        "DATA_scaled = np.hstack([scaler.fit_transform(DATA[:, [i]]) for i, scaler in enumerate(scalers)])\n",
        "\n",
        "reshaped_data_X, reshaped_data_y=reshape_data_mlt_feature_changer(DATA_scaled,n_timesteps,final_indexes)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(reshaped_data_X, reshaped_data_y, test_size=0.2, random_state=42,shuffle=False)\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
        "\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE)\n",
        "\n",
        "train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "test_dataset = test_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "\n",
        "\n",
        "small_batches_model = Sequential([\n",
        "    Bidirectional(LSTM(128, return_sequences=True, dropout=0.2)),\n",
        "    LSTM(64, activation='relu', dropout=0.2, kernel_regularizer=l2(0.01)),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "small_batches_model.compile(optimizer=optimizer, loss='mse',metrics=[\"mae\"])\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=8, min_lr=0.00001)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
        "callbacks = [reduce_lr,early_stopping]\n",
        "\n",
        "history = small_batches_model.fit(train_dataset, epochs=500, batch_size=32, validation_data=test_dataset, callbacks=callbacks)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTW7KErvKNEH",
        "outputId": "81dc25f5-c8a8-4bfe-8a48-ef1028f59a36"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "58/58 [==============================] - 24s 174ms/step - loss: 1.2347 - mae: 0.0776 - val_loss: 0.4839 - val_mae: 0.2304 - lr: 0.0010\n",
            "Epoch 2/500\n",
            "58/58 [==============================] - 7s 117ms/step - loss: 0.2014 - mae: 0.0857 - val_loss: 0.0729 - val_mae: 0.0744 - lr: 0.0010\n",
            "Epoch 3/500\n",
            "58/58 [==============================] - 12s 205ms/step - loss: 0.0497 - mae: 0.0859 - val_loss: 0.0997 - val_mae: 0.2310 - lr: 0.0010\n",
            "Epoch 4/500\n",
            "58/58 [==============================] - 12s 206ms/step - loss: 0.0301 - mae: 0.0759 - val_loss: 0.1237 - val_mae: 0.2750 - lr: 0.0010\n",
            "Epoch 5/500\n",
            "58/58 [==============================] - 12s 201ms/step - loss: 0.0300 - mae: 0.0881 - val_loss: 0.0517 - val_mae: 0.1359 - lr: 0.0010\n",
            "Epoch 6/500\n",
            "58/58 [==============================] - 14s 249ms/step - loss: 0.0417 - mae: 0.1253 - val_loss: 0.0230 - val_mae: 0.0865 - lr: 0.0010\n",
            "Epoch 7/500\n",
            "58/58 [==============================] - 13s 228ms/step - loss: 0.0387 - mae: 0.1234 - val_loss: 0.0186 - val_mae: 0.0900 - lr: 0.0010\n",
            "Epoch 8/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.0283 - mae: 0.1079 - val_loss: 0.0212 - val_mae: 0.1209 - lr: 0.0010\n",
            "Epoch 9/500\n",
            "58/58 [==============================] - 14s 234ms/step - loss: 0.0153 - mae: 0.0744 - val_loss: 0.0196 - val_mae: 0.1156 - lr: 0.0010\n",
            "Epoch 10/500\n",
            "58/58 [==============================] - 15s 264ms/step - loss: 0.0084 - mae: 0.0471 - val_loss: 0.0262 - val_mae: 0.1403 - lr: 0.0010\n",
            "Epoch 11/500\n",
            "58/58 [==============================] - 14s 238ms/step - loss: 0.0066 - mae: 0.0442 - val_loss: 0.0409 - val_mae: 0.1797 - lr: 0.0010\n",
            "Epoch 12/500\n",
            "58/58 [==============================] - 10s 167ms/step - loss: 0.0069 - mae: 0.0473 - val_loss: 0.0264 - val_mae: 0.1371 - lr: 0.0010\n",
            "Epoch 13/500\n",
            "58/58 [==============================] - 9s 156ms/step - loss: 0.0077 - mae: 0.0523 - val_loss: 0.0051 - val_mae: 0.0473 - lr: 0.0010\n",
            "Epoch 14/500\n",
            "58/58 [==============================] - 7s 118ms/step - loss: 0.0048 - mae: 0.0395 - val_loss: 0.0049 - val_mae: 0.0386 - lr: 0.0010\n",
            "Epoch 15/500\n",
            "58/58 [==============================] - 8s 128ms/step - loss: 0.0049 - mae: 0.0395 - val_loss: 0.0097 - val_mae: 0.0544 - lr: 0.0010\n",
            "Epoch 16/500\n",
            "58/58 [==============================] - 9s 156ms/step - loss: 0.0053 - mae: 0.0434 - val_loss: 0.0073 - val_mae: 0.0634 - lr: 0.0010\n",
            "Epoch 17/500\n",
            "58/58 [==============================] - 7s 127ms/step - loss: 0.0049 - mae: 0.0438 - val_loss: 0.0074 - val_mae: 0.0663 - lr: 0.0010\n",
            "Epoch 18/500\n",
            "58/58 [==============================] - 7s 119ms/step - loss: 0.0035 - mae: 0.0358 - val_loss: 0.0027 - val_mae: 0.0302 - lr: 0.0010\n",
            "Epoch 19/500\n",
            "58/58 [==============================] - 9s 157ms/step - loss: 0.0031 - mae: 0.0337 - val_loss: 0.0038 - val_mae: 0.0435 - lr: 0.0010\n",
            "Epoch 20/500\n",
            "58/58 [==============================] - 7s 118ms/step - loss: 0.0048 - mae: 0.0425 - val_loss: 0.0084 - val_mae: 0.0594 - lr: 0.0010\n",
            "Epoch 21/500\n",
            "58/58 [==============================] - 7s 117ms/step - loss: 0.0046 - mae: 0.0396 - val_loss: 0.0050 - val_mae: 0.0456 - lr: 0.0010\n",
            "Epoch 22/500\n",
            "58/58 [==============================] - 9s 154ms/step - loss: 0.0040 - mae: 0.0376 - val_loss: 0.0039 - val_mae: 0.0417 - lr: 0.0010\n",
            "Epoch 23/500\n",
            "58/58 [==============================] - 7s 121ms/step - loss: 0.0034 - mae: 0.0352 - val_loss: 0.0054 - val_mae: 0.0572 - lr: 0.0010\n",
            "Epoch 24/500\n",
            "58/58 [==============================] - 9s 160ms/step - loss: 0.0035 - mae: 0.0347 - val_loss: 0.0050 - val_mae: 0.0547 - lr: 0.0010\n",
            "Epoch 25/500\n",
            "58/58 [==============================] - 8s 135ms/step - loss: 0.0037 - mae: 0.0380 - val_loss: 0.0070 - val_mae: 0.0678 - lr: 0.0010\n",
            "Epoch 26/500\n",
            "58/58 [==============================] - 7s 127ms/step - loss: 0.0040 - mae: 0.0405 - val_loss: 0.0057 - val_mae: 0.0577 - lr: 0.0010\n",
            "Epoch 27/500\n",
            "58/58 [==============================] - 9s 155ms/step - loss: 0.0039 - mae: 0.0364 - val_loss: 0.0166 - val_mae: 0.1119 - lr: 2.0000e-04\n",
            "Epoch 28/500\n",
            "58/58 [==============================] - 7s 115ms/step - loss: 0.0045 - mae: 0.0394 - val_loss: 0.0048 - val_mae: 0.0469 - lr: 2.0000e-04\n",
            "Epoch 29/500\n",
            "58/58 [==============================] - 9s 157ms/step - loss: 0.0029 - mae: 0.0332 - val_loss: 0.0080 - val_mae: 0.0770 - lr: 2.0000e-04\n",
            "Epoch 30/500\n",
            "58/58 [==============================] - 8s 146ms/step - loss: 0.0026 - mae: 0.0297 - val_loss: 0.0064 - val_mae: 0.0656 - lr: 2.0000e-04\n",
            "Epoch 31/500\n",
            "58/58 [==============================] - 7s 126ms/step - loss: 0.0024 - mae: 0.0279 - val_loss: 0.0050 - val_mae: 0.0563 - lr: 2.0000e-04\n",
            "Epoch 32/500\n",
            "58/58 [==============================] - 9s 149ms/step - loss: 0.0024 - mae: 0.0285 - val_loss: 0.0059 - val_mae: 0.0635 - lr: 2.0000e-04\n",
            "Epoch 33/500\n",
            "58/58 [==============================] - 9s 151ms/step - loss: 0.0023 - mae: 0.0277 - val_loss: 0.0050 - val_mae: 0.0570 - lr: 2.0000e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "small_batches_model.save(\"/content/drive/MyDrive/CRYPTO/Models/small_batches_model.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5QgEuUnV8vg",
        "outputId": "44fadec6-9b0c-47fa-8d48-15f3c4c887e5"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "small_batches_model_loaded=load_model(\"/content/drive/MyDrive/CRYPTO/Models/small_batches_model.h5\")"
      ],
      "metadata": {
        "id": "mn0T6lYNPj3X"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "small_batches_model_loaded.evaluate(X_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHS2hIz3isYd",
        "outputId": "376113d9-98da-495c-9df2-53773dbc6c5d"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 4s 81ms/step - loss: 0.0027 - mae: 0.0302\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.002733752829954028, 0.030241791158914566]"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Zwiększamy BATCH_SIZE"
      ],
      "metadata": {
        "id": "f0e8vFEHWaEp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "scalers = [MinMaxScaler() for _ in range(DATA.shape[1])]\n",
        "\n",
        "DATA_scaled = np.hstack([scaler.fit_transform(DATA[:, [i]]) for i, scaler in enumerate(scalers)])\n",
        "\n",
        "reshaped_data_X, reshaped_data_y=reshape_data_mlt_feature_changer(DATA_scaled,n_timesteps,final_indexes)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(reshaped_data_X, reshaped_data_y, test_size=0.2, random_state=42,shuffle=False)\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
        "\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE)\n",
        "\n",
        "# Use AUTOTUNE for optimization\n",
        "train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "test_dataset = test_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "\n",
        "# Define the LSTM model\n",
        "\n",
        "medium_batches_model = Sequential([\n",
        "    Bidirectional(LSTM(128, return_sequences=True, dropout=0.2)),\n",
        "    LSTM(64, activation='relu', dropout=0.2, kernel_regularizer=l2(0.01)),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1)  # Output only 1 value\n",
        "])\n",
        "\n",
        "\n",
        "# Compile the medium_batches_model with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.001)  # Adjust the learning rate as needed\n",
        "medium_batches_model.compile(optimizer=optimizer, loss='mse',metrics=[\"mae\"])\n",
        "\n",
        "# Add a callback to reduce learning rate on plateau\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=8, min_lr=0.00001)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
        "callbacks = [reduce_lr,early_stopping]\n",
        "\n",
        "# Train the medium_batches_model with callbacks\n",
        "history = medium_batches_model.fit(train_dataset, epochs=500, batch_size=64, validation_data=test_dataset, callbacks=callbacks)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qj7qzwhtWTF_",
        "outputId": "25613f58-49d8-458d-9700-ed27149c8447"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "29/29 [==============================] - 15s 242ms/step - loss: 1.7695 - mae: 0.0763 - val_loss: 1.1406 - val_mae: 0.1802 - lr: 0.0010\n",
            "Epoch 2/500\n",
            "29/29 [==============================] - 5s 173ms/step - loss: 0.7468 - mae: 0.0893 - val_loss: 0.4791 - val_mae: 0.1454 - lr: 0.0010\n",
            "Epoch 3/500\n",
            "29/29 [==============================] - 7s 238ms/step - loss: 0.3296 - mae: 0.1266 - val_loss: 0.1947 - val_mae: 0.0800 - lr: 0.0010\n",
            "Epoch 4/500\n",
            "29/29 [==============================] - 5s 179ms/step - loss: 0.1654 - mae: 0.1177 - val_loss: 0.1377 - val_mae: 0.2176 - lr: 0.0010\n",
            "Epoch 5/500\n",
            "29/29 [==============================] - 7s 236ms/step - loss: 0.0706 - mae: 0.0486 - val_loss: 0.0503 - val_mae: 0.0252 - lr: 0.0010\n",
            "Epoch 6/500\n",
            "29/29 [==============================] - 5s 162ms/step - loss: 0.0430 - mae: 0.0451 - val_loss: 0.0333 - val_mae: 0.0368 - lr: 0.0010\n",
            "Epoch 7/500\n",
            "29/29 [==============================] - 7s 253ms/step - loss: 0.0343 - mae: 0.0636 - val_loss: 0.0473 - val_mae: 0.1515 - lr: 0.0010\n",
            "Epoch 8/500\n",
            "29/29 [==============================] - 5s 178ms/step - loss: 0.0220 - mae: 0.0343 - val_loss: 0.0397 - val_mae: 0.1349 - lr: 0.0010\n",
            "Epoch 9/500\n",
            "29/29 [==============================] - 7s 250ms/step - loss: 0.0219 - mae: 0.0552 - val_loss: 0.0153 - val_mae: 0.0258 - lr: 0.0010\n",
            "Epoch 10/500\n",
            "29/29 [==============================] - 5s 166ms/step - loss: 0.0145 - mae: 0.0312 - val_loss: 0.0225 - val_mae: 0.0811 - lr: 0.0010\n",
            "Epoch 11/500\n",
            "29/29 [==============================] - 7s 240ms/step - loss: 0.0196 - mae: 0.0678 - val_loss: 0.0216 - val_mae: 0.1066 - lr: 0.0010\n",
            "Epoch 12/500\n",
            "29/29 [==============================] - 5s 187ms/step - loss: 0.0124 - mae: 0.0478 - val_loss: 0.0195 - val_mae: 0.1005 - lr: 0.0010\n",
            "Epoch 13/500\n",
            "29/29 [==============================] - 7s 239ms/step - loss: 0.0088 - mae: 0.0301 - val_loss: 0.0094 - val_mae: 0.0466 - lr: 0.0010\n",
            "Epoch 14/500\n",
            "29/29 [==============================] - 6s 213ms/step - loss: 0.0076 - mae: 0.0296 - val_loss: 0.0073 - val_mae: 0.0281 - lr: 0.0010\n",
            "Epoch 15/500\n",
            "29/29 [==============================] - 5s 173ms/step - loss: 0.0064 - mae: 0.0283 - val_loss: 0.0069 - val_mae: 0.0322 - lr: 0.0010\n",
            "Epoch 16/500\n",
            "29/29 [==============================] - 7s 245ms/step - loss: 0.0091 - mae: 0.0478 - val_loss: 0.0100 - val_mae: 0.0710 - lr: 0.0010\n",
            "Epoch 17/500\n",
            "29/29 [==============================] - 5s 168ms/step - loss: 0.0077 - mae: 0.0419 - val_loss: 0.0219 - val_mae: 0.1244 - lr: 0.0010\n",
            "Epoch 18/500\n",
            "29/29 [==============================] - 7s 246ms/step - loss: 0.0053 - mae: 0.0298 - val_loss: 0.0195 - val_mae: 0.1134 - lr: 0.0010\n",
            "Epoch 19/500\n",
            "29/29 [==============================] - 5s 169ms/step - loss: 0.0104 - mae: 0.0575 - val_loss: 0.0060 - val_mae: 0.0321 - lr: 0.0010\n",
            "Epoch 20/500\n",
            "29/29 [==============================] - 9s 304ms/step - loss: 0.0058 - mae: 0.0319 - val_loss: 0.0185 - val_mae: 0.0889 - lr: 0.0010\n",
            "Epoch 21/500\n",
            "29/29 [==============================] - 11s 375ms/step - loss: 0.0135 - mae: 0.0686 - val_loss: 0.0152 - val_mae: 0.1047 - lr: 0.0010\n",
            "Epoch 22/500\n",
            "29/29 [==============================] - 11s 371ms/step - loss: 0.0076 - mae: 0.0527 - val_loss: 0.0151 - val_mae: 0.1020 - lr: 0.0010\n",
            "Epoch 23/500\n",
            "29/29 [==============================] - 12s 401ms/step - loss: 0.0047 - mae: 0.0337 - val_loss: 0.0059 - val_mae: 0.0483 - lr: 0.0010\n",
            "Epoch 24/500\n",
            "29/29 [==============================] - 7s 238ms/step - loss: 0.0047 - mae: 0.0348 - val_loss: 0.0054 - val_mae: 0.0376 - lr: 0.0010\n",
            "Epoch 25/500\n",
            "29/29 [==============================] - 5s 186ms/step - loss: 0.0039 - mae: 0.0316 - val_loss: 0.0047 - val_mae: 0.0348 - lr: 0.0010\n",
            "Epoch 26/500\n",
            "29/29 [==============================] - 5s 163ms/step - loss: 0.0075 - mae: 0.0524 - val_loss: 0.0148 - val_mae: 0.1047 - lr: 0.0010\n",
            "Epoch 27/500\n",
            "29/29 [==============================] - 7s 239ms/step - loss: 0.0035 - mae: 0.0278 - val_loss: 0.0090 - val_mae: 0.0738 - lr: 0.0010\n",
            "Epoch 28/500\n",
            "29/29 [==============================] - 5s 174ms/step - loss: 0.0038 - mae: 0.0333 - val_loss: 0.0036 - val_mae: 0.0367 - lr: 0.0010\n",
            "Epoch 29/500\n",
            "29/29 [==============================] - 7s 232ms/step - loss: 0.0035 - mae: 0.0291 - val_loss: 0.0052 - val_mae: 0.0360 - lr: 0.0010\n",
            "Epoch 30/500\n",
            "29/29 [==============================] - 5s 171ms/step - loss: 0.0035 - mae: 0.0307 - val_loss: 0.0051 - val_mae: 0.0352 - lr: 0.0010\n",
            "Epoch 31/500\n",
            "29/29 [==============================] - 8s 288ms/step - loss: 0.0088 - mae: 0.0571 - val_loss: 0.0154 - val_mae: 0.1084 - lr: 0.0010\n",
            "Epoch 32/500\n",
            "29/29 [==============================] - 7s 244ms/step - loss: 0.0040 - mae: 0.0355 - val_loss: 0.0181 - val_mae: 0.1163 - lr: 0.0010\n",
            "Epoch 33/500\n",
            "29/29 [==============================] - 5s 174ms/step - loss: 0.0051 - mae: 0.0437 - val_loss: 0.0071 - val_mae: 0.0625 - lr: 0.0010\n",
            "Epoch 34/500\n",
            "29/29 [==============================] - 6s 215ms/step - loss: 0.0079 - mae: 0.0541 - val_loss: 0.0165 - val_mae: 0.0979 - lr: 0.0010\n",
            "Epoch 35/500\n",
            "29/29 [==============================] - 5s 169ms/step - loss: 0.0060 - mae: 0.0472 - val_loss: 0.0057 - val_mae: 0.0472 - lr: 0.0010\n",
            "Epoch 36/500\n",
            "29/29 [==============================] - 7s 240ms/step - loss: 0.0084 - mae: 0.0550 - val_loss: 0.0258 - val_mae: 0.1469 - lr: 0.0010\n",
            "Epoch 37/500\n",
            "29/29 [==============================] - 5s 178ms/step - loss: 0.0065 - mae: 0.0500 - val_loss: 0.0032 - val_mae: 0.0268 - lr: 2.0000e-04\n",
            "Epoch 38/500\n",
            "29/29 [==============================] - 5s 175ms/step - loss: 0.0052 - mae: 0.0421 - val_loss: 0.0032 - val_mae: 0.0304 - lr: 2.0000e-04\n",
            "Epoch 39/500\n",
            "29/29 [==============================] - 7s 235ms/step - loss: 0.0029 - mae: 0.0264 - val_loss: 0.0036 - val_mae: 0.0388 - lr: 2.0000e-04\n",
            "Epoch 40/500\n",
            "29/29 [==============================] - 5s 174ms/step - loss: 0.0027 - mae: 0.0251 - val_loss: 0.0034 - val_mae: 0.0374 - lr: 2.0000e-04\n",
            "Epoch 41/500\n",
            "29/29 [==============================] - 7s 253ms/step - loss: 0.0026 - mae: 0.0238 - val_loss: 0.0034 - val_mae: 0.0374 - lr: 2.0000e-04\n",
            "Epoch 42/500\n",
            "29/29 [==============================] - 5s 183ms/step - loss: 0.0025 - mae: 0.0239 - val_loss: 0.0033 - val_mae: 0.0370 - lr: 2.0000e-04\n",
            "Epoch 43/500\n",
            "29/29 [==============================] - 7s 232ms/step - loss: 0.0024 - mae: 0.0232 - val_loss: 0.0033 - val_mae: 0.0370 - lr: 2.0000e-04\n",
            "Epoch 44/500\n",
            "29/29 [==============================] - 6s 195ms/step - loss: 0.0024 - mae: 0.0228 - val_loss: 0.0032 - val_mae: 0.0366 - lr: 2.0000e-04\n",
            "Epoch 45/500\n",
            "29/29 [==============================] - 5s 168ms/step - loss: 0.0024 - mae: 0.0230 - val_loss: 0.0032 - val_mae: 0.0362 - lr: 2.0000e-04\n",
            "Epoch 46/500\n",
            "29/29 [==============================] - 7s 251ms/step - loss: 0.0023 - mae: 0.0221 - val_loss: 0.0032 - val_mae: 0.0360 - lr: 4.0000e-05\n",
            "Epoch 47/500\n",
            "29/29 [==============================] - 5s 178ms/step - loss: 0.0023 - mae: 0.0221 - val_loss: 0.0031 - val_mae: 0.0359 - lr: 4.0000e-05\n",
            "Epoch 48/500\n",
            "29/29 [==============================] - 5s 177ms/step - loss: 0.0023 - mae: 0.0224 - val_loss: 0.0031 - val_mae: 0.0358 - lr: 4.0000e-05\n",
            "Epoch 49/500\n",
            "29/29 [==============================] - 7s 239ms/step - loss: 0.0023 - mae: 0.0221 - val_loss: 0.0031 - val_mae: 0.0356 - lr: 4.0000e-05\n",
            "Epoch 50/500\n",
            "29/29 [==============================] - 6s 221ms/step - loss: 0.0023 - mae: 0.0225 - val_loss: 0.0031 - val_mae: 0.0357 - lr: 4.0000e-05\n",
            "Epoch 51/500\n",
            "29/29 [==============================] - 5s 169ms/step - loss: 0.0022 - mae: 0.0219 - val_loss: 0.0031 - val_mae: 0.0360 - lr: 4.0000e-05\n",
            "Epoch 52/500\n",
            "29/29 [==============================] - 7s 242ms/step - loss: 0.0022 - mae: 0.0222 - val_loss: 0.0031 - val_mae: 0.0359 - lr: 4.0000e-05\n",
            "Epoch 53/500\n",
            "29/29 [==============================] - 5s 166ms/step - loss: 0.0022 - mae: 0.0219 - val_loss: 0.0031 - val_mae: 0.0362 - lr: 4.0000e-05\n",
            "Epoch 54/500\n",
            "29/29 [==============================] - 7s 244ms/step - loss: 0.0022 - mae: 0.0222 - val_loss: 0.0031 - val_mae: 0.0362 - lr: 1.0000e-05\n",
            "Epoch 55/500\n",
            "29/29 [==============================] - 5s 165ms/step - loss: 0.0022 - mae: 0.0218 - val_loss: 0.0031 - val_mae: 0.0361 - lr: 1.0000e-05\n",
            "Epoch 56/500\n",
            "29/29 [==============================] - 5s 172ms/step - loss: 0.0023 - mae: 0.0218 - val_loss: 0.0031 - val_mae: 0.0360 - lr: 1.0000e-05\n",
            "Epoch 57/500\n",
            "29/29 [==============================] - 7s 238ms/step - loss: 0.0023 - mae: 0.0222 - val_loss: 0.0031 - val_mae: 0.0361 - lr: 1.0000e-05\n",
            "Epoch 58/500\n",
            "29/29 [==============================] - 6s 225ms/step - loss: 0.0023 - mae: 0.0222 - val_loss: 0.0031 - val_mae: 0.0362 - lr: 1.0000e-05\n",
            "Epoch 59/500\n",
            "29/29 [==============================] - 5s 167ms/step - loss: 0.0022 - mae: 0.0214 - val_loss: 0.0031 - val_mae: 0.0362 - lr: 1.0000e-05\n",
            "Epoch 60/500\n",
            "29/29 [==============================] - 7s 247ms/step - loss: 0.0022 - mae: 0.0218 - val_loss: 0.0031 - val_mae: 0.0363 - lr: 1.0000e-05\n",
            "Epoch 61/500\n",
            "29/29 [==============================] - 5s 177ms/step - loss: 0.0022 - mae: 0.0222 - val_loss: 0.0031 - val_mae: 0.0362 - lr: 1.0000e-05\n",
            "Epoch 62/500\n",
            "29/29 [==============================] - 5s 168ms/step - loss: 0.0022 - mae: 0.0216 - val_loss: 0.0031 - val_mae: 0.0362 - lr: 1.0000e-05\n",
            "Epoch 63/500\n",
            "29/29 [==============================] - 6s 206ms/step - loss: 0.0022 - mae: 0.0223 - val_loss: 0.0031 - val_mae: 0.0362 - lr: 1.0000e-05\n",
            "Epoch 64/500\n",
            "29/29 [==============================] - 5s 171ms/step - loss: 0.0022 - mae: 0.0217 - val_loss: 0.0031 - val_mae: 0.0363 - lr: 1.0000e-05\n",
            "Epoch 65/500\n",
            "29/29 [==============================] - 7s 249ms/step - loss: 0.0023 - mae: 0.0227 - val_loss: 0.0031 - val_mae: 0.0363 - lr: 1.0000e-05\n",
            "Epoch 66/500\n",
            "29/29 [==============================] - 5s 184ms/step - loss: 0.0023 - mae: 0.0227 - val_loss: 0.0031 - val_mae: 0.0362 - lr: 1.0000e-05\n",
            "Epoch 67/500\n",
            "29/29 [==============================] - 6s 222ms/step - loss: 0.0023 - mae: 0.0223 - val_loss: 0.0031 - val_mae: 0.0362 - lr: 1.0000e-05\n",
            "Epoch 68/500\n",
            "29/29 [==============================] - 9s 300ms/step - loss: 0.0022 - mae: 0.0225 - val_loss: 0.0031 - val_mae: 0.0363 - lr: 1.0000e-05\n",
            "Epoch 69/500\n",
            "29/29 [==============================] - 6s 210ms/step - loss: 0.0022 - mae: 0.0216 - val_loss: 0.0031 - val_mae: 0.0363 - lr: 1.0000e-05\n",
            "Epoch 70/500\n",
            "29/29 [==============================] - 6s 222ms/step - loss: 0.0022 - mae: 0.0216 - val_loss: 0.0031 - val_mae: 0.0363 - lr: 1.0000e-05\n",
            "Epoch 71/500\n",
            "29/29 [==============================] - 7s 255ms/step - loss: 0.0021 - mae: 0.0220 - val_loss: 0.0031 - val_mae: 0.0362 - lr: 1.0000e-05\n",
            "Epoch 72/500\n",
            "29/29 [==============================] - 6s 193ms/step - loss: 0.0022 - mae: 0.0226 - val_loss: 0.0031 - val_mae: 0.0361 - lr: 1.0000e-05\n",
            "Epoch 73/500\n",
            "29/29 [==============================] - 5s 179ms/step - loss: 0.0023 - mae: 0.0223 - val_loss: 0.0031 - val_mae: 0.0361 - lr: 1.0000e-05\n",
            "Epoch 74/500\n",
            "29/29 [==============================] - 6s 196ms/step - loss: 0.0021 - mae: 0.0215 - val_loss: 0.0031 - val_mae: 0.0361 - lr: 1.0000e-05\n",
            "Epoch 75/500\n",
            "29/29 [==============================] - 5s 166ms/step - loss: 0.0022 - mae: 0.0222 - val_loss: 0.0031 - val_mae: 0.0361 - lr: 1.0000e-05\n",
            "Epoch 76/500\n",
            "29/29 [==============================] - 7s 255ms/step - loss: 0.0021 - mae: 0.0214 - val_loss: 0.0031 - val_mae: 0.0360 - lr: 1.0000e-05\n",
            "Epoch 77/500\n",
            "29/29 [==============================] - 7s 237ms/step - loss: 0.0021 - mae: 0.0212 - val_loss: 0.0031 - val_mae: 0.0360 - lr: 1.0000e-05\n",
            "Epoch 78/500\n",
            "29/29 [==============================] - 10s 331ms/step - loss: 0.0022 - mae: 0.0220 - val_loss: 0.0031 - val_mae: 0.0361 - lr: 1.0000e-05\n",
            "Epoch 79/500\n",
            "29/29 [==============================] - 7s 239ms/step - loss: 0.0022 - mae: 0.0220 - val_loss: 0.0031 - val_mae: 0.0361 - lr: 1.0000e-05\n",
            "Epoch 80/500\n",
            "29/29 [==============================] - 10s 344ms/step - loss: 0.0022 - mae: 0.0221 - val_loss: 0.0031 - val_mae: 0.0360 - lr: 1.0000e-05\n",
            "Epoch 81/500\n",
            "29/29 [==============================] - 10s 364ms/step - loss: 0.0022 - mae: 0.0226 - val_loss: 0.0031 - val_mae: 0.0363 - lr: 1.0000e-05\n",
            "Epoch 82/500\n",
            "29/29 [==============================] - 8s 283ms/step - loss: 0.0022 - mae: 0.0216 - val_loss: 0.0031 - val_mae: 0.0362 - lr: 1.0000e-05\n",
            "Epoch 83/500\n",
            "29/29 [==============================] - 8s 280ms/step - loss: 0.0021 - mae: 0.0215 - val_loss: 0.0031 - val_mae: 0.0361 - lr: 1.0000e-05\n",
            "Epoch 84/500\n",
            "29/29 [==============================] - 9s 290ms/step - loss: 0.0021 - mae: 0.0217 - val_loss: 0.0031 - val_mae: 0.0362 - lr: 1.0000e-05\n",
            "Epoch 85/500\n",
            "29/29 [==============================] - 9s 301ms/step - loss: 0.0022 - mae: 0.0218 - val_loss: 0.0031 - val_mae: 0.0362 - lr: 1.0000e-05\n",
            "Epoch 86/500\n",
            "29/29 [==============================] - 5s 167ms/step - loss: 0.0022 - mae: 0.0222 - val_loss: 0.0031 - val_mae: 0.0363 - lr: 1.0000e-05\n",
            "Epoch 87/500\n",
            "29/29 [==============================] - 8s 275ms/step - loss: 0.0022 - mae: 0.0218 - val_loss: 0.0031 - val_mae: 0.0362 - lr: 1.0000e-05\n",
            "Epoch 88/500\n",
            "29/29 [==============================] - 9s 328ms/step - loss: 0.0022 - mae: 0.0222 - val_loss: 0.0031 - val_mae: 0.0360 - lr: 1.0000e-05\n",
            "Epoch 89/500\n",
            "29/29 [==============================] - 6s 219ms/step - loss: 0.0022 - mae: 0.0216 - val_loss: 0.0030 - val_mae: 0.0360 - lr: 1.0000e-05\n",
            "Epoch 90/500\n",
            "29/29 [==============================] - 7s 244ms/step - loss: 0.0022 - mae: 0.0216 - val_loss: 0.0031 - val_mae: 0.0361 - lr: 1.0000e-05\n",
            "Epoch 91/500\n",
            "29/29 [==============================] - 10s 339ms/step - loss: 0.0021 - mae: 0.0217 - val_loss: 0.0030 - val_mae: 0.0359 - lr: 1.0000e-05\n",
            "Epoch 92/500\n",
            "29/29 [==============================] - 10s 336ms/step - loss: 0.0022 - mae: 0.0223 - val_loss: 0.0030 - val_mae: 0.0359 - lr: 1.0000e-05\n",
            "Epoch 93/500\n",
            "29/29 [==============================] - 9s 304ms/step - loss: 0.0021 - mae: 0.0213 - val_loss: 0.0030 - val_mae: 0.0360 - lr: 1.0000e-05\n",
            "Epoch 94/500\n",
            "29/29 [==============================] - 5s 178ms/step - loss: 0.0021 - mae: 0.0218 - val_loss: 0.0030 - val_mae: 0.0361 - lr: 1.0000e-05\n",
            "Epoch 95/500\n",
            "29/29 [==============================] - 8s 265ms/step - loss: 0.0021 - mae: 0.0218 - val_loss: 0.0031 - val_mae: 0.0362 - lr: 1.0000e-05\n",
            "Epoch 96/500\n",
            "29/29 [==============================] - 5s 169ms/step - loss: 0.0022 - mae: 0.0221 - val_loss: 0.0030 - val_mae: 0.0362 - lr: 1.0000e-05\n",
            "Epoch 97/500\n",
            "29/29 [==============================] - 7s 257ms/step - loss: 0.0022 - mae: 0.0224 - val_loss: 0.0030 - val_mae: 0.0361 - lr: 1.0000e-05\n",
            "Epoch 98/500\n",
            "29/29 [==============================] - 5s 172ms/step - loss: 0.0021 - mae: 0.0219 - val_loss: 0.0030 - val_mae: 0.0361 - lr: 1.0000e-05\n",
            "Epoch 99/500\n",
            "29/29 [==============================] - 7s 257ms/step - loss: 0.0021 - mae: 0.0217 - val_loss: 0.0030 - val_mae: 0.0362 - lr: 1.0000e-05\n",
            "Epoch 100/500\n",
            "29/29 [==============================] - 5s 172ms/step - loss: 0.0021 - mae: 0.0215 - val_loss: 0.0031 - val_mae: 0.0365 - lr: 1.0000e-05\n",
            "Epoch 101/500\n",
            "29/29 [==============================] - 6s 206ms/step - loss: 0.0021 - mae: 0.0218 - val_loss: 0.0030 - val_mae: 0.0364 - lr: 1.0000e-05\n",
            "Epoch 102/500\n",
            "29/29 [==============================] - 6s 194ms/step - loss: 0.0022 - mae: 0.0225 - val_loss: 0.0030 - val_mae: 0.0363 - lr: 1.0000e-05\n",
            "Epoch 103/500\n",
            "29/29 [==============================] - 9s 300ms/step - loss: 0.0022 - mae: 0.0217 - val_loss: 0.0030 - val_mae: 0.0363 - lr: 1.0000e-05\n",
            "Epoch 104/500\n",
            "29/29 [==============================] - 9s 297ms/step - loss: 0.0021 - mae: 0.0215 - val_loss: 0.0030 - val_mae: 0.0363 - lr: 1.0000e-05\n",
            "Epoch 105/500\n",
            "29/29 [==============================] - 7s 232ms/step - loss: 0.0021 - mae: 0.0215 - val_loss: 0.0030 - val_mae: 0.0364 - lr: 1.0000e-05\n",
            "Epoch 106/500\n",
            "29/29 [==============================] - 6s 199ms/step - loss: 0.0021 - mae: 0.0216 - val_loss: 0.0030 - val_mae: 0.0364 - lr: 1.0000e-05\n",
            "Epoch 107/500\n",
            "29/29 [==============================] - 5s 172ms/step - loss: 0.0021 - mae: 0.0215 - val_loss: 0.0030 - val_mae: 0.0364 - lr: 1.0000e-05\n",
            "Epoch 108/500\n",
            "29/29 [==============================] - 5s 179ms/step - loss: 0.0021 - mae: 0.0216 - val_loss: 0.0030 - val_mae: 0.0364 - lr: 1.0000e-05\n",
            "Epoch 109/500\n",
            "29/29 [==============================] - 7s 232ms/step - loss: 0.0021 - mae: 0.0217 - val_loss: 0.0030 - val_mae: 0.0365 - lr: 1.0000e-05\n",
            "Epoch 110/500\n",
            "29/29 [==============================] - 5s 174ms/step - loss: 0.0021 - mae: 0.0214 - val_loss: 0.0030 - val_mae: 0.0368 - lr: 1.0000e-05\n",
            "Epoch 111/500\n",
            "29/29 [==============================] - 7s 241ms/step - loss: 0.0021 - mae: 0.0217 - val_loss: 0.0030 - val_mae: 0.0368 - lr: 1.0000e-05\n",
            "Epoch 112/500\n",
            "29/29 [==============================] - 5s 169ms/step - loss: 0.0021 - mae: 0.0216 - val_loss: 0.0030 - val_mae: 0.0366 - lr: 1.0000e-05\n",
            "Epoch 113/500\n",
            "29/29 [==============================] - 6s 196ms/step - loss: 0.0021 - mae: 0.0217 - val_loss: 0.0030 - val_mae: 0.0365 - lr: 1.0000e-05\n",
            "Epoch 114/500\n",
            "29/29 [==============================] - 5s 165ms/step - loss: 0.0021 - mae: 0.0213 - val_loss: 0.0030 - val_mae: 0.0363 - lr: 1.0000e-05\n",
            "Epoch 115/500\n",
            "29/29 [==============================] - 7s 242ms/step - loss: 0.0021 - mae: 0.0214 - val_loss: 0.0030 - val_mae: 0.0361 - lr: 1.0000e-05\n",
            "Epoch 116/500\n",
            "29/29 [==============================] - 5s 173ms/step - loss: 0.0021 - mae: 0.0213 - val_loss: 0.0030 - val_mae: 0.0361 - lr: 1.0000e-05\n",
            "Epoch 117/500\n",
            "29/29 [==============================] - 6s 215ms/step - loss: 0.0021 - mae: 0.0214 - val_loss: 0.0030 - val_mae: 0.0362 - lr: 1.0000e-05\n",
            "Epoch 118/500\n",
            "29/29 [==============================] - 5s 165ms/step - loss: 0.0021 - mae: 0.0219 - val_loss: 0.0030 - val_mae: 0.0362 - lr: 1.0000e-05\n",
            "Epoch 119/500\n",
            "29/29 [==============================] - 7s 250ms/step - loss: 0.0021 - mae: 0.0216 - val_loss: 0.0030 - val_mae: 0.0362 - lr: 1.0000e-05\n",
            "Epoch 120/500\n",
            "29/29 [==============================] - 5s 179ms/step - loss: 0.0021 - mae: 0.0217 - val_loss: 0.0030 - val_mae: 0.0363 - lr: 1.0000e-05\n",
            "Epoch 121/500\n",
            "29/29 [==============================] - 8s 287ms/step - loss: 0.0020 - mae: 0.0213 - val_loss: 0.0030 - val_mae: 0.0364 - lr: 1.0000e-05\n",
            "Epoch 122/500\n",
            "29/29 [==============================] - 6s 215ms/step - loss: 0.0020 - mae: 0.0212 - val_loss: 0.0030 - val_mae: 0.0366 - lr: 1.0000e-05\n",
            "Epoch 123/500\n",
            "29/29 [==============================] - 8s 268ms/step - loss: 0.0020 - mae: 0.0213 - val_loss: 0.0030 - val_mae: 0.0366 - lr: 1.0000e-05\n",
            "Epoch 124/500\n",
            "29/29 [==============================] - 5s 185ms/step - loss: 0.0021 - mae: 0.0215 - val_loss: 0.0030 - val_mae: 0.0365 - lr: 1.0000e-05\n",
            "Epoch 125/500\n",
            "29/29 [==============================] - 5s 173ms/step - loss: 0.0020 - mae: 0.0212 - val_loss: 0.0030 - val_mae: 0.0365 - lr: 1.0000e-05\n",
            "Epoch 126/500\n",
            "29/29 [==============================] - 5s 174ms/step - loss: 0.0020 - mae: 0.0210 - val_loss: 0.0030 - val_mae: 0.0365 - lr: 1.0000e-05\n",
            "Epoch 127/500\n",
            "29/29 [==============================] - 7s 234ms/step - loss: 0.0020 - mae: 0.0211 - val_loss: 0.0030 - val_mae: 0.0364 - lr: 1.0000e-05\n",
            "Epoch 128/500\n",
            "29/29 [==============================] - 5s 163ms/step - loss: 0.0021 - mae: 0.0217 - val_loss: 0.0030 - val_mae: 0.0364 - lr: 1.0000e-05\n",
            "Epoch 129/500\n",
            "29/29 [==============================] - 6s 226ms/step - loss: 0.0020 - mae: 0.0210 - val_loss: 0.0030 - val_mae: 0.0363 - lr: 1.0000e-05\n",
            "Epoch 130/500\n",
            "29/29 [==============================] - 5s 164ms/step - loss: 0.0021 - mae: 0.0219 - val_loss: 0.0030 - val_mae: 0.0363 - lr: 1.0000e-05\n",
            "Epoch 131/500\n",
            "29/29 [==============================] - 7s 239ms/step - loss: 0.0020 - mae: 0.0215 - val_loss: 0.0030 - val_mae: 0.0365 - lr: 1.0000e-05\n",
            "Epoch 132/500\n",
            "29/29 [==============================] - 5s 183ms/step - loss: 0.0021 - mae: 0.0213 - val_loss: 0.0030 - val_mae: 0.0365 - lr: 1.0000e-05\n",
            "Epoch 133/500\n",
            "29/29 [==============================] - 5s 174ms/step - loss: 0.0020 - mae: 0.0214 - val_loss: 0.0029 - val_mae: 0.0361 - lr: 1.0000e-05\n",
            "Epoch 134/500\n",
            "29/29 [==============================] - 7s 243ms/step - loss: 0.0020 - mae: 0.0210 - val_loss: 0.0030 - val_mae: 0.0363 - lr: 1.0000e-05\n",
            "Epoch 135/500\n",
            "29/29 [==============================] - 5s 178ms/step - loss: 0.0020 - mae: 0.0214 - val_loss: 0.0030 - val_mae: 0.0366 - lr: 1.0000e-05\n",
            "Epoch 136/500\n",
            "29/29 [==============================] - 7s 249ms/step - loss: 0.0020 - mae: 0.0214 - val_loss: 0.0030 - val_mae: 0.0367 - lr: 1.0000e-05\n",
            "Epoch 137/500\n",
            "29/29 [==============================] - 5s 178ms/step - loss: 0.0020 - mae: 0.0208 - val_loss: 0.0030 - val_mae: 0.0368 - lr: 1.0000e-05\n",
            "Epoch 138/500\n",
            "29/29 [==============================] - 7s 231ms/step - loss: 0.0019 - mae: 0.0208 - val_loss: 0.0030 - val_mae: 0.0368 - lr: 1.0000e-05\n",
            "Epoch 139/500\n",
            "29/29 [==============================] - 7s 263ms/step - loss: 0.0020 - mae: 0.0211 - val_loss: 0.0030 - val_mae: 0.0366 - lr: 1.0000e-05\n",
            "Epoch 140/500\n",
            "29/29 [==============================] - 5s 186ms/step - loss: 0.0020 - mae: 0.0213 - val_loss: 0.0030 - val_mae: 0.0367 - lr: 1.0000e-05\n",
            "Epoch 141/500\n",
            "29/29 [==============================] - 6s 192ms/step - loss: 0.0021 - mae: 0.0217 - val_loss: 0.0030 - val_mae: 0.0368 - lr: 1.0000e-05\n",
            "Epoch 142/500\n",
            "29/29 [==============================] - 5s 167ms/step - loss: 0.0020 - mae: 0.0208 - val_loss: 0.0030 - val_mae: 0.0368 - lr: 1.0000e-05\n",
            "Epoch 143/500\n",
            "29/29 [==============================] - 7s 246ms/step - loss: 0.0020 - mae: 0.0213 - val_loss: 0.0030 - val_mae: 0.0367 - lr: 1.0000e-05\n",
            "Epoch 144/500\n",
            "29/29 [==============================] - 5s 169ms/step - loss: 0.0020 - mae: 0.0213 - val_loss: 0.0029 - val_mae: 0.0366 - lr: 1.0000e-05\n",
            "Epoch 145/500\n",
            "29/29 [==============================] - 6s 206ms/step - loss: 0.0019 - mae: 0.0210 - val_loss: 0.0029 - val_mae: 0.0366 - lr: 1.0000e-05\n",
            "Epoch 146/500\n",
            "29/29 [==============================] - 5s 166ms/step - loss: 0.0019 - mae: 0.0206 - val_loss: 0.0029 - val_mae: 0.0366 - lr: 1.0000e-05\n",
            "Epoch 147/500\n",
            "29/29 [==============================] - 7s 238ms/step - loss: 0.0020 - mae: 0.0211 - val_loss: 0.0029 - val_mae: 0.0367 - lr: 1.0000e-05\n",
            "Epoch 148/500\n",
            "29/29 [==============================] - 6s 209ms/step - loss: 0.0019 - mae: 0.0210 - val_loss: 0.0029 - val_mae: 0.0366 - lr: 1.0000e-05\n",
            "Epoch 149/500\n",
            "29/29 [==============================] - 8s 271ms/step - loss: 0.0020 - mae: 0.0213 - val_loss: 0.0029 - val_mae: 0.0366 - lr: 1.0000e-05\n",
            "Epoch 150/500\n",
            "29/29 [==============================] - 5s 171ms/step - loss: 0.0020 - mae: 0.0212 - val_loss: 0.0030 - val_mae: 0.0370 - lr: 1.0000e-05\n",
            "Epoch 151/500\n",
            "29/29 [==============================] - 8s 263ms/step - loss: 0.0019 - mae: 0.0205 - val_loss: 0.0029 - val_mae: 0.0369 - lr: 1.0000e-05\n",
            "Epoch 152/500\n",
            "29/29 [==============================] - 5s 167ms/step - loss: 0.0020 - mae: 0.0215 - val_loss: 0.0029 - val_mae: 0.0369 - lr: 1.0000e-05\n",
            "Epoch 153/500\n",
            "29/29 [==============================] - 6s 206ms/step - loss: 0.0019 - mae: 0.0207 - val_loss: 0.0029 - val_mae: 0.0369 - lr: 1.0000e-05\n",
            "Epoch 154/500\n",
            "29/29 [==============================] - 5s 170ms/step - loss: 0.0019 - mae: 0.0209 - val_loss: 0.0029 - val_mae: 0.0367 - lr: 1.0000e-05\n",
            "Epoch 155/500\n",
            "29/29 [==============================] - 7s 241ms/step - loss: 0.0020 - mae: 0.0214 - val_loss: 0.0029 - val_mae: 0.0369 - lr: 1.0000e-05\n",
            "Epoch 156/500\n",
            "29/29 [==============================] - 5s 174ms/step - loss: 0.0020 - mae: 0.0213 - val_loss: 0.0029 - val_mae: 0.0368 - lr: 1.0000e-05\n",
            "Epoch 157/500\n",
            "29/29 [==============================] - 8s 263ms/step - loss: 0.0020 - mae: 0.0210 - val_loss: 0.0029 - val_mae: 0.0366 - lr: 1.0000e-05\n",
            "Epoch 158/500\n",
            "29/29 [==============================] - 6s 218ms/step - loss: 0.0020 - mae: 0.0213 - val_loss: 0.0029 - val_mae: 0.0368 - lr: 1.0000e-05\n",
            "Epoch 159/500\n",
            "29/29 [==============================] - 6s 197ms/step - loss: 0.0019 - mae: 0.0211 - val_loss: 0.0029 - val_mae: 0.0367 - lr: 1.0000e-05\n",
            "Epoch 160/500\n",
            "29/29 [==============================] - 5s 177ms/step - loss: 0.0019 - mae: 0.0208 - val_loss: 0.0029 - val_mae: 0.0369 - lr: 1.0000e-05\n",
            "Epoch 161/500\n",
            "29/29 [==============================] - 7s 256ms/step - loss: 0.0019 - mae: 0.0208 - val_loss: 0.0029 - val_mae: 0.0371 - lr: 1.0000e-05\n",
            "Epoch 162/500\n",
            "29/29 [==============================] - 5s 174ms/step - loss: 0.0019 - mae: 0.0209 - val_loss: 0.0029 - val_mae: 0.0366 - lr: 1.0000e-05\n",
            "Epoch 163/500\n",
            "29/29 [==============================] - 7s 235ms/step - loss: 0.0019 - mae: 0.0212 - val_loss: 0.0029 - val_mae: 0.0366 - lr: 1.0000e-05\n",
            "Epoch 164/500\n",
            "29/29 [==============================] - 5s 165ms/step - loss: 0.0019 - mae: 0.0206 - val_loss: 0.0029 - val_mae: 0.0370 - lr: 1.0000e-05\n",
            "Epoch 165/500\n",
            "29/29 [==============================] - 7s 247ms/step - loss: 0.0019 - mae: 0.0214 - val_loss: 0.0029 - val_mae: 0.0368 - lr: 1.0000e-05\n",
            "Epoch 166/500\n",
            "29/29 [==============================] - 5s 191ms/step - loss: 0.0019 - mae: 0.0206 - val_loss: 0.0029 - val_mae: 0.0366 - lr: 1.0000e-05\n",
            "Epoch 167/500\n",
            "29/29 [==============================] - 7s 244ms/step - loss: 0.0019 - mae: 0.0213 - val_loss: 0.0029 - val_mae: 0.0370 - lr: 1.0000e-05\n",
            "Epoch 168/500\n",
            "29/29 [==============================] - 5s 175ms/step - loss: 0.0019 - mae: 0.0210 - val_loss: 0.0029 - val_mae: 0.0371 - lr: 1.0000e-05\n",
            "Epoch 169/500\n",
            "29/29 [==============================] - 7s 244ms/step - loss: 0.0019 - mae: 0.0205 - val_loss: 0.0029 - val_mae: 0.0369 - lr: 1.0000e-05\n",
            "Epoch 170/500\n",
            "29/29 [==============================] - 5s 169ms/step - loss: 0.0019 - mae: 0.0211 - val_loss: 0.0029 - val_mae: 0.0371 - lr: 1.0000e-05\n",
            "Epoch 171/500\n",
            "29/29 [==============================] - 6s 221ms/step - loss: 0.0019 - mae: 0.0208 - val_loss: 0.0029 - val_mae: 0.0373 - lr: 1.0000e-05\n",
            "Epoch 172/500\n",
            "29/29 [==============================] - 6s 192ms/step - loss: 0.0019 - mae: 0.0204 - val_loss: 0.0029 - val_mae: 0.0373 - lr: 1.0000e-05\n",
            "Epoch 173/500\n",
            "29/29 [==============================] - 8s 264ms/step - loss: 0.0019 - mae: 0.0204 - val_loss: 0.0029 - val_mae: 0.0371 - lr: 1.0000e-05\n",
            "Epoch 174/500\n",
            "29/29 [==============================] - 5s 181ms/step - loss: 0.0019 - mae: 0.0208 - val_loss: 0.0029 - val_mae: 0.0372 - lr: 1.0000e-05\n",
            "Epoch 175/500\n",
            "29/29 [==============================] - 5s 171ms/step - loss: 0.0018 - mae: 0.0204 - val_loss: 0.0029 - val_mae: 0.0372 - lr: 1.0000e-05\n",
            "Epoch 176/500\n",
            "29/29 [==============================] - 7s 239ms/step - loss: 0.0019 - mae: 0.0211 - val_loss: 0.0029 - val_mae: 0.0371 - lr: 1.0000e-05\n",
            "Epoch 177/500\n",
            "29/29 [==============================] - 5s 181ms/step - loss: 0.0019 - mae: 0.0209 - val_loss: 0.0029 - val_mae: 0.0371 - lr: 1.0000e-05\n",
            "Epoch 178/500\n",
            "29/29 [==============================] - 7s 246ms/step - loss: 0.0019 - mae: 0.0213 - val_loss: 0.0029 - val_mae: 0.0373 - lr: 1.0000e-05\n",
            "Epoch 179/500\n",
            "29/29 [==============================] - 5s 182ms/step - loss: 0.0019 - mae: 0.0210 - val_loss: 0.0029 - val_mae: 0.0374 - lr: 1.0000e-05\n",
            "Epoch 180/500\n",
            "29/29 [==============================] - 7s 244ms/step - loss: 0.0018 - mae: 0.0207 - val_loss: 0.0029 - val_mae: 0.0373 - lr: 1.0000e-05\n",
            "Epoch 181/500\n",
            "29/29 [==============================] - 6s 225ms/step - loss: 0.0018 - mae: 0.0205 - val_loss: 0.0029 - val_mae: 0.0369 - lr: 1.0000e-05\n",
            "Epoch 182/500\n",
            "29/29 [==============================] - 5s 183ms/step - loss: 0.0018 - mae: 0.0203 - val_loss: 0.0029 - val_mae: 0.0370 - lr: 1.0000e-05\n",
            "Epoch 183/500\n",
            "29/29 [==============================] - 7s 250ms/step - loss: 0.0018 - mae: 0.0207 - val_loss: 0.0029 - val_mae: 0.0372 - lr: 1.0000e-05\n",
            "Epoch 184/500\n",
            "29/29 [==============================] - 5s 179ms/step - loss: 0.0019 - mae: 0.0208 - val_loss: 0.0029 - val_mae: 0.0372 - lr: 1.0000e-05\n",
            "Epoch 185/500\n",
            "29/29 [==============================] - 5s 183ms/step - loss: 0.0018 - mae: 0.0204 - val_loss: 0.0029 - val_mae: 0.0374 - lr: 1.0000e-05\n",
            "Epoch 186/500\n",
            "29/29 [==============================] - 5s 167ms/step - loss: 0.0018 - mae: 0.0203 - val_loss: 0.0028 - val_mae: 0.0368 - lr: 1.0000e-05\n",
            "Epoch 187/500\n",
            "29/29 [==============================] - 7s 245ms/step - loss: 0.0019 - mae: 0.0210 - val_loss: 0.0028 - val_mae: 0.0367 - lr: 1.0000e-05\n",
            "Epoch 188/500\n",
            "29/29 [==============================] - 5s 180ms/step - loss: 0.0018 - mae: 0.0208 - val_loss: 0.0029 - val_mae: 0.0372 - lr: 1.0000e-05\n",
            "Epoch 189/500\n",
            "29/29 [==============================] - 7s 249ms/step - loss: 0.0018 - mae: 0.0205 - val_loss: 0.0028 - val_mae: 0.0369 - lr: 1.0000e-05\n",
            "Epoch 190/500\n",
            "29/29 [==============================] - 5s 180ms/step - loss: 0.0018 - mae: 0.0202 - val_loss: 0.0028 - val_mae: 0.0367 - lr: 1.0000e-05\n",
            "Epoch 191/500\n",
            "29/29 [==============================] - 7s 239ms/step - loss: 0.0018 - mae: 0.0208 - val_loss: 0.0028 - val_mae: 0.0369 - lr: 1.0000e-05\n",
            "Epoch 192/500\n",
            "29/29 [==============================] - 5s 176ms/step - loss: 0.0018 - mae: 0.0203 - val_loss: 0.0028 - val_mae: 0.0366 - lr: 1.0000e-05\n",
            "Epoch 193/500\n",
            "29/29 [==============================] - 7s 236ms/step - loss: 0.0018 - mae: 0.0204 - val_loss: 0.0028 - val_mae: 0.0368 - lr: 1.0000e-05\n",
            "Epoch 194/500\n",
            "29/29 [==============================] - 5s 189ms/step - loss: 0.0019 - mae: 0.0211 - val_loss: 0.0028 - val_mae: 0.0368 - lr: 1.0000e-05\n",
            "Epoch 195/500\n",
            "29/29 [==============================] - 5s 165ms/step - loss: 0.0018 - mae: 0.0205 - val_loss: 0.0028 - val_mae: 0.0367 - lr: 1.0000e-05\n",
            "Epoch 196/500\n",
            "29/29 [==============================] - 7s 243ms/step - loss: 0.0018 - mae: 0.0204 - val_loss: 0.0028 - val_mae: 0.0367 - lr: 1.0000e-05\n",
            "Epoch 197/500\n",
            "29/29 [==============================] - 5s 172ms/step - loss: 0.0018 - mae: 0.0203 - val_loss: 0.0028 - val_mae: 0.0367 - lr: 1.0000e-05\n",
            "Epoch 198/500\n",
            "29/29 [==============================] - 7s 246ms/step - loss: 0.0018 - mae: 0.0204 - val_loss: 0.0028 - val_mae: 0.0366 - lr: 1.0000e-05\n",
            "Epoch 199/500\n",
            "29/29 [==============================] - 5s 169ms/step - loss: 0.0018 - mae: 0.0204 - val_loss: 0.0028 - val_mae: 0.0366 - lr: 1.0000e-05\n",
            "Epoch 200/500\n",
            "29/29 [==============================] - 6s 212ms/step - loss: 0.0018 - mae: 0.0205 - val_loss: 0.0028 - val_mae: 0.0369 - lr: 1.0000e-05\n",
            "Epoch 201/500\n",
            "29/29 [==============================] - 5s 177ms/step - loss: 0.0018 - mae: 0.0206 - val_loss: 0.0028 - val_mae: 0.0368 - lr: 1.0000e-05\n",
            "Epoch 202/500\n",
            "29/29 [==============================] - 7s 238ms/step - loss: 0.0017 - mae: 0.0200 - val_loss: 0.0028 - val_mae: 0.0367 - lr: 1.0000e-05\n",
            "Epoch 203/500\n",
            "29/29 [==============================] - 5s 166ms/step - loss: 0.0017 - mae: 0.0201 - val_loss: 0.0028 - val_mae: 0.0367 - lr: 1.0000e-05\n",
            "Epoch 204/500\n",
            "29/29 [==============================] - 5s 173ms/step - loss: 0.0017 - mae: 0.0200 - val_loss: 0.0028 - val_mae: 0.0365 - lr: 1.0000e-05\n",
            "Epoch 205/500\n",
            "29/29 [==============================] - 7s 234ms/step - loss: 0.0017 - mae: 0.0201 - val_loss: 0.0028 - val_mae: 0.0372 - lr: 1.0000e-05\n",
            "Epoch 206/500\n",
            "29/29 [==============================] - 5s 170ms/step - loss: 0.0017 - mae: 0.0202 - val_loss: 0.0028 - val_mae: 0.0370 - lr: 1.0000e-05\n",
            "Epoch 207/500\n",
            "29/29 [==============================] - 7s 246ms/step - loss: 0.0017 - mae: 0.0203 - val_loss: 0.0028 - val_mae: 0.0365 - lr: 1.0000e-05\n",
            "Epoch 208/500\n",
            "29/29 [==============================] - 5s 167ms/step - loss: 0.0018 - mae: 0.0205 - val_loss: 0.0028 - val_mae: 0.0367 - lr: 1.0000e-05\n",
            "Epoch 209/500\n",
            "29/29 [==============================] - 7s 239ms/step - loss: 0.0017 - mae: 0.0199 - val_loss: 0.0028 - val_mae: 0.0369 - lr: 1.0000e-05\n",
            "Epoch 210/500\n",
            "29/29 [==============================] - 5s 177ms/step - loss: 0.0017 - mae: 0.0199 - val_loss: 0.0028 - val_mae: 0.0369 - lr: 1.0000e-05\n",
            "Epoch 211/500\n",
            "29/29 [==============================] - 6s 199ms/step - loss: 0.0018 - mae: 0.0210 - val_loss: 0.0028 - val_mae: 0.0372 - lr: 1.0000e-05\n",
            "Epoch 212/500\n",
            "29/29 [==============================] - 5s 167ms/step - loss: 0.0017 - mae: 0.0201 - val_loss: 0.0028 - val_mae: 0.0368 - lr: 1.0000e-05\n",
            "Epoch 213/500\n",
            "29/29 [==============================] - 7s 242ms/step - loss: 0.0017 - mae: 0.0202 - val_loss: 0.0028 - val_mae: 0.0371 - lr: 1.0000e-05\n",
            "Epoch 214/500\n",
            "29/29 [==============================] - 5s 169ms/step - loss: 0.0017 - mae: 0.0204 - val_loss: 0.0028 - val_mae: 0.0372 - lr: 1.0000e-05\n",
            "Epoch 215/500\n",
            "29/29 [==============================] - 6s 204ms/step - loss: 0.0017 - mae: 0.0203 - val_loss: 0.0028 - val_mae: 0.0367 - lr: 1.0000e-05\n",
            "Epoch 216/500\n",
            "29/29 [==============================] - 5s 176ms/step - loss: 0.0017 - mae: 0.0200 - val_loss: 0.0028 - val_mae: 0.0369 - lr: 1.0000e-05\n",
            "Epoch 217/500\n",
            "29/29 [==============================] - 10s 346ms/step - loss: 0.0017 - mae: 0.0197 - val_loss: 0.0028 - val_mae: 0.0375 - lr: 1.0000e-05\n",
            "Epoch 218/500\n",
            "29/29 [==============================] - 6s 209ms/step - loss: 0.0017 - mae: 0.0196 - val_loss: 0.0028 - val_mae: 0.0376 - lr: 1.0000e-05\n",
            "Epoch 219/500\n",
            "29/29 [==============================] - 7s 240ms/step - loss: 0.0017 - mae: 0.0197 - val_loss: 0.0028 - val_mae: 0.0377 - lr: 1.0000e-05\n",
            "Epoch 220/500\n",
            "29/29 [==============================] - 5s 169ms/step - loss: 0.0017 - mae: 0.0200 - val_loss: 0.0028 - val_mae: 0.0376 - lr: 1.0000e-05\n",
            "Epoch 221/500\n",
            "29/29 [==============================] - 7s 239ms/step - loss: 0.0017 - mae: 0.0202 - val_loss: 0.0028 - val_mae: 0.0377 - lr: 1.0000e-05\n",
            "Epoch 222/500\n",
            "29/29 [==============================] - 5s 167ms/step - loss: 0.0017 - mae: 0.0201 - val_loss: 0.0028 - val_mae: 0.0378 - lr: 1.0000e-05\n",
            "Epoch 223/500\n",
            "29/29 [==============================] - 5s 174ms/step - loss: 0.0016 - mae: 0.0197 - val_loss: 0.0028 - val_mae: 0.0380 - lr: 1.0000e-05\n",
            "Epoch 224/500\n",
            "29/29 [==============================] - 7s 241ms/step - loss: 0.0017 - mae: 0.0203 - val_loss: 0.0028 - val_mae: 0.0376 - lr: 1.0000e-05\n",
            "Epoch 225/500\n",
            "29/29 [==============================] - 5s 168ms/step - loss: 0.0017 - mae: 0.0197 - val_loss: 0.0028 - val_mae: 0.0374 - lr: 1.0000e-05\n",
            "Epoch 226/500\n",
            "29/29 [==============================] - 6s 226ms/step - loss: 0.0017 - mae: 0.0202 - val_loss: 0.0028 - val_mae: 0.0373 - lr: 1.0000e-05\n",
            "Epoch 227/500\n",
            "29/29 [==============================] - 6s 189ms/step - loss: 0.0016 - mae: 0.0197 - val_loss: 0.0028 - val_mae: 0.0373 - lr: 1.0000e-05\n",
            "Epoch 228/500\n",
            "29/29 [==============================] - 7s 244ms/step - loss: 0.0018 - mae: 0.0206 - val_loss: 0.0028 - val_mae: 0.0376 - lr: 1.0000e-05\n",
            "Epoch 229/500\n",
            "29/29 [==============================] - 9s 317ms/step - loss: 0.0016 - mae: 0.0197 - val_loss: 0.0028 - val_mae: 0.0375 - lr: 1.0000e-05\n",
            "Epoch 230/500\n",
            "29/29 [==============================] - 5s 170ms/step - loss: 0.0017 - mae: 0.0198 - val_loss: 0.0028 - val_mae: 0.0378 - lr: 1.0000e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "medium_batches_model.save(\"/content/drive/MyDrive/CRYPTO/Models/medium_batches_model.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rX4ncBbqWg04",
        "outputId": "89a00aec-2f48-4858-a07b-40ce85bf37a2"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "medium_batches_model_loaded=load_model(\"/content/drive/MyDrive/CRYPTO/Models/medium_batches_model.h5\")"
      ],
      "metadata": {
        "id": "725igGGVWlOy"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "medium_batches_model_loaded.evaluate(X_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VFrmGj5i2Tf",
        "outputId": "942f4c9d-c80c-4523-c1b2-21f981c41f90"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 4s 91ms/step - loss: 0.0028 - mae: 0.0367\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0027533189859241247, 0.03671141713857651]"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Znowu zwiększamy BATCH_SIZE"
      ],
      "metadata": {
        "id": "2on5YfK652rg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 128\n",
        "\n",
        "scalers = [MinMaxScaler() for _ in range(DATA.shape[1])]\n",
        "\n",
        "DATA_scaled = np.hstack([scaler.fit_transform(DATA[:, [i]]) for i, scaler in enumerate(scalers)])\n",
        "\n",
        "reshaped_data_X, reshaped_data_y=reshape_data_mlt_feature_changer(DATA_scaled,n_timesteps,final_indexes)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(reshaped_data_X, reshaped_data_y, test_size=0.2, random_state=42,shuffle=False)\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
        "\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE)\n",
        "\n",
        "# Use AUTOTUNE for optimization\n",
        "train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "test_dataset = test_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "\n",
        "# Define the LSTM model\n",
        "\n",
        "big_batches_model = Sequential([\n",
        "    Bidirectional(LSTM(128, return_sequences=True, dropout=0.2)),\n",
        "    LSTM(64, activation='relu', dropout=0.2, kernel_regularizer=l2(0.01)),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1)  # Output only 1 value\n",
        "])\n",
        "\n",
        "\n",
        "# Compile the big_batches_model with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.001)  # Adjust the learning rate as needed\n",
        "big_batches_model.compile(optimizer=optimizer, loss='mse',metrics=[\"mae\"])\n",
        "\n",
        "# Add a callback to reduce learning rate on plateau\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=8, min_lr=0.00001)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
        "callbacks = [reduce_lr,early_stopping]\n",
        "\n",
        "# Train the big_batches_model with callbacks\n",
        "history = big_batches_model.fit(train_dataset, epochs=500, batch_size=128, validation_data=test_dataset, callbacks=callbacks)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vl0K10J2WpCA",
        "outputId": "a238a104-8a16-4253-8e4c-4974fb4d9841"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "15/15 [==============================] - 13s 327ms/step - loss: 2.1777 - mae: 0.1430 - val_loss: 1.7242 - val_mae: 0.1918 - lr: 0.0010\n",
            "Epoch 2/500\n",
            "15/15 [==============================] - 5s 331ms/step - loss: 1.4219 - mae: 0.1194 - val_loss: 1.1851 - val_mae: 0.2663 - lr: 0.0010\n",
            "Epoch 3/500\n",
            "15/15 [==============================] - 4s 271ms/step - loss: 0.9309 - mae: 0.0973 - val_loss: 0.7542 - val_mae: 0.2184 - lr: 0.0010\n",
            "Epoch 4/500\n",
            "15/15 [==============================] - 4s 241ms/step - loss: 0.6112 - mae: 0.1229 - val_loss: 0.4650 - val_mae: 0.1076 - lr: 0.0010\n",
            "Epoch 5/500\n",
            "15/15 [==============================] - 6s 389ms/step - loss: 0.3999 - mae: 0.1131 - val_loss: 0.3896 - val_mae: 0.2800 - lr: 0.0010\n",
            "Epoch 6/500\n",
            "15/15 [==============================] - 4s 241ms/step - loss: 0.3074 - mae: 0.1764 - val_loss: 0.2325 - val_mae: 0.1300 - lr: 0.0010\n",
            "Epoch 7/500\n",
            "15/15 [==============================] - 4s 249ms/step - loss: 0.1800 - mae: 0.0659 - val_loss: 0.1484 - val_mae: 0.0681 - lr: 0.0010\n",
            "Epoch 8/500\n",
            "15/15 [==============================] - 5s 347ms/step - loss: 0.1288 - mae: 0.0527 - val_loss: 0.1077 - val_mae: 0.0648 - lr: 0.0010\n",
            "Epoch 9/500\n",
            "15/15 [==============================] - 4s 275ms/step - loss: 0.0930 - mae: 0.0401 - val_loss: 0.0798 - val_mae: 0.0321 - lr: 0.0010\n",
            "Epoch 10/500\n",
            "15/15 [==============================] - 5s 297ms/step - loss: 0.0763 - mae: 0.0555 - val_loss: 0.0641 - val_mae: 0.0534 - lr: 0.0010\n",
            "Epoch 11/500\n",
            "15/15 [==============================] - 4s 246ms/step - loss: 0.0613 - mae: 0.0545 - val_loss: 0.0573 - val_mae: 0.0665 - lr: 0.0010\n",
            "Epoch 12/500\n",
            "15/15 [==============================] - 5s 356ms/step - loss: 0.0659 - mae: 0.0931 - val_loss: 0.0493 - val_mae: 0.0554 - lr: 0.0010\n",
            "Epoch 13/500\n",
            "15/15 [==============================] - 4s 241ms/step - loss: 0.0442 - mae: 0.0579 - val_loss: 0.0404 - val_mae: 0.0569 - lr: 0.0010\n",
            "Epoch 14/500\n",
            "15/15 [==============================] - 6s 380ms/step - loss: 0.0388 - mae: 0.0466 - val_loss: 0.0339 - val_mae: 0.0366 - lr: 0.0010\n",
            "Epoch 15/500\n",
            "15/15 [==============================] - 4s 264ms/step - loss: 0.0319 - mae: 0.0368 - val_loss: 0.0294 - val_mae: 0.0366 - lr: 0.0010\n",
            "Epoch 16/500\n",
            "15/15 [==============================] - 5s 339ms/step - loss: 0.0290 - mae: 0.0363 - val_loss: 0.0262 - val_mae: 0.0375 - lr: 0.0010\n",
            "Epoch 17/500\n",
            "15/15 [==============================] - 5s 319ms/step - loss: 0.0252 - mae: 0.0325 - val_loss: 0.0230 - val_mae: 0.0269 - lr: 0.0010\n",
            "Epoch 18/500\n",
            "15/15 [==============================] - 5s 317ms/step - loss: 0.0248 - mae: 0.0431 - val_loss: 0.0221 - val_mae: 0.0464 - lr: 0.0010\n",
            "Epoch 19/500\n",
            "15/15 [==============================] - 4s 288ms/step - loss: 0.0221 - mae: 0.0426 - val_loss: 0.0197 - val_mae: 0.0281 - lr: 0.0010\n",
            "Epoch 20/500\n",
            "15/15 [==============================] - 4s 273ms/step - loss: 0.0261 - mae: 0.0664 - val_loss: 0.0181 - val_mae: 0.0388 - lr: 0.0010\n",
            "Epoch 21/500\n",
            "15/15 [==============================] - 5s 293ms/step - loss: 0.0208 - mae: 0.0556 - val_loss: 0.0178 - val_mae: 0.0345 - lr: 0.0010\n",
            "Epoch 22/500\n",
            "15/15 [==============================] - 4s 248ms/step - loss: 0.0269 - mae: 0.0747 - val_loss: 0.0171 - val_mae: 0.0365 - lr: 0.0010\n",
            "Epoch 23/500\n",
            "15/15 [==============================] - 5s 372ms/step - loss: 0.0172 - mae: 0.0489 - val_loss: 0.0149 - val_mae: 0.0374 - lr: 0.0010\n",
            "Epoch 24/500\n",
            "15/15 [==============================] - 4s 260ms/step - loss: 0.0193 - mae: 0.0545 - val_loss: 0.0140 - val_mae: 0.0402 - lr: 0.0010\n",
            "Epoch 25/500\n",
            "15/15 [==============================] - 6s 406ms/step - loss: 0.0152 - mae: 0.0455 - val_loss: 0.0130 - val_mae: 0.0357 - lr: 0.0010\n",
            "Epoch 26/500\n",
            "15/15 [==============================] - 4s 243ms/step - loss: 0.0179 - mae: 0.0572 - val_loss: 0.0123 - val_mae: 0.0355 - lr: 0.0010\n",
            "Epoch 27/500\n",
            "15/15 [==============================] - 4s 243ms/step - loss: 0.0130 - mae: 0.0432 - val_loss: 0.0117 - val_mae: 0.0383 - lr: 0.0010\n",
            "Epoch 28/500\n",
            "15/15 [==============================] - 5s 371ms/step - loss: 0.0148 - mae: 0.0517 - val_loss: 0.0109 - val_mae: 0.0396 - lr: 0.0010\n",
            "Epoch 29/500\n",
            "15/15 [==============================] - 4s 247ms/step - loss: 0.0115 - mae: 0.0400 - val_loss: 0.0100 - val_mae: 0.0336 - lr: 0.0010\n",
            "Epoch 30/500\n",
            "15/15 [==============================] - 6s 385ms/step - loss: 0.0136 - mae: 0.0505 - val_loss: 0.0102 - val_mae: 0.0447 - lr: 0.0010\n",
            "Epoch 31/500\n",
            "15/15 [==============================] - 4s 248ms/step - loss: 0.0111 - mae: 0.0442 - val_loss: 0.0093 - val_mae: 0.0332 - lr: 0.0010\n",
            "Epoch 32/500\n",
            "15/15 [==============================] - 5s 347ms/step - loss: 0.0144 - mae: 0.0589 - val_loss: 0.0093 - val_mae: 0.0411 - lr: 0.0010\n",
            "Epoch 33/500\n",
            "15/15 [==============================] - 4s 271ms/step - loss: 0.0102 - mae: 0.0460 - val_loss: 0.0088 - val_mae: 0.0393 - lr: 0.0010\n",
            "Epoch 34/500\n",
            "15/15 [==============================] - 4s 250ms/step - loss: 0.0126 - mae: 0.0543 - val_loss: 0.0087 - val_mae: 0.0434 - lr: 0.0010\n",
            "Epoch 35/500\n",
            "15/15 [==============================] - 6s 390ms/step - loss: 0.0096 - mae: 0.0442 - val_loss: 0.0080 - val_mae: 0.0357 - lr: 0.0010\n",
            "Epoch 36/500\n",
            "15/15 [==============================] - 4s 240ms/step - loss: 0.0127 - mae: 0.0563 - val_loss: 0.0082 - val_mae: 0.0436 - lr: 0.0010\n",
            "Epoch 37/500\n",
            "15/15 [==============================] - 6s 377ms/step - loss: 0.0090 - mae: 0.0454 - val_loss: 0.0081 - val_mae: 0.0427 - lr: 0.0010\n",
            "Epoch 38/500\n",
            "15/15 [==============================] - 7s 456ms/step - loss: 0.0115 - mae: 0.0551 - val_loss: 0.0077 - val_mae: 0.0438 - lr: 0.0010\n",
            "Epoch 39/500\n",
            "15/15 [==============================] - 5s 322ms/step - loss: 0.0082 - mae: 0.0435 - val_loss: 0.0070 - val_mae: 0.0388 - lr: 0.0010\n",
            "Epoch 40/500\n",
            "15/15 [==============================] - 4s 244ms/step - loss: 0.0104 - mae: 0.0518 - val_loss: 0.0074 - val_mae: 0.0464 - lr: 0.0010\n",
            "Epoch 41/500\n",
            "15/15 [==============================] - 4s 251ms/step - loss: 0.0078 - mae: 0.0436 - val_loss: 0.0070 - val_mae: 0.0420 - lr: 0.0010\n",
            "Epoch 42/500\n",
            "15/15 [==============================] - 6s 363ms/step - loss: 0.0101 - mae: 0.0533 - val_loss: 0.0070 - val_mae: 0.0462 - lr: 0.0010\n",
            "Epoch 43/500\n",
            "15/15 [==============================] - 4s 242ms/step - loss: 0.0074 - mae: 0.0435 - val_loss: 0.0063 - val_mae: 0.0398 - lr: 0.0010\n",
            "Epoch 44/500\n",
            "15/15 [==============================] - 6s 387ms/step - loss: 0.0095 - mae: 0.0516 - val_loss: 0.0069 - val_mae: 0.0484 - lr: 0.0010\n",
            "Epoch 45/500\n",
            "15/15 [==============================] - 4s 242ms/step - loss: 0.0071 - mae: 0.0441 - val_loss: 0.0064 - val_mae: 0.0434 - lr: 0.0010\n",
            "Epoch 46/500\n",
            "15/15 [==============================] - 4s 244ms/step - loss: 0.0092 - mae: 0.0522 - val_loss: 0.0065 - val_mae: 0.0467 - lr: 0.0010\n",
            "Epoch 47/500\n",
            "15/15 [==============================] - 5s 306ms/step - loss: 0.0069 - mae: 0.0443 - val_loss: 0.0059 - val_mae: 0.0411 - lr: 0.0010\n",
            "Epoch 48/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 0.0091 - mae: 0.0522 - val_loss: 0.0065 - val_mae: 0.0489 - lr: 0.0010\n",
            "Epoch 49/500\n",
            "15/15 [==============================] - 4s 283ms/step - loss: 0.0068 - mae: 0.0447 - val_loss: 0.0061 - val_mae: 0.0445 - lr: 0.0010\n",
            "Epoch 50/500\n",
            "15/15 [==============================] - 5s 332ms/step - loss: 0.0090 - mae: 0.0535 - val_loss: 0.0062 - val_mae: 0.0473 - lr: 0.0010\n",
            "Epoch 51/500\n",
            "15/15 [==============================] - 8s 514ms/step - loss: 0.0065 - mae: 0.0443 - val_loss: 0.0056 - val_mae: 0.0418 - lr: 0.0010\n",
            "Epoch 52/500\n",
            "15/15 [==============================] - 7s 456ms/step - loss: 0.0085 - mae: 0.0508 - val_loss: 0.0063 - val_mae: 0.0507 - lr: 0.0010\n",
            "Epoch 53/500\n",
            "15/15 [==============================] - 5s 344ms/step - loss: 0.0062 - mae: 0.0439 - val_loss: 0.0058 - val_mae: 0.0453 - lr: 0.0010\n",
            "Epoch 54/500\n",
            "15/15 [==============================] - 4s 240ms/step - loss: 0.0083 - mae: 0.0522 - val_loss: 0.0059 - val_mae: 0.0482 - lr: 0.0010\n",
            "Epoch 55/500\n",
            "15/15 [==============================] - 8s 574ms/step - loss: 0.0059 - mae: 0.0432 - val_loss: 0.0053 - val_mae: 0.0432 - lr: 0.0010\n",
            "Epoch 56/500\n",
            "15/15 [==============================] - 4s 241ms/step - loss: 0.0077 - mae: 0.0492 - val_loss: 0.0060 - val_mae: 0.0519 - lr: 0.0010\n",
            "Epoch 57/500\n",
            "15/15 [==============================] - 5s 310ms/step - loss: 0.0058 - mae: 0.0429 - val_loss: 0.0055 - val_mae: 0.0461 - lr: 0.0010\n",
            "Epoch 58/500\n",
            "15/15 [==============================] - 5s 360ms/step - loss: 0.0077 - mae: 0.0510 - val_loss: 0.0058 - val_mae: 0.0501 - lr: 0.0010\n",
            "Epoch 59/500\n",
            "15/15 [==============================] - 5s 340ms/step - loss: 0.0056 - mae: 0.0431 - val_loss: 0.0051 - val_mae: 0.0438 - lr: 0.0010\n",
            "Epoch 60/500\n",
            "15/15 [==============================] - 4s 275ms/step - loss: 0.0071 - mae: 0.0481 - val_loss: 0.0058 - val_mae: 0.0521 - lr: 0.0010\n",
            "Epoch 61/500\n",
            "15/15 [==============================] - 4s 247ms/step - loss: 0.0054 - mae: 0.0423 - val_loss: 0.0052 - val_mae: 0.0459 - lr: 0.0010\n",
            "Epoch 62/500\n",
            "15/15 [==============================] - 9s 604ms/step - loss: 0.0071 - mae: 0.0496 - val_loss: 0.0055 - val_mae: 0.0508 - lr: 0.0010\n",
            "Epoch 63/500\n",
            "15/15 [==============================] - 7s 461ms/step - loss: 0.0054 - mae: 0.0430 - val_loss: 0.0049 - val_mae: 0.0442 - lr: 0.0010\n",
            "Epoch 64/500\n",
            "15/15 [==============================] - 6s 425ms/step - loss: 0.0067 - mae: 0.0479 - val_loss: 0.0057 - val_mae: 0.0535 - lr: 0.0010\n",
            "Epoch 65/500\n",
            "15/15 [==============================] - 6s 396ms/step - loss: 0.0053 - mae: 0.0426 - val_loss: 0.0051 - val_mae: 0.0443 - lr: 0.0010\n",
            "Epoch 66/500\n",
            "15/15 [==============================] - 4s 257ms/step - loss: 0.0077 - mae: 0.0514 - val_loss: 0.0058 - val_mae: 0.0548 - lr: 0.0010\n",
            "Epoch 67/500\n",
            "15/15 [==============================] - 4s 250ms/step - loss: 0.0057 - mae: 0.0436 - val_loss: 0.0049 - val_mae: 0.0394 - lr: 0.0010\n",
            "Epoch 68/500\n",
            "15/15 [==============================] - 6s 381ms/step - loss: 0.0081 - mae: 0.0531 - val_loss: 0.0062 - val_mae: 0.0556 - lr: 0.0010\n",
            "Epoch 69/500\n",
            "15/15 [==============================] - 4s 254ms/step - loss: 0.0055 - mae: 0.0444 - val_loss: 0.0053 - val_mae: 0.0477 - lr: 0.0010\n",
            "Epoch 70/500\n",
            "15/15 [==============================] - 6s 390ms/step - loss: 0.0065 - mae: 0.0468 - val_loss: 0.0057 - val_mae: 0.0524 - lr: 0.0010\n",
            "Epoch 71/500\n",
            "15/15 [==============================] - 5s 354ms/step - loss: 0.0051 - mae: 0.0413 - val_loss: 0.0052 - val_mae: 0.0477 - lr: 0.0010\n",
            "Epoch 72/500\n",
            "15/15 [==============================] - 7s 480ms/step - loss: 0.0039 - mae: 0.0332 - val_loss: 0.0049 - val_mae: 0.0442 - lr: 2.0000e-04\n",
            "Epoch 73/500\n",
            "15/15 [==============================] - 6s 392ms/step - loss: 0.0033 - mae: 0.0259 - val_loss: 0.0051 - val_mae: 0.0491 - lr: 2.0000e-04\n",
            "Epoch 74/500\n",
            "15/15 [==============================] - 6s 373ms/step - loss: 0.0031 - mae: 0.0260 - val_loss: 0.0052 - val_mae: 0.0511 - lr: 2.0000e-04\n",
            "Epoch 75/500\n",
            "15/15 [==============================] - 4s 252ms/step - loss: 0.0030 - mae: 0.0255 - val_loss: 0.0051 - val_mae: 0.0506 - lr: 2.0000e-04\n",
            "Epoch 76/500\n",
            "15/15 [==============================] - 5s 365ms/step - loss: 0.0030 - mae: 0.0252 - val_loss: 0.0049 - val_mae: 0.0497 - lr: 2.0000e-04\n",
            "Epoch 77/500\n",
            "15/15 [==============================] - 6s 379ms/step - loss: 0.0030 - mae: 0.0255 - val_loss: 0.0049 - val_mae: 0.0494 - lr: 2.0000e-04\n",
            "Epoch 78/500\n",
            "15/15 [==============================] - 6s 406ms/step - loss: 0.0028 - mae: 0.0246 - val_loss: 0.0048 - val_mae: 0.0493 - lr: 2.0000e-04\n",
            "Epoch 79/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0029 - mae: 0.0255 - val_loss: 0.0047 - val_mae: 0.0485 - lr: 2.0000e-04\n",
            "Epoch 80/500\n",
            "15/15 [==============================] - 7s 473ms/step - loss: 0.0029 - mae: 0.0250 - val_loss: 0.0047 - val_mae: 0.0482 - lr: 2.0000e-04\n",
            "Epoch 81/500\n",
            "15/15 [==============================] - 6s 411ms/step - loss: 0.0028 - mae: 0.0248 - val_loss: 0.0046 - val_mae: 0.0479 - lr: 2.0000e-04\n",
            "Epoch 82/500\n",
            "15/15 [==============================] - 7s 468ms/step - loss: 0.0028 - mae: 0.0247 - val_loss: 0.0045 - val_mae: 0.0474 - lr: 2.0000e-04\n",
            "Epoch 83/500\n",
            "15/15 [==============================] - 5s 341ms/step - loss: 0.0027 - mae: 0.0243 - val_loss: 0.0045 - val_mae: 0.0468 - lr: 2.0000e-04\n",
            "Epoch 84/500\n",
            "15/15 [==============================] - 7s 441ms/step - loss: 0.0027 - mae: 0.0244 - val_loss: 0.0044 - val_mae: 0.0460 - lr: 2.0000e-04\n",
            "Epoch 85/500\n",
            "15/15 [==============================] - 6s 430ms/step - loss: 0.0027 - mae: 0.0244 - val_loss: 0.0043 - val_mae: 0.0457 - lr: 2.0000e-04\n",
            "Epoch 86/500\n",
            "15/15 [==============================] - 7s 487ms/step - loss: 0.0026 - mae: 0.0242 - val_loss: 0.0043 - val_mae: 0.0460 - lr: 2.0000e-04\n",
            "Epoch 87/500\n",
            "15/15 [==============================] - 5s 304ms/step - loss: 0.0026 - mae: 0.0244 - val_loss: 0.0042 - val_mae: 0.0453 - lr: 2.0000e-04\n",
            "Epoch 88/500\n",
            "15/15 [==============================] - 5s 311ms/step - loss: 0.0026 - mae: 0.0242 - val_loss: 0.0042 - val_mae: 0.0447 - lr: 2.0000e-04\n",
            "Epoch 89/500\n",
            "15/15 [==============================] - 4s 277ms/step - loss: 0.0026 - mae: 0.0245 - val_loss: 0.0041 - val_mae: 0.0438 - lr: 2.0000e-04\n",
            "Epoch 90/500\n",
            "15/15 [==============================] - 4s 270ms/step - loss: 0.0026 - mae: 0.0239 - val_loss: 0.0040 - val_mae: 0.0437 - lr: 2.0000e-04\n",
            "Epoch 91/500\n",
            "15/15 [==============================] - 4s 303ms/step - loss: 0.0026 - mae: 0.0240 - val_loss: 0.0040 - val_mae: 0.0439 - lr: 2.0000e-04\n",
            "Epoch 92/500\n",
            "15/15 [==============================] - 5s 304ms/step - loss: 0.0025 - mae: 0.0237 - val_loss: 0.0040 - val_mae: 0.0438 - lr: 2.0000e-04\n",
            "Epoch 93/500\n",
            "15/15 [==============================] - 4s 255ms/step - loss: 0.0025 - mae: 0.0240 - val_loss: 0.0040 - val_mae: 0.0435 - lr: 2.0000e-04\n",
            "Epoch 94/500\n",
            "15/15 [==============================] - 5s 338ms/step - loss: 0.0024 - mae: 0.0234 - val_loss: 0.0039 - val_mae: 0.0425 - lr: 2.0000e-04\n",
            "Epoch 95/500\n",
            "15/15 [==============================] - 7s 457ms/step - loss: 0.0025 - mae: 0.0236 - val_loss: 0.0039 - val_mae: 0.0429 - lr: 2.0000e-04\n",
            "Epoch 96/500\n",
            "15/15 [==============================] - 5s 323ms/step - loss: 0.0024 - mae: 0.0232 - val_loss: 0.0040 - val_mae: 0.0441 - lr: 2.0000e-04\n",
            "Epoch 97/500\n",
            "15/15 [==============================] - 6s 351ms/step - loss: 0.0024 - mae: 0.0228 - val_loss: 0.0039 - val_mae: 0.0434 - lr: 2.0000e-04\n",
            "Epoch 98/500\n",
            "15/15 [==============================] - 5s 371ms/step - loss: 0.0023 - mae: 0.0227 - val_loss: 0.0037 - val_mae: 0.0419 - lr: 2.0000e-04\n",
            "Epoch 99/500\n",
            "15/15 [==============================] - 4s 254ms/step - loss: 0.0023 - mae: 0.0225 - val_loss: 0.0038 - val_mae: 0.0428 - lr: 2.0000e-04\n",
            "Epoch 100/500\n",
            "15/15 [==============================] - 6s 417ms/step - loss: 0.0024 - mae: 0.0233 - val_loss: 0.0039 - val_mae: 0.0435 - lr: 2.0000e-04\n",
            "Epoch 101/500\n",
            "15/15 [==============================] - 4s 259ms/step - loss: 0.0023 - mae: 0.0230 - val_loss: 0.0038 - val_mae: 0.0432 - lr: 2.0000e-04\n",
            "Epoch 102/500\n",
            "15/15 [==============================] - 4s 258ms/step - loss: 0.0023 - mae: 0.0226 - val_loss: 0.0038 - val_mae: 0.0428 - lr: 2.0000e-04\n",
            "Epoch 103/500\n",
            "15/15 [==============================] - 6s 388ms/step - loss: 0.0023 - mae: 0.0225 - val_loss: 0.0038 - val_mae: 0.0427 - lr: 2.0000e-04\n",
            "Epoch 104/500\n",
            "15/15 [==============================] - 4s 272ms/step - loss: 0.0023 - mae: 0.0224 - val_loss: 0.0038 - val_mae: 0.0429 - lr: 2.0000e-04\n",
            "Epoch 105/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 0.0022 - mae: 0.0222 - val_loss: 0.0036 - val_mae: 0.0417 - lr: 2.0000e-04\n",
            "Epoch 106/500\n",
            "15/15 [==============================] - 4s 247ms/step - loss: 0.0023 - mae: 0.0228 - val_loss: 0.0038 - val_mae: 0.0434 - lr: 2.0000e-04\n",
            "Epoch 107/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 0.0022 - mae: 0.0225 - val_loss: 0.0039 - val_mae: 0.0443 - lr: 2.0000e-04\n",
            "Epoch 108/500\n",
            "15/15 [==============================] - 4s 246ms/step - loss: 0.0021 - mae: 0.0217 - val_loss: 0.0036 - val_mae: 0.0419 - lr: 2.0000e-04\n",
            "Epoch 109/500\n",
            "15/15 [==============================] - 4s 244ms/step - loss: 0.0021 - mae: 0.0220 - val_loss: 0.0037 - val_mae: 0.0432 - lr: 2.0000e-04\n",
            "Epoch 110/500\n",
            "15/15 [==============================] - 6s 407ms/step - loss: 0.0021 - mae: 0.0220 - val_loss: 0.0037 - val_mae: 0.0432 - lr: 2.0000e-04\n",
            "Epoch 111/500\n",
            "15/15 [==============================] - 4s 269ms/step - loss: 0.0021 - mae: 0.0218 - val_loss: 0.0037 - val_mae: 0.0433 - lr: 2.0000e-04\n",
            "Epoch 112/500\n",
            "15/15 [==============================] - 4s 282ms/step - loss: 0.0022 - mae: 0.0219 - val_loss: 0.0037 - val_mae: 0.0430 - lr: 2.0000e-04\n",
            "Epoch 113/500\n",
            "15/15 [==============================] - 6s 396ms/step - loss: 0.0021 - mae: 0.0224 - val_loss: 0.0038 - val_mae: 0.0440 - lr: 2.0000e-04\n",
            "Epoch 114/500\n",
            "15/15 [==============================] - 5s 365ms/step - loss: 0.0021 - mae: 0.0213 - val_loss: 0.0038 - val_mae: 0.0441 - lr: 4.0000e-05\n",
            "Epoch 115/500\n",
            "15/15 [==============================] - 4s 283ms/step - loss: 0.0021 - mae: 0.0213 - val_loss: 0.0037 - val_mae: 0.0436 - lr: 4.0000e-05\n",
            "Epoch 116/500\n",
            "15/15 [==============================] - 4s 249ms/step - loss: 0.0022 - mae: 0.0222 - val_loss: 0.0037 - val_mae: 0.0429 - lr: 4.0000e-05\n",
            "Epoch 117/500\n",
            "15/15 [==============================] - 4s 279ms/step - loss: 0.0020 - mae: 0.0213 - val_loss: 0.0036 - val_mae: 0.0427 - lr: 4.0000e-05\n",
            "Epoch 118/500\n",
            "15/15 [==============================] - 4s 286ms/step - loss: 0.0021 - mae: 0.0220 - val_loss: 0.0037 - val_mae: 0.0430 - lr: 4.0000e-05\n",
            "Epoch 119/500\n",
            "15/15 [==============================] - 4s 261ms/step - loss: 0.0021 - mae: 0.0218 - val_loss: 0.0036 - val_mae: 0.0429 - lr: 4.0000e-05\n",
            "Epoch 120/500\n",
            "15/15 [==============================] - 5s 315ms/step - loss: 0.0020 - mae: 0.0207 - val_loss: 0.0036 - val_mae: 0.0427 - lr: 4.0000e-05\n",
            "Epoch 121/500\n",
            "15/15 [==============================] - 5s 303ms/step - loss: 0.0021 - mae: 0.0216 - val_loss: 0.0036 - val_mae: 0.0427 - lr: 4.0000e-05\n",
            "Epoch 122/500\n",
            "15/15 [==============================] - 4s 260ms/step - loss: 0.0021 - mae: 0.0216 - val_loss: 0.0036 - val_mae: 0.0427 - lr: 1.0000e-05\n",
            "Epoch 123/500\n",
            "15/15 [==============================] - 5s 333ms/step - loss: 0.0021 - mae: 0.0215 - val_loss: 0.0036 - val_mae: 0.0426 - lr: 1.0000e-05\n",
            "Epoch 124/500\n",
            "15/15 [==============================] - 5s 298ms/step - loss: 0.0021 - mae: 0.0217 - val_loss: 0.0036 - val_mae: 0.0425 - lr: 1.0000e-05\n",
            "Epoch 125/500\n",
            "15/15 [==============================] - 4s 247ms/step - loss: 0.0021 - mae: 0.0216 - val_loss: 0.0036 - val_mae: 0.0424 - lr: 1.0000e-05\n",
            "Epoch 126/500\n",
            "15/15 [==============================] - 4s 251ms/step - loss: 0.0020 - mae: 0.0214 - val_loss: 0.0036 - val_mae: 0.0423 - lr: 1.0000e-05\n",
            "Epoch 127/500\n",
            "15/15 [==============================] - 6s 392ms/step - loss: 0.0021 - mae: 0.0215 - val_loss: 0.0036 - val_mae: 0.0423 - lr: 1.0000e-05\n",
            "Epoch 128/500\n",
            "15/15 [==============================] - 4s 251ms/step - loss: 0.0021 - mae: 0.0214 - val_loss: 0.0036 - val_mae: 0.0424 - lr: 1.0000e-05\n",
            "Epoch 129/500\n",
            "15/15 [==============================] - 4s 254ms/step - loss: 0.0021 - mae: 0.0220 - val_loss: 0.0036 - val_mae: 0.0424 - lr: 1.0000e-05\n",
            "Epoch 130/500\n",
            "15/15 [==============================] - 5s 356ms/step - loss: 0.0021 - mae: 0.0219 - val_loss: 0.0036 - val_mae: 0.0424 - lr: 1.0000e-05\n",
            "Epoch 131/500\n",
            "15/15 [==============================] - 4s 248ms/step - loss: 0.0021 - mae: 0.0216 - val_loss: 0.0036 - val_mae: 0.0425 - lr: 1.0000e-05\n",
            "Epoch 132/500\n",
            "15/15 [==============================] - 4s 245ms/step - loss: 0.0021 - mae: 0.0223 - val_loss: 0.0036 - val_mae: 0.0426 - lr: 1.0000e-05\n",
            "Epoch 133/500\n",
            "15/15 [==============================] - 6s 390ms/step - loss: 0.0020 - mae: 0.0207 - val_loss: 0.0036 - val_mae: 0.0426 - lr: 1.0000e-05\n",
            "Epoch 134/500\n",
            "15/15 [==============================] - 4s 264ms/step - loss: 0.0021 - mae: 0.0216 - val_loss: 0.0036 - val_mae: 0.0427 - lr: 1.0000e-05\n",
            "Epoch 135/500\n",
            "15/15 [==============================] - 7s 486ms/step - loss: 0.0021 - mae: 0.0215 - val_loss: 0.0036 - val_mae: 0.0427 - lr: 1.0000e-05\n",
            "Epoch 136/500\n",
            "15/15 [==============================] - 4s 257ms/step - loss: 0.0021 - mae: 0.0219 - val_loss: 0.0036 - val_mae: 0.0428 - lr: 1.0000e-05\n",
            "Epoch 137/500\n",
            "15/15 [==============================] - 4s 277ms/step - loss: 0.0020 - mae: 0.0211 - val_loss: 0.0036 - val_mae: 0.0428 - lr: 1.0000e-05\n",
            "Epoch 138/500\n",
            "15/15 [==============================] - 5s 356ms/step - loss: 0.0020 - mae: 0.0208 - val_loss: 0.0036 - val_mae: 0.0427 - lr: 1.0000e-05\n",
            "Epoch 139/500\n",
            "15/15 [==============================] - 4s 280ms/step - loss: 0.0021 - mae: 0.0217 - val_loss: 0.0036 - val_mae: 0.0427 - lr: 1.0000e-05\n",
            "Epoch 140/500\n",
            "15/15 [==============================] - 5s 350ms/step - loss: 0.0020 - mae: 0.0212 - val_loss: 0.0036 - val_mae: 0.0428 - lr: 1.0000e-05\n",
            "Epoch 141/500\n",
            "15/15 [==============================] - 4s 273ms/step - loss: 0.0021 - mae: 0.0215 - val_loss: 0.0036 - val_mae: 0.0429 - lr: 1.0000e-05\n",
            "Epoch 142/500\n",
            "15/15 [==============================] - 5s 355ms/step - loss: 0.0021 - mae: 0.0217 - val_loss: 0.0036 - val_mae: 0.0430 - lr: 1.0000e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "big_batches_model.save(\"/content/drive/MyDrive/CRYPTO/Models/big_batches_model.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbLhExxzBbrF",
        "outputId": "ebf567b7-cb28-4f29-9aae-3ce7ffa0f64e"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "big_batches_model_loaded=load_model(\"/content/drive/MyDrive/CRYPTO/Models/big_batches_model.h5\")"
      ],
      "metadata": {
        "id": "w-Qip0uIYKQq"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "big_batches_model_loaded.evaluate(X_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s15P5TS5i5_b",
        "outputId": "cc4e1b3b-74a6-49a0-e660-5fe4add0a071"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 6s 73ms/step - loss: 0.0036 - mae: 0.0423\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0035809408873319626, 0.04231996461749077]"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BATCH_SIZE=32 jest najlepszym rozwiązaniem"
      ],
      "metadata": {
        "id": "THgGEe4ii_cN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Spróbujemy zastąpić Bidirectional LSTM na zwykł LSTM"
      ],
      "metadata": {
        "id": "jkT5jSz2ZytQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scalers = [MinMaxScaler() for _ in range(DATA.shape[1])]\n",
        "\n",
        "DATA_scaled = np.hstack([scaler.fit_transform(DATA[:, [i]]) for i, scaler in enumerate(scalers)])\n",
        "\n",
        "reshaped_data_X, reshaped_data_y=reshape_data_mlt_feature_changer(DATA_scaled,n_timesteps,final_indexes)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(reshaped_data_X, reshaped_data_y, test_size=0.2, random_state=42,shuffle=False)\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
        "\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE)\n",
        "\n",
        "train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "test_dataset = test_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "\n",
        "\n",
        "LSTM_model = Sequential()\n",
        "LSTM_model.add(LSTM(128, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True))\n",
        "LSTM_model.add(Dropout(0.2))\n",
        "LSTM_model.add(LSTM(64, return_sequences=False))\n",
        "LSTM_model.add(Dense(1))\n",
        "\n",
        "\n",
        "# Compile the big_batches_model with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.001)  # Adjust the learning rate as needed\n",
        "LSTM_model.compile(optimizer=optimizer, loss='mse',metrics=[\"mae\"])\n",
        "\n",
        "# Add a callback to reduce learning rate on plateau\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=8, min_lr=0.00001)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
        "callbacks = [reduce_lr,early_stopping]\n",
        "\n",
        "# Train the big_batches_model with callbacks\n",
        "history = LSTM_model.fit(train_dataset, epochs=500, batch_size=128, validation_data=test_dataset, callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxFcXC5uYOml",
        "outputId": "e03fbd93-9ca3-43d4-8dfb-262659d67367"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "15/15 [==============================] - 13s 277ms/step - loss: 0.0214 - mae: 0.1244 - val_loss: 0.0104 - val_mae: 0.0603 - lr: 0.0010\n",
            "Epoch 2/500\n",
            "15/15 [==============================] - 3s 212ms/step - loss: 0.0483 - mae: 0.1493 - val_loss: 0.0931 - val_mae: 0.3017 - lr: 0.0010\n",
            "Epoch 3/500\n",
            "15/15 [==============================] - 2s 152ms/step - loss: 0.0217 - mae: 0.1109 - val_loss: 0.0065 - val_mae: 0.0743 - lr: 0.0010\n",
            "Epoch 4/500\n",
            "15/15 [==============================] - 2s 163ms/step - loss: 0.0297 - mae: 0.1437 - val_loss: 0.0439 - val_mae: 0.1820 - lr: 0.0010\n",
            "Epoch 5/500\n",
            "15/15 [==============================] - 2s 152ms/step - loss: 0.0614 - mae: 0.1561 - val_loss: 0.0169 - val_mae: 0.0817 - lr: 0.0010\n",
            "Epoch 6/500\n",
            "15/15 [==============================] - 4s 275ms/step - loss: 0.0107 - mae: 0.0944 - val_loss: 0.0045 - val_mae: 0.0506 - lr: 0.0010\n",
            "Epoch 7/500\n",
            "15/15 [==============================] - 2s 149ms/step - loss: 0.0023 - mae: 0.0338 - val_loss: 0.0032 - val_mae: 0.0512 - lr: 0.0010\n",
            "Epoch 8/500\n",
            "15/15 [==============================] - 3s 187ms/step - loss: 0.0018 - mae: 0.0307 - val_loss: 0.0015 - val_mae: 0.0244 - lr: 0.0010\n",
            "Epoch 9/500\n",
            "15/15 [==============================] - 6s 386ms/step - loss: 0.0035 - mae: 0.0429 - val_loss: 0.0060 - val_mae: 0.0734 - lr: 0.0010\n",
            "Epoch 10/500\n",
            "15/15 [==============================] - 5s 330ms/step - loss: 0.0031 - mae: 0.0473 - val_loss: 0.0020 - val_mae: 0.0309 - lr: 0.0010\n",
            "Epoch 11/500\n",
            "15/15 [==============================] - 4s 278ms/step - loss: 0.0045 - mae: 0.0561 - val_loss: 0.0054 - val_mae: 0.0693 - lr: 0.0010\n",
            "Epoch 12/500\n",
            "15/15 [==============================] - 6s 393ms/step - loss: 0.0035 - mae: 0.0508 - val_loss: 0.0019 - val_mae: 0.0278 - lr: 0.0010\n",
            "Epoch 13/500\n",
            "15/15 [==============================] - 5s 323ms/step - loss: 0.0056 - mae: 0.0587 - val_loss: 0.0039 - val_mae: 0.0582 - lr: 0.0010\n",
            "Epoch 14/500\n",
            "15/15 [==============================] - 5s 332ms/step - loss: 0.0046 - mae: 0.0567 - val_loss: 0.0023 - val_mae: 0.0291 - lr: 0.0010\n",
            "Epoch 15/500\n",
            "15/15 [==============================] - 4s 272ms/step - loss: 0.0090 - mae: 0.0719 - val_loss: 0.0023 - val_mae: 0.0418 - lr: 0.0010\n",
            "Epoch 16/500\n",
            "15/15 [==============================] - 4s 244ms/step - loss: 0.0052 - mae: 0.0621 - val_loss: 0.0018 - val_mae: 0.0279 - lr: 0.0010\n",
            "Epoch 17/500\n",
            "15/15 [==============================] - 5s 329ms/step - loss: 0.0024 - mae: 0.0338 - val_loss: 0.0022 - val_mae: 0.0270 - lr: 2.0000e-04\n",
            "Epoch 18/500\n",
            "15/15 [==============================] - 4s 258ms/step - loss: 0.0016 - mae: 0.0284 - val_loss: 0.0017 - val_mae: 0.0308 - lr: 2.0000e-04\n",
            "Epoch 19/500\n",
            "15/15 [==============================] - 3s 172ms/step - loss: 0.0012 - mae: 0.0234 - val_loss: 0.0019 - val_mae: 0.0377 - lr: 2.0000e-04\n",
            "Epoch 20/500\n",
            "15/15 [==============================] - 4s 246ms/step - loss: 0.0011 - mae: 0.0231 - val_loss: 0.0019 - val_mae: 0.0386 - lr: 2.0000e-04\n",
            "Epoch 21/500\n",
            "15/15 [==============================] - 4s 242ms/step - loss: 0.0011 - mae: 0.0221 - val_loss: 0.0018 - val_mae: 0.0367 - lr: 2.0000e-04\n",
            "Epoch 22/500\n",
            "15/15 [==============================] - 3s 179ms/step - loss: 0.0011 - mae: 0.0225 - val_loss: 0.0017 - val_mae: 0.0354 - lr: 2.0000e-04\n",
            "Epoch 23/500\n",
            "15/15 [==============================] - 6s 392ms/step - loss: 0.0010 - mae: 0.0220 - val_loss: 0.0016 - val_mae: 0.0351 - lr: 2.0000e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LSTM_model.save(\"/content/drive/MyDrive/CRYPTO/Models/LSTM_batches_model.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATASL8sEjPGD",
        "outputId": "9abba590-e510-4cfc-c937-582f8c6f58bb"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LSTM_model_loaded=load_model(\"/content/drive/MyDrive/CRYPTO/Models/LSTM_batches_model.h5\")"
      ],
      "metadata": {
        "id": "TBm-dF_mjaFi"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LSTM_model_loaded.evaluate(X_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQ4w_4apjjxy",
        "outputId": "12575ac2-8436-46d1-ed39-b5d923241625"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 3s 40ms/step - loss: 0.0015 - mae: 0.0244\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0015461184084415436, 0.024416744709014893]"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Zwykły LSTM radzi sobie lepiej\n",
        "\n",
        "Możemy sprawdzić jeszcze warstwę GRU, tak samo jak LSTM jest to warstwa przeznaczona do przewidywania sekwencji."
      ],
      "metadata": {
        "id": "RC9SWhuRkFcW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import GRU\n",
        "scalers = [MinMaxScaler() for _ in range(DATA.shape[1])]\n",
        "\n",
        "DATA_scaled = np.hstack([scaler.fit_transform(DATA[:, [i]]) for i, scaler in enumerate(scalers)])\n",
        "\n",
        "reshaped_data_X, reshaped_data_y=reshape_data_mlt_feature_changer(DATA_scaled,n_timesteps,final_indexes)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(reshaped_data_X, reshaped_data_y, test_size=0.2, random_state=42,shuffle=False)\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
        "\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE)\n",
        "\n",
        "train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "test_dataset = test_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "\n",
        "\n",
        "GRU_model = Sequential()\n",
        "GRU_model.add(GRU(128, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True))\n",
        "GRU_model.add(Dropout(0.2))\n",
        "GRU_model.add(GRU(64, return_sequences=False))\n",
        "GRU_model.add(Dense(1))\n",
        "\n",
        "\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "GRU_model.compile(optimizer=optimizer, loss='mse',metrics=[\"mae\"])\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=8, min_lr=0.00001)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
        "callbacks = [reduce_lr,early_stopping]\n",
        "\n",
        "history = GRU_model.fit(train_dataset, epochs=500, batch_size=128, validation_data=test_dataset, callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TaVbrk4Rj7S3",
        "outputId": "b85ea193-c777-47e6-fc83-eea2130cb2be"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "15/15 [==============================] - 11s 229ms/step - loss: 0.0167 - mae: 0.1075 - val_loss: 0.0077 - val_mae: 0.0553 - lr: 0.0010\n",
            "Epoch 2/500\n",
            "15/15 [==============================] - 3s 222ms/step - loss: 0.0386 - mae: 0.1399 - val_loss: 0.2419 - val_mae: 0.4863 - lr: 0.0010\n",
            "Epoch 3/500\n",
            "15/15 [==============================] - 2s 135ms/step - loss: 0.0501 - mae: 0.1634 - val_loss: 0.0087 - val_mae: 0.0838 - lr: 0.0010\n",
            "Epoch 4/500\n",
            "15/15 [==============================] - 2s 141ms/step - loss: 0.0673 - mae: 0.2241 - val_loss: 0.0358 - val_mae: 0.1603 - lr: 0.0010\n",
            "Epoch 5/500\n",
            "15/15 [==============================] - 2s 131ms/step - loss: 0.0927 - mae: 0.2049 - val_loss: 0.0061 - val_mae: 0.0526 - lr: 0.0010\n",
            "Epoch 6/500\n",
            "15/15 [==============================] - 4s 297ms/step - loss: 0.0155 - mae: 0.1118 - val_loss: 0.0047 - val_mae: 0.0515 - lr: 0.0010\n",
            "Epoch 7/500\n",
            "15/15 [==============================] - 2s 126ms/step - loss: 0.0146 - mae: 0.1026 - val_loss: 0.0044 - val_mae: 0.0624 - lr: 0.0010\n",
            "Epoch 8/500\n",
            "15/15 [==============================] - 2s 148ms/step - loss: 0.0106 - mae: 0.0916 - val_loss: 8.6913e-04 - val_mae: 0.0194 - lr: 0.0010\n",
            "Epoch 9/500\n",
            "15/15 [==============================] - 2s 148ms/step - loss: 0.0084 - mae: 0.0708 - val_loss: 0.0012 - val_mae: 0.0204 - lr: 0.0010\n",
            "Epoch 10/500\n",
            "15/15 [==============================] - 2s 143ms/step - loss: 0.0030 - mae: 0.0442 - val_loss: 0.0014 - val_mae: 0.0327 - lr: 0.0010\n",
            "Epoch 11/500\n",
            "15/15 [==============================] - 3s 232ms/step - loss: 0.0023 - mae: 0.0325 - val_loss: 7.4714e-04 - val_mae: 0.0174 - lr: 0.0010\n",
            "Epoch 12/500\n",
            "15/15 [==============================] - 2s 133ms/step - loss: 0.0013 - mae: 0.0264 - val_loss: 9.7605e-04 - val_mae: 0.0260 - lr: 0.0010\n",
            "Epoch 13/500\n",
            "15/15 [==============================] - 2s 137ms/step - loss: 0.0012 - mae: 0.0244 - val_loss: 7.4660e-04 - val_mae: 0.0211 - lr: 0.0010\n",
            "Epoch 14/500\n",
            "15/15 [==============================] - 2s 142ms/step - loss: 0.0011 - mae: 0.0231 - val_loss: 8.9096e-04 - val_mae: 0.0241 - lr: 0.0010\n",
            "Epoch 15/500\n",
            "15/15 [==============================] - 2s 140ms/step - loss: 0.0011 - mae: 0.0231 - val_loss: 8.7195e-04 - val_mae: 0.0237 - lr: 0.0010\n",
            "Epoch 16/500\n",
            "15/15 [==============================] - 3s 232ms/step - loss: 9.5244e-04 - mae: 0.0221 - val_loss: 8.0135e-04 - val_mae: 0.0222 - lr: 0.0010\n",
            "Epoch 17/500\n",
            "15/15 [==============================] - 2s 145ms/step - loss: 0.0010 - mae: 0.0229 - val_loss: 8.8582e-04 - val_mae: 0.0239 - lr: 0.0010\n",
            "Epoch 18/500\n",
            "15/15 [==============================] - 2s 131ms/step - loss: 9.7382e-04 - mae: 0.0223 - val_loss: 8.6836e-04 - val_mae: 0.0234 - lr: 0.0010\n",
            "Epoch 19/500\n",
            "15/15 [==============================] - 2s 133ms/step - loss: 9.0381e-04 - mae: 0.0218 - val_loss: 9.8510e-04 - val_mae: 0.0254 - lr: 0.0010\n",
            "Epoch 20/500\n",
            "15/15 [==============================] - 2s 164ms/step - loss: 9.2315e-04 - mae: 0.0215 - val_loss: 9.4902e-04 - val_mae: 0.0248 - lr: 2.0000e-04\n",
            "Epoch 21/500\n",
            "15/15 [==============================] - 4s 235ms/step - loss: 9.1816e-04 - mae: 0.0217 - val_loss: 8.5127e-04 - val_mae: 0.0229 - lr: 2.0000e-04\n",
            "Epoch 22/500\n",
            "15/15 [==============================] - 2s 130ms/step - loss: 9.5608e-04 - mae: 0.0218 - val_loss: 8.4387e-04 - val_mae: 0.0228 - lr: 2.0000e-04\n",
            "Epoch 23/500\n",
            "15/15 [==============================] - 2s 137ms/step - loss: 9.0684e-04 - mae: 0.0213 - val_loss: 9.1590e-04 - val_mae: 0.0241 - lr: 2.0000e-04\n",
            "Epoch 24/500\n",
            "15/15 [==============================] - 2s 139ms/step - loss: 8.7003e-04 - mae: 0.0212 - val_loss: 9.1653e-04 - val_mae: 0.0241 - lr: 2.0000e-04\n",
            "Epoch 25/500\n",
            "15/15 [==============================] - 3s 179ms/step - loss: 8.9283e-04 - mae: 0.0213 - val_loss: 8.7675e-04 - val_mae: 0.0234 - lr: 2.0000e-04\n",
            "Epoch 26/500\n",
            "15/15 [==============================] - 2s 128ms/step - loss: 8.4204e-04 - mae: 0.0207 - val_loss: 8.7158e-04 - val_mae: 0.0233 - lr: 2.0000e-04\n",
            "Epoch 27/500\n",
            "15/15 [==============================] - 2s 128ms/step - loss: 8.2532e-04 - mae: 0.0207 - val_loss: 8.7086e-04 - val_mae: 0.0233 - lr: 2.0000e-04\n",
            "Epoch 28/500\n",
            "15/15 [==============================] - 2s 128ms/step - loss: 9.3354e-04 - mae: 0.0212 - val_loss: 8.7672e-04 - val_mae: 0.0234 - lr: 4.0000e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GRU_model.evaluate(X_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfkODC18nVLH",
        "outputId": "e09ac6c7-1056-436e-edad-49308ee2f9e7"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 3s 33ms/step - loss: 7.4660e-04 - mae: 0.0211\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.000746600388083607, 0.02106551267206669]"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GRU_model.save(\"/content/drive/MyDrive/CRYPTO/Models/GRU_model.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOZnRj2dt-zq",
        "outputId": "1c7d0b70-1468-4ecf-f142-bfa84c336176"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GRU_model_loaded=load_model(\"/content/drive/MyDrive/CRYPTO/Models/GRU_model.h5\")"
      ],
      "metadata": {
        "id": "qu7ZdhqGuDo4"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model GRU sprawuje się lepiej niż LSTM\n",
        "\n",
        "Podstawowa funkcja aktywacyjna to tanh, funkcja nieliniowa\n",
        "\n",
        "Sprawdzimy jeszcze funkcję relu oraz sigmoid"
      ],
      "metadata": {
        "id": "h2Tnnm-OpBnL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scalers = [MinMaxScaler() for _ in range(DATA.shape[1])]\n",
        "\n",
        "DATA_scaled = np.hstack([scaler.fit_transform(DATA[:, [i]]) for i, scaler in enumerate(scalers)])\n",
        "\n",
        "reshaped_data_X, reshaped_data_y=reshape_data_mlt_feature_changer(DATA_scaled,n_timesteps,final_indexes)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(reshaped_data_X, reshaped_data_y, test_size=0.2, random_state=42,shuffle=False)\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
        "\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE)\n",
        "\n",
        "train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "test_dataset = test_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "\n",
        "\n",
        "GRU_relu_model = Sequential()\n",
        "GRU_relu_model.add(GRU(128, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True,activation=\"relu\"))\n",
        "GRU_relu_model.add(Dropout(0.2))\n",
        "GRU_relu_model.add(GRU(64, return_sequences=False,activation=\"relu\"))\n",
        "GRU_relu_model.add(Dense(1))\n",
        "\n",
        "\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "GRU_relu_model.compile(optimizer=optimizer, loss='mse',metrics=[\"mae\"])\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=8, min_lr=0.00001)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
        "callbacks = [reduce_lr,early_stopping]\n",
        "\n",
        "history = GRU_relu_model.fit(train_dataset, epochs=500, batch_size=128, validation_data=test_dataset, callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRdJXJ3UnVjc",
        "outputId": "b11d287c-59dd-4ac1-917f-5c2e5270e8ef"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "15/15 [==============================] - 7s 170ms/step - loss: 0.0288 - mae: 0.1175 - val_loss: 0.0191 - val_mae: 0.1294 - lr: 0.0010\n",
            "Epoch 2/500\n",
            "15/15 [==============================] - 2s 124ms/step - loss: 0.0188 - mae: 0.1148 - val_loss: 0.0363 - val_mae: 0.1780 - lr: 0.0010\n",
            "Epoch 3/500\n",
            "15/15 [==============================] - 2s 136ms/step - loss: 0.0536 - mae: 0.2035 - val_loss: 0.0108 - val_mae: 0.0715 - lr: 0.0010\n",
            "Epoch 4/500\n",
            "15/15 [==============================] - 2s 149ms/step - loss: 0.0074 - mae: 0.0775 - val_loss: 0.0035 - val_mae: 0.0480 - lr: 0.0010\n",
            "Epoch 5/500\n",
            "15/15 [==============================] - 4s 275ms/step - loss: 0.0055 - mae: 0.0554 - val_loss: 0.0029 - val_mae: 0.0368 - lr: 0.0010\n",
            "Epoch 6/500\n",
            "15/15 [==============================] - 4s 246ms/step - loss: 0.0026 - mae: 0.0385 - val_loss: 0.0018 - val_mae: 0.0312 - lr: 0.0010\n",
            "Epoch 7/500\n",
            "15/15 [==============================] - 3s 219ms/step - loss: 0.0027 - mae: 0.0338 - val_loss: 0.0015 - val_mae: 0.0288 - lr: 0.0010\n",
            "Epoch 8/500\n",
            "15/15 [==============================] - 2s 159ms/step - loss: 0.0021 - mae: 0.0329 - val_loss: 0.0014 - val_mae: 0.0252 - lr: 0.0010\n",
            "Epoch 9/500\n",
            "15/15 [==============================] - 4s 268ms/step - loss: 0.0030 - mae: 0.0361 - val_loss: 0.0014 - val_mae: 0.0303 - lr: 0.0010\n",
            "Epoch 10/500\n",
            "15/15 [==============================] - 4s 252ms/step - loss: 0.0028 - mae: 0.0370 - val_loss: 0.0014 - val_mae: 0.0245 - lr: 0.0010\n",
            "Epoch 11/500\n",
            "15/15 [==============================] - 3s 213ms/step - loss: 0.0048 - mae: 0.0458 - val_loss: 0.0015 - val_mae: 0.0323 - lr: 0.0010\n",
            "Epoch 12/500\n",
            "15/15 [==============================] - 6s 424ms/step - loss: 0.0046 - mae: 0.0477 - val_loss: 0.0019 - val_mae: 0.0265 - lr: 0.0010\n",
            "Epoch 13/500\n",
            "15/15 [==============================] - 3s 189ms/step - loss: 0.0087 - mae: 0.0632 - val_loss: 0.0017 - val_mae: 0.0284 - lr: 0.0010\n",
            "Epoch 14/500\n",
            "15/15 [==============================] - 4s 258ms/step - loss: 0.0055 - mae: 0.0547 - val_loss: 0.0019 - val_mae: 0.0297 - lr: 0.0010\n",
            "Epoch 15/500\n",
            "15/15 [==============================] - 5s 325ms/step - loss: 0.0087 - mae: 0.0615 - val_loss: 0.0023 - val_mae: 0.0304 - lr: 0.0010\n",
            "Epoch 16/500\n",
            "15/15 [==============================] - 4s 244ms/step - loss: 0.0037 - mae: 0.0447 - val_loss: 0.0016 - val_mae: 0.0317 - lr: 0.0010\n",
            "Epoch 17/500\n",
            "15/15 [==============================] - 3s 200ms/step - loss: 0.0015 - mae: 0.0262 - val_loss: 0.0017 - val_mae: 0.0275 - lr: 2.0000e-04\n",
            "Epoch 18/500\n",
            "15/15 [==============================] - 5s 328ms/step - loss: 0.0015 - mae: 0.0261 - val_loss: 0.0015 - val_mae: 0.0275 - lr: 2.0000e-04\n",
            "Epoch 19/500\n",
            "15/15 [==============================] - 4s 250ms/step - loss: 0.0014 - mae: 0.0253 - val_loss: 0.0014 - val_mae: 0.0290 - lr: 2.0000e-04\n",
            "Epoch 20/500\n",
            "15/15 [==============================] - 4s 259ms/step - loss: 0.0013 - mae: 0.0250 - val_loss: 0.0014 - val_mae: 0.0295 - lr: 2.0000e-04\n",
            "Epoch 21/500\n",
            "15/15 [==============================] - 5s 330ms/step - loss: 0.0013 - mae: 0.0249 - val_loss: 0.0013 - val_mae: 0.0287 - lr: 2.0000e-04\n",
            "Epoch 22/500\n",
            "15/15 [==============================] - 5s 322ms/step - loss: 0.0012 - mae: 0.0240 - val_loss: 0.0013 - val_mae: 0.0281 - lr: 2.0000e-04\n",
            "Epoch 23/500\n",
            "15/15 [==============================] - 4s 259ms/step - loss: 0.0012 - mae: 0.0238 - val_loss: 0.0012 - val_mae: 0.0281 - lr: 2.0000e-04\n",
            "Epoch 24/500\n",
            "15/15 [==============================] - 4s 285ms/step - loss: 0.0011 - mae: 0.0234 - val_loss: 0.0012 - val_mae: 0.0278 - lr: 2.0000e-04\n",
            "Epoch 25/500\n",
            "15/15 [==============================] - 5s 363ms/step - loss: 0.0011 - mae: 0.0233 - val_loss: 0.0012 - val_mae: 0.0274 - lr: 2.0000e-04\n",
            "Epoch 26/500\n",
            "15/15 [==============================] - 4s 242ms/step - loss: 0.0011 - mae: 0.0232 - val_loss: 0.0011 - val_mae: 0.0271 - lr: 2.0000e-04\n",
            "Epoch 27/500\n",
            "15/15 [==============================] - 4s 277ms/step - loss: 0.0011 - mae: 0.0229 - val_loss: 0.0011 - val_mae: 0.0274 - lr: 2.0000e-04\n",
            "Epoch 28/500\n",
            "15/15 [==============================] - 3s 194ms/step - loss: 0.0010 - mae: 0.0224 - val_loss: 0.0011 - val_mae: 0.0278 - lr: 2.0000e-04\n",
            "Epoch 29/500\n",
            "15/15 [==============================] - 2s 141ms/step - loss: 0.0010 - mae: 0.0221 - val_loss: 0.0011 - val_mae: 0.0275 - lr: 2.0000e-04\n",
            "Epoch 30/500\n",
            "15/15 [==============================] - 2s 150ms/step - loss: 9.9206e-04 - mae: 0.0219 - val_loss: 0.0011 - val_mae: 0.0270 - lr: 2.0000e-04\n",
            "Epoch 31/500\n",
            "15/15 [==============================] - 3s 232ms/step - loss: 0.0010 - mae: 0.0221 - val_loss: 0.0011 - val_mae: 0.0268 - lr: 2.0000e-04\n",
            "Epoch 32/500\n",
            "15/15 [==============================] - 2s 125ms/step - loss: 9.9570e-04 - mae: 0.0220 - val_loss: 0.0011 - val_mae: 0.0271 - lr: 2.0000e-04\n",
            "Epoch 33/500\n",
            "15/15 [==============================] - 2s 126ms/step - loss: 9.5097e-04 - mae: 0.0215 - val_loss: 0.0011 - val_mae: 0.0269 - lr: 2.0000e-04\n",
            "Epoch 34/500\n",
            "15/15 [==============================] - 2s 124ms/step - loss: 9.8348e-04 - mae: 0.0217 - val_loss: 0.0011 - val_mae: 0.0275 - lr: 2.0000e-04\n",
            "Epoch 35/500\n",
            "15/15 [==============================] - 2s 142ms/step - loss: 9.1533e-04 - mae: 0.0211 - val_loss: 0.0012 - val_mae: 0.0288 - lr: 2.0000e-04\n",
            "Epoch 36/500\n",
            "15/15 [==============================] - 3s 212ms/step - loss: 0.0010 - mae: 0.0219 - val_loss: 0.0012 - val_mae: 0.0288 - lr: 4.0000e-05\n",
            "Epoch 37/500\n",
            "15/15 [==============================] - 2s 125ms/step - loss: 9.4128e-04 - mae: 0.0213 - val_loss: 0.0012 - val_mae: 0.0285 - lr: 4.0000e-05\n",
            "Epoch 38/500\n",
            "15/15 [==============================] - 2s 126ms/step - loss: 9.2377e-04 - mae: 0.0212 - val_loss: 0.0012 - val_mae: 0.0284 - lr: 4.0000e-05\n",
            "Epoch 39/500\n",
            "15/15 [==============================] - 2s 137ms/step - loss: 9.4798e-04 - mae: 0.0212 - val_loss: 0.0011 - val_mae: 0.0284 - lr: 4.0000e-05\n",
            "Epoch 40/500\n",
            "15/15 [==============================] - 2s 124ms/step - loss: 9.0735e-04 - mae: 0.0208 - val_loss: 0.0011 - val_mae: 0.0281 - lr: 4.0000e-05\n",
            "Epoch 41/500\n",
            "15/15 [==============================] - 2s 147ms/step - loss: 9.3634e-04 - mae: 0.0213 - val_loss: 0.0011 - val_mae: 0.0279 - lr: 4.0000e-05\n",
            "Epoch 42/500\n",
            "15/15 [==============================] - 3s 228ms/step - loss: 9.4724e-04 - mae: 0.0215 - val_loss: 0.0011 - val_mae: 0.0278 - lr: 4.0000e-05\n",
            "Epoch 43/500\n",
            "15/15 [==============================] - 2s 141ms/step - loss: 9.5554e-04 - mae: 0.0214 - val_loss: 0.0011 - val_mae: 0.0279 - lr: 4.0000e-05\n",
            "Epoch 44/500\n",
            "15/15 [==============================] - 2s 124ms/step - loss: 9.2831e-04 - mae: 0.0214 - val_loss: 0.0011 - val_mae: 0.0279 - lr: 1.0000e-05\n",
            "Epoch 45/500\n",
            "15/15 [==============================] - 2s 134ms/step - loss: 9.4105e-04 - mae: 0.0211 - val_loss: 0.0011 - val_mae: 0.0280 - lr: 1.0000e-05\n",
            "Epoch 46/500\n",
            "15/15 [==============================] - 2s 123ms/step - loss: 9.1295e-04 - mae: 0.0210 - val_loss: 0.0011 - val_mae: 0.0280 - lr: 1.0000e-05\n",
            "Epoch 47/500\n",
            "15/15 [==============================] - 3s 178ms/step - loss: 8.8095e-04 - mae: 0.0209 - val_loss: 0.0011 - val_mae: 0.0279 - lr: 1.0000e-05\n",
            "Epoch 48/500\n",
            "15/15 [==============================] - 3s 212ms/step - loss: 8.7628e-04 - mae: 0.0206 - val_loss: 0.0011 - val_mae: 0.0279 - lr: 1.0000e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GRU_relu_model.evaluate(X_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IcAXa-OZp7tV",
        "outputId": "1b2a5058-55da-4ccc-81f7-b0ebda648af2"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 1s 24ms/step - loss: 0.0011 - mae: 0.0269\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0010715718381106853, 0.026895053684711456]"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GRU_relu_model.save(\"/content/drive/MyDrive/CRYPTO/Models/GRU_relu_model.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pxau8yQKvSce",
        "outputId": "ecc52322-f0c3-487c-d899-bc5770683562"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GRU_relu_model_loaded=load_model(\"/content/drive/MyDrive/CRYPTO/Models/GRU_relu_model.h5\")"
      ],
      "metadata": {
        "id": "Ay0HoNtJvboz"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import GRU\n",
        "scalers = [MinMaxScaler() for _ in range(DATA.shape[1])]\n",
        "\n",
        "DATA_scaled = np.hstack([scaler.fit_transform(DATA[:, [i]]) for i, scaler in enumerate(scalers)])\n",
        "\n",
        "reshaped_data_X, reshaped_data_y=reshape_data_mlt_feature_changer(DATA_scaled,n_timesteps,final_indexes)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(reshaped_data_X, reshaped_data_y, test_size=0.2, random_state=42,shuffle=False)\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
        "\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE)\n",
        "\n",
        "train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "test_dataset = test_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "\n",
        "\n",
        "GRU_sigmoid_model = Sequential()\n",
        "GRU_sigmoid_model.add(GRU(128, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True,activation=\"sigmoid\"))\n",
        "GRU_sigmoid_model.add(Dropout(0.2))\n",
        "GRU_sigmoid_model.add(GRU(64, return_sequences=False,activation=\"sigmoid\"))\n",
        "GRU_sigmoid_model.add(Dense(1))\n",
        "\n",
        "\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "GRU_sigmoid_model.compile(optimizer=optimizer, loss='mse',metrics=[\"mae\"])\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=8, min_lr=0.00001)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
        "callbacks = [reduce_lr,early_stopping]\n",
        "\n",
        "history = GRU_sigmoid_model.fit(train_dataset, epochs=500, batch_size=128, validation_data=test_dataset, callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYkfgOsEp75o",
        "outputId": "29d543ea-f62f-4b8a-b6c8-8deefe7eaa8f"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "15/15 [==============================] - 13s 459ms/step - loss: 0.0895 - mae: 0.2554 - val_loss: 0.0342 - val_mae: 0.1576 - lr: 0.0010\n",
            "Epoch 2/500\n",
            "15/15 [==============================] - 3s 208ms/step - loss: 0.1494 - mae: 0.3120 - val_loss: 0.0296 - val_mae: 0.1252 - lr: 0.0010\n",
            "Epoch 3/500\n",
            "15/15 [==============================] - 4s 279ms/step - loss: 0.1087 - mae: 0.2953 - val_loss: 0.0484 - val_mae: 0.1535 - lr: 0.0010\n",
            "Epoch 4/500\n",
            "15/15 [==============================] - 3s 218ms/step - loss: 0.0568 - mae: 0.1921 - val_loss: 0.0251 - val_mae: 0.1097 - lr: 0.0010\n",
            "Epoch 5/500\n",
            "15/15 [==============================] - 2s 126ms/step - loss: 0.0682 - mae: 0.2224 - val_loss: 0.0274 - val_mae: 0.1034 - lr: 0.0010\n",
            "Epoch 6/500\n",
            "15/15 [==============================] - 2s 138ms/step - loss: 0.0465 - mae: 0.1825 - val_loss: 0.0204 - val_mae: 0.0943 - lr: 0.0010\n",
            "Epoch 7/500\n",
            "15/15 [==============================] - 3s 211ms/step - loss: 0.0399 - mae: 0.1667 - val_loss: 0.0164 - val_mae: 0.0890 - lr: 0.0010\n",
            "Epoch 8/500\n",
            "15/15 [==============================] - 3s 180ms/step - loss: 0.0296 - mae: 0.1441 - val_loss: 0.0130 - val_mae: 0.0819 - lr: 0.0010\n",
            "Epoch 9/500\n",
            "15/15 [==============================] - 2s 138ms/step - loss: 0.0180 - mae: 0.1096 - val_loss: 0.0098 - val_mae: 0.0753 - lr: 0.0010\n",
            "Epoch 10/500\n",
            "15/15 [==============================] - 2s 139ms/step - loss: 0.0102 - mae: 0.0788 - val_loss: 0.0076 - val_mae: 0.0691 - lr: 0.0010\n",
            "Epoch 11/500\n",
            "15/15 [==============================] - 2s 126ms/step - loss: 0.0056 - mae: 0.0557 - val_loss: 0.0059 - val_mae: 0.0599 - lr: 0.0010\n",
            "Epoch 12/500\n",
            "15/15 [==============================] - 2s 128ms/step - loss: 0.0043 - mae: 0.0501 - val_loss: 0.0052 - val_mae: 0.0539 - lr: 0.0010\n",
            "Epoch 13/500\n",
            "15/15 [==============================] - 3s 234ms/step - loss: 0.0050 - mae: 0.0581 - val_loss: 0.0053 - val_mae: 0.0560 - lr: 0.0010\n",
            "Epoch 14/500\n",
            "15/15 [==============================] - 2s 161ms/step - loss: 0.0056 - mae: 0.0590 - val_loss: 0.0058 - val_mae: 0.0624 - lr: 0.0010\n",
            "Epoch 15/500\n",
            "15/15 [==============================] - 2s 129ms/step - loss: 0.0055 - mae: 0.0555 - val_loss: 0.0061 - val_mae: 0.0656 - lr: 0.0010\n",
            "Epoch 16/500\n",
            "15/15 [==============================] - 2s 130ms/step - loss: 0.0052 - mae: 0.0528 - val_loss: 0.0057 - val_mae: 0.0637 - lr: 0.0010\n",
            "Epoch 17/500\n",
            "15/15 [==============================] - 2s 127ms/step - loss: 0.0047 - mae: 0.0510 - val_loss: 0.0049 - val_mae: 0.0577 - lr: 0.0010\n",
            "Epoch 18/500\n",
            "15/15 [==============================] - 2s 125ms/step - loss: 0.0041 - mae: 0.0484 - val_loss: 0.0044 - val_mae: 0.0532 - lr: 0.0010\n",
            "Epoch 19/500\n",
            "15/15 [==============================] - 3s 214ms/step - loss: 0.0041 - mae: 0.0494 - val_loss: 0.0043 - val_mae: 0.0516 - lr: 0.0010\n",
            "Epoch 20/500\n",
            "15/15 [==============================] - 2s 132ms/step - loss: 0.0044 - mae: 0.0507 - val_loss: 0.0046 - val_mae: 0.0555 - lr: 0.0010\n",
            "Epoch 21/500\n",
            "15/15 [==============================] - 2s 138ms/step - loss: 0.0046 - mae: 0.0515 - val_loss: 0.0047 - val_mae: 0.0575 - lr: 0.0010\n",
            "Epoch 22/500\n",
            "15/15 [==============================] - 2s 139ms/step - loss: 0.0048 - mae: 0.0515 - val_loss: 0.0048 - val_mae: 0.0596 - lr: 0.0010\n",
            "Epoch 23/500\n",
            "15/15 [==============================] - 2s 137ms/step - loss: 0.0045 - mae: 0.0503 - val_loss: 0.0044 - val_mae: 0.0572 - lr: 0.0010\n",
            "Epoch 24/500\n",
            "15/15 [==============================] - 5s 285ms/step - loss: 0.0042 - mae: 0.0494 - val_loss: 0.0040 - val_mae: 0.0537 - lr: 0.0010\n",
            "Epoch 25/500\n",
            "15/15 [==============================] - 3s 239ms/step - loss: 0.0041 - mae: 0.0490 - val_loss: 0.0037 - val_mae: 0.0511 - lr: 0.0010\n",
            "Epoch 26/500\n",
            "15/15 [==============================] - 4s 292ms/step - loss: 0.0039 - mae: 0.0472 - val_loss: 0.0039 - val_mae: 0.0536 - lr: 0.0010\n",
            "Epoch 27/500\n",
            "15/15 [==============================] - 5s 344ms/step - loss: 0.0040 - mae: 0.0479 - val_loss: 0.0037 - val_mae: 0.0524 - lr: 0.0010\n",
            "Epoch 28/500\n",
            "15/15 [==============================] - 4s 248ms/step - loss: 0.0037 - mae: 0.0468 - val_loss: 0.0034 - val_mae: 0.0490 - lr: 0.0010\n",
            "Epoch 29/500\n",
            "15/15 [==============================] - 5s 336ms/step - loss: 0.0040 - mae: 0.0480 - val_loss: 0.0040 - val_mae: 0.0554 - lr: 0.0010\n",
            "Epoch 30/500\n",
            "15/15 [==============================] - 3s 212ms/step - loss: 0.0043 - mae: 0.0502 - val_loss: 0.0040 - val_mae: 0.0560 - lr: 0.0010\n",
            "Epoch 31/500\n",
            "15/15 [==============================] - 3s 209ms/step - loss: 0.0041 - mae: 0.0499 - val_loss: 0.0039 - val_mae: 0.0556 - lr: 0.0010\n",
            "Epoch 32/500\n",
            "15/15 [==============================] - 2s 162ms/step - loss: 0.0040 - mae: 0.0495 - val_loss: 0.0035 - val_mae: 0.0528 - lr: 0.0010\n",
            "Epoch 33/500\n",
            "15/15 [==============================] - 5s 309ms/step - loss: 0.0038 - mae: 0.0487 - val_loss: 0.0037 - val_mae: 0.0547 - lr: 0.0010\n",
            "Epoch 34/500\n",
            "15/15 [==============================] - 6s 383ms/step - loss: 0.0039 - mae: 0.0488 - val_loss: 0.0036 - val_mae: 0.0541 - lr: 0.0010\n",
            "Epoch 35/500\n",
            "15/15 [==============================] - 4s 240ms/step - loss: 0.0038 - mae: 0.0488 - val_loss: 0.0035 - val_mae: 0.0538 - lr: 0.0010\n",
            "Epoch 36/500\n",
            "15/15 [==============================] - 4s 301ms/step - loss: 0.0037 - mae: 0.0473 - val_loss: 0.0033 - val_mae: 0.0517 - lr: 0.0010\n",
            "Epoch 37/500\n",
            "15/15 [==============================] - 3s 211ms/step - loss: 0.0025 - mae: 0.0393 - val_loss: 0.0022 - val_mae: 0.0309 - lr: 2.0000e-04\n",
            "Epoch 38/500\n",
            "15/15 [==============================] - 3s 197ms/step - loss: 0.0019 - mae: 0.0333 - val_loss: 0.0016 - val_mae: 0.0295 - lr: 2.0000e-04\n",
            "Epoch 39/500\n",
            "15/15 [==============================] - 5s 314ms/step - loss: 0.0018 - mae: 0.0318 - val_loss: 0.0016 - val_mae: 0.0274 - lr: 2.0000e-04\n",
            "Epoch 40/500\n",
            "15/15 [==============================] - 4s 260ms/step - loss: 0.0017 - mae: 0.0310 - val_loss: 0.0015 - val_mae: 0.0273 - lr: 2.0000e-04\n",
            "Epoch 41/500\n",
            "15/15 [==============================] - 4s 239ms/step - loss: 0.0017 - mae: 0.0310 - val_loss: 0.0015 - val_mae: 0.0273 - lr: 2.0000e-04\n",
            "Epoch 42/500\n",
            "15/15 [==============================] - 7s 448ms/step - loss: 0.0016 - mae: 0.0305 - val_loss: 0.0015 - val_mae: 0.0272 - lr: 2.0000e-04\n",
            "Epoch 43/500\n",
            "15/15 [==============================] - 3s 217ms/step - loss: 0.0017 - mae: 0.0307 - val_loss: 0.0014 - val_mae: 0.0271 - lr: 2.0000e-04\n",
            "Epoch 44/500\n",
            "15/15 [==============================] - 4s 292ms/step - loss: 0.0017 - mae: 0.0311 - val_loss: 0.0014 - val_mae: 0.0268 - lr: 2.0000e-04\n",
            "Epoch 45/500\n",
            "15/15 [==============================] - 6s 378ms/step - loss: 0.0016 - mae: 0.0304 - val_loss: 0.0014 - val_mae: 0.0269 - lr: 2.0000e-04\n",
            "Epoch 46/500\n",
            "15/15 [==============================] - 4s 257ms/step - loss: 0.0016 - mae: 0.0301 - val_loss: 0.0014 - val_mae: 0.0267 - lr: 2.0000e-04\n",
            "Epoch 47/500\n",
            "15/15 [==============================] - 3s 231ms/step - loss: 0.0016 - mae: 0.0302 - val_loss: 0.0014 - val_mae: 0.0265 - lr: 2.0000e-04\n",
            "Epoch 48/500\n",
            "15/15 [==============================] - 5s 313ms/step - loss: 0.0016 - mae: 0.0299 - val_loss: 0.0014 - val_mae: 0.0263 - lr: 2.0000e-04\n",
            "Epoch 49/500\n",
            "15/15 [==============================] - 3s 214ms/step - loss: 0.0017 - mae: 0.0310 - val_loss: 0.0014 - val_mae: 0.0273 - lr: 2.0000e-04\n",
            "Epoch 50/500\n",
            "15/15 [==============================] - 2s 127ms/step - loss: 0.0016 - mae: 0.0292 - val_loss: 0.0014 - val_mae: 0.0262 - lr: 2.0000e-04\n",
            "Epoch 51/500\n",
            "15/15 [==============================] - 2s 127ms/step - loss: 0.0015 - mae: 0.0295 - val_loss: 0.0014 - val_mae: 0.0269 - lr: 2.0000e-04\n",
            "Epoch 52/500\n",
            "15/15 [==============================] - 2s 169ms/step - loss: 0.0016 - mae: 0.0302 - val_loss: 0.0013 - val_mae: 0.0262 - lr: 2.0000e-04\n",
            "Epoch 53/500\n",
            "15/15 [==============================] - 3s 211ms/step - loss: 0.0016 - mae: 0.0297 - val_loss: 0.0013 - val_mae: 0.0260 - lr: 4.0000e-05\n",
            "Epoch 54/500\n",
            "15/15 [==============================] - 2s 139ms/step - loss: 0.0016 - mae: 0.0305 - val_loss: 0.0013 - val_mae: 0.0262 - lr: 4.0000e-05\n",
            "Epoch 55/500\n",
            "15/15 [==============================] - 2s 132ms/step - loss: 0.0017 - mae: 0.0300 - val_loss: 0.0013 - val_mae: 0.0262 - lr: 4.0000e-05\n",
            "Epoch 56/500\n",
            "15/15 [==============================] - 2s 125ms/step - loss: 0.0016 - mae: 0.0301 - val_loss: 0.0013 - val_mae: 0.0261 - lr: 4.0000e-05\n",
            "Epoch 57/500\n",
            "15/15 [==============================] - 2s 131ms/step - loss: 0.0016 - mae: 0.0296 - val_loss: 0.0013 - val_mae: 0.0261 - lr: 4.0000e-05\n",
            "Epoch 58/500\n",
            "15/15 [==============================] - 3s 234ms/step - loss: 0.0017 - mae: 0.0303 - val_loss: 0.0013 - val_mae: 0.0263 - lr: 4.0000e-05\n",
            "Epoch 59/500\n",
            "15/15 [==============================] - 2s 144ms/step - loss: 0.0016 - mae: 0.0300 - val_loss: 0.0013 - val_mae: 0.0262 - lr: 4.0000e-05\n",
            "Epoch 60/500\n",
            "15/15 [==============================] - 2s 127ms/step - loss: 0.0016 - mae: 0.0297 - val_loss: 0.0013 - val_mae: 0.0261 - lr: 4.0000e-05\n",
            "Epoch 61/500\n",
            "15/15 [==============================] - 2s 123ms/step - loss: 0.0016 - mae: 0.0300 - val_loss: 0.0013 - val_mae: 0.0260 - lr: 1.0000e-05\n",
            "Epoch 62/500\n",
            "15/15 [==============================] - 2s 141ms/step - loss: 0.0016 - mae: 0.0297 - val_loss: 0.0013 - val_mae: 0.0260 - lr: 1.0000e-05\n",
            "Epoch 63/500\n",
            "15/15 [==============================] - 3s 216ms/step - loss: 0.0016 - mae: 0.0296 - val_loss: 0.0013 - val_mae: 0.0260 - lr: 1.0000e-05\n",
            "Epoch 64/500\n",
            "15/15 [==============================] - 2s 139ms/step - loss: 0.0016 - mae: 0.0298 - val_loss: 0.0013 - val_mae: 0.0260 - lr: 1.0000e-05\n",
            "Epoch 65/500\n",
            "15/15 [==============================] - 2s 139ms/step - loss: 0.0015 - mae: 0.0293 - val_loss: 0.0013 - val_mae: 0.0260 - lr: 1.0000e-05\n",
            "Epoch 66/500\n",
            "15/15 [==============================] - 2s 137ms/step - loss: 0.0016 - mae: 0.0298 - val_loss: 0.0013 - val_mae: 0.0260 - lr: 1.0000e-05\n",
            "Epoch 67/500\n",
            "15/15 [==============================] - 2s 128ms/step - loss: 0.0015 - mae: 0.0291 - val_loss: 0.0013 - val_mae: 0.0260 - lr: 1.0000e-05\n",
            "Epoch 68/500\n",
            "15/15 [==============================] - 3s 232ms/step - loss: 0.0015 - mae: 0.0292 - val_loss: 0.0013 - val_mae: 0.0260 - lr: 1.0000e-05\n",
            "Epoch 69/500\n",
            "15/15 [==============================] - 2s 138ms/step - loss: 0.0016 - mae: 0.0298 - val_loss: 0.0013 - val_mae: 0.0260 - lr: 1.0000e-05\n",
            "Epoch 70/500\n",
            "15/15 [==============================] - 2s 131ms/step - loss: 0.0016 - mae: 0.0300 - val_loss: 0.0013 - val_mae: 0.0260 - lr: 1.0000e-05\n",
            "Epoch 71/500\n",
            "15/15 [==============================] - 2s 132ms/step - loss: 0.0016 - mae: 0.0298 - val_loss: 0.0013 - val_mae: 0.0260 - lr: 1.0000e-05\n",
            "Epoch 72/500\n",
            "15/15 [==============================] - 2s 141ms/step - loss: 0.0016 - mae: 0.0297 - val_loss: 0.0013 - val_mae: 0.0260 - lr: 1.0000e-05\n",
            "Epoch 73/500\n",
            "15/15 [==============================] - 3s 231ms/step - loss: 0.0015 - mae: 0.0287 - val_loss: 0.0013 - val_mae: 0.0260 - lr: 1.0000e-05\n",
            "Epoch 74/500\n",
            "15/15 [==============================] - 3s 177ms/step - loss: 0.0017 - mae: 0.0301 - val_loss: 0.0013 - val_mae: 0.0260 - lr: 1.0000e-05\n",
            "Epoch 75/500\n",
            "15/15 [==============================] - 2s 157ms/step - loss: 0.0016 - mae: 0.0295 - val_loss: 0.0013 - val_mae: 0.0260 - lr: 1.0000e-05\n",
            "Epoch 76/500\n",
            "15/15 [==============================] - 2s 144ms/step - loss: 0.0016 - mae: 0.0293 - val_loss: 0.0013 - val_mae: 0.0260 - lr: 1.0000e-05\n",
            "Epoch 77/500\n",
            "15/15 [==============================] - 3s 174ms/step - loss: 0.0015 - mae: 0.0293 - val_loss: 0.0013 - val_mae: 0.0260 - lr: 1.0000e-05\n",
            "Epoch 78/500\n",
            "15/15 [==============================] - 2s 135ms/step - loss: 0.0016 - mae: 0.0292 - val_loss: 0.0013 - val_mae: 0.0260 - lr: 1.0000e-05\n",
            "Epoch 79/500\n",
            "15/15 [==============================] - 2s 153ms/step - loss: 0.0016 - mae: 0.0295 - val_loss: 0.0013 - val_mae: 0.0261 - lr: 1.0000e-05\n",
            "Epoch 80/500\n",
            "15/15 [==============================] - 2s 154ms/step - loss: 0.0016 - mae: 0.0299 - val_loss: 0.0013 - val_mae: 0.0261 - lr: 1.0000e-05\n",
            "Epoch 81/500\n",
            "15/15 [==============================] - 2s 133ms/step - loss: 0.0016 - mae: 0.0298 - val_loss: 0.0013 - val_mae: 0.0261 - lr: 1.0000e-05\n",
            "Epoch 82/500\n",
            "15/15 [==============================] - 3s 233ms/step - loss: 0.0016 - mae: 0.0290 - val_loss: 0.0013 - val_mae: 0.0260 - lr: 1.0000e-05\n",
            "Epoch 83/500\n",
            "15/15 [==============================] - 2s 133ms/step - loss: 0.0015 - mae: 0.0295 - val_loss: 0.0013 - val_mae: 0.0260 - lr: 1.0000e-05\n",
            "Epoch 84/500\n",
            "15/15 [==============================] - 2s 137ms/step - loss: 0.0016 - mae: 0.0298 - val_loss: 0.0013 - val_mae: 0.0260 - lr: 1.0000e-05\n",
            "Epoch 85/500\n",
            "15/15 [==============================] - 2s 128ms/step - loss: 0.0015 - mae: 0.0292 - val_loss: 0.0013 - val_mae: 0.0260 - lr: 1.0000e-05\n",
            "Epoch 86/500\n",
            "15/15 [==============================] - 2s 140ms/step - loss: 0.0015 - mae: 0.0289 - val_loss: 0.0013 - val_mae: 0.0260 - lr: 1.0000e-05\n",
            "Epoch 87/500\n",
            "15/15 [==============================] - 3s 230ms/step - loss: 0.0015 - mae: 0.0292 - val_loss: 0.0013 - val_mae: 0.0260 - lr: 1.0000e-05\n",
            "Epoch 88/500\n",
            "15/15 [==============================] - 2s 145ms/step - loss: 0.0015 - mae: 0.0291 - val_loss: 0.0013 - val_mae: 0.0260 - lr: 1.0000e-05\n",
            "Epoch 89/500\n",
            "15/15 [==============================] - 2s 140ms/step - loss: 0.0016 - mae: 0.0299 - val_loss: 0.0013 - val_mae: 0.0260 - lr: 1.0000e-05\n",
            "Epoch 90/500\n",
            "15/15 [==============================] - 2s 145ms/step - loss: 0.0016 - mae: 0.0296 - val_loss: 0.0013 - val_mae: 0.0260 - lr: 1.0000e-05\n",
            "Epoch 91/500\n",
            "15/15 [==============================] - 2s 139ms/step - loss: 0.0015 - mae: 0.0292 - val_loss: 0.0013 - val_mae: 0.0260 - lr: 1.0000e-05\n",
            "Epoch 92/500\n",
            "15/15 [==============================] - 2s 150ms/step - loss: 0.0015 - mae: 0.0292 - val_loss: 0.0013 - val_mae: 0.0259 - lr: 1.0000e-05\n",
            "Epoch 93/500\n",
            "15/15 [==============================] - 3s 228ms/step - loss: 0.0016 - mae: 0.0301 - val_loss: 0.0013 - val_mae: 0.0259 - lr: 1.0000e-05\n",
            "Epoch 94/500\n",
            "15/15 [==============================] - 2s 129ms/step - loss: 0.0015 - mae: 0.0295 - val_loss: 0.0013 - val_mae: 0.0259 - lr: 1.0000e-05\n",
            "Epoch 95/500\n",
            "15/15 [==============================] - 2s 131ms/step - loss: 0.0015 - mae: 0.0293 - val_loss: 0.0013 - val_mae: 0.0259 - lr: 1.0000e-05\n",
            "Epoch 96/500\n",
            "15/15 [==============================] - 2s 130ms/step - loss: 0.0015 - mae: 0.0286 - val_loss: 0.0013 - val_mae: 0.0259 - lr: 1.0000e-05\n",
            "Epoch 97/500\n",
            "15/15 [==============================] - 2s 132ms/step - loss: 0.0015 - mae: 0.0291 - val_loss: 0.0013 - val_mae: 0.0258 - lr: 1.0000e-05\n",
            "Epoch 98/500\n",
            "15/15 [==============================] - 3s 232ms/step - loss: 0.0015 - mae: 0.0290 - val_loss: 0.0013 - val_mae: 0.0258 - lr: 1.0000e-05\n",
            "Epoch 99/500\n",
            "15/15 [==============================] - 2s 128ms/step - loss: 0.0015 - mae: 0.0294 - val_loss: 0.0013 - val_mae: 0.0258 - lr: 1.0000e-05\n",
            "Epoch 100/500\n",
            "15/15 [==============================] - 2s 140ms/step - loss: 0.0015 - mae: 0.0290 - val_loss: 0.0013 - val_mae: 0.0259 - lr: 1.0000e-05\n",
            "Epoch 101/500\n",
            "15/15 [==============================] - 3s 213ms/step - loss: 0.0016 - mae: 0.0294 - val_loss: 0.0013 - val_mae: 0.0258 - lr: 1.0000e-05\n",
            "Epoch 102/500\n",
            "15/15 [==============================] - 4s 248ms/step - loss: 0.0016 - mae: 0.0298 - val_loss: 0.0013 - val_mae: 0.0259 - lr: 1.0000e-05\n",
            "Epoch 103/500\n",
            "15/15 [==============================] - 3s 211ms/step - loss: 0.0015 - mae: 0.0293 - val_loss: 0.0013 - val_mae: 0.0259 - lr: 1.0000e-05\n",
            "Epoch 104/500\n",
            "15/15 [==============================] - 2s 129ms/step - loss: 0.0015 - mae: 0.0291 - val_loss: 0.0013 - val_mae: 0.0258 - lr: 1.0000e-05\n",
            "Epoch 105/500\n",
            "15/15 [==============================] - 2s 134ms/step - loss: 0.0014 - mae: 0.0285 - val_loss: 0.0013 - val_mae: 0.0258 - lr: 1.0000e-05\n",
            "Epoch 106/500\n",
            "15/15 [==============================] - 2s 133ms/step - loss: 0.0015 - mae: 0.0286 - val_loss: 0.0013 - val_mae: 0.0258 - lr: 1.0000e-05\n",
            "Epoch 107/500\n",
            "15/15 [==============================] - 2s 130ms/step - loss: 0.0016 - mae: 0.0292 - val_loss: 0.0013 - val_mae: 0.0259 - lr: 1.0000e-05\n",
            "Epoch 108/500\n",
            "15/15 [==============================] - 2s 135ms/step - loss: 0.0015 - mae: 0.0293 - val_loss: 0.0013 - val_mae: 0.0259 - lr: 1.0000e-05\n",
            "Epoch 109/500\n",
            "15/15 [==============================] - 3s 220ms/step - loss: 0.0016 - mae: 0.0295 - val_loss: 0.0013 - val_mae: 0.0259 - lr: 1.0000e-05\n",
            "Epoch 110/500\n",
            "15/15 [==============================] - 2s 130ms/step - loss: 0.0015 - mae: 0.0296 - val_loss: 0.0013 - val_mae: 0.0259 - lr: 1.0000e-05\n",
            "Epoch 111/500\n",
            "15/15 [==============================] - 2s 140ms/step - loss: 0.0016 - mae: 0.0296 - val_loss: 0.0013 - val_mae: 0.0259 - lr: 1.0000e-05\n",
            "Epoch 112/500\n",
            "15/15 [==============================] - 2s 126ms/step - loss: 0.0016 - mae: 0.0296 - val_loss: 0.0013 - val_mae: 0.0258 - lr: 1.0000e-05\n",
            "Epoch 113/500\n",
            "15/15 [==============================] - 2s 146ms/step - loss: 0.0016 - mae: 0.0299 - val_loss: 0.0013 - val_mae: 0.0258 - lr: 1.0000e-05\n",
            "Epoch 114/500\n",
            "15/15 [==============================] - 5s 314ms/step - loss: 0.0015 - mae: 0.0290 - val_loss: 0.0013 - val_mae: 0.0259 - lr: 1.0000e-05\n",
            "Epoch 115/500\n",
            "15/15 [==============================] - 2s 138ms/step - loss: 0.0016 - mae: 0.0296 - val_loss: 0.0013 - val_mae: 0.0259 - lr: 1.0000e-05\n",
            "Epoch 116/500\n",
            "15/15 [==============================] - 2s 139ms/step - loss: 0.0015 - mae: 0.0290 - val_loss: 0.0013 - val_mae: 0.0259 - lr: 1.0000e-05\n",
            "Epoch 117/500\n",
            "15/15 [==============================] - 2s 144ms/step - loss: 0.0015 - mae: 0.0290 - val_loss: 0.0013 - val_mae: 0.0258 - lr: 1.0000e-05\n",
            "Epoch 118/500\n",
            "15/15 [==============================] - 2s 138ms/step - loss: 0.0016 - mae: 0.0295 - val_loss: 0.0013 - val_mae: 0.0257 - lr: 1.0000e-05\n",
            "Epoch 119/500\n",
            "15/15 [==============================] - 3s 224ms/step - loss: 0.0016 - mae: 0.0295 - val_loss: 0.0013 - val_mae: 0.0257 - lr: 1.0000e-05\n",
            "Epoch 120/500\n",
            "15/15 [==============================] - 2s 152ms/step - loss: 0.0015 - mae: 0.0290 - val_loss: 0.0013 - val_mae: 0.0258 - lr: 1.0000e-05\n",
            "Epoch 121/500\n",
            "15/15 [==============================] - 2s 133ms/step - loss: 0.0015 - mae: 0.0294 - val_loss: 0.0013 - val_mae: 0.0259 - lr: 1.0000e-05\n",
            "Epoch 122/500\n",
            "15/15 [==============================] - 3s 196ms/step - loss: 0.0016 - mae: 0.0294 - val_loss: 0.0013 - val_mae: 0.0258 - lr: 1.0000e-05\n",
            "Epoch 123/500\n",
            "15/15 [==============================] - 4s 243ms/step - loss: 0.0016 - mae: 0.0303 - val_loss: 0.0013 - val_mae: 0.0258 - lr: 1.0000e-05\n",
            "Epoch 124/500\n",
            "15/15 [==============================] - 2s 143ms/step - loss: 0.0016 - mae: 0.0292 - val_loss: 0.0013 - val_mae: 0.0258 - lr: 1.0000e-05\n",
            "Epoch 125/500\n",
            "15/15 [==============================] - 2s 136ms/step - loss: 0.0015 - mae: 0.0294 - val_loss: 0.0013 - val_mae: 0.0257 - lr: 1.0000e-05\n",
            "Epoch 126/500\n",
            "15/15 [==============================] - 2s 137ms/step - loss: 0.0015 - mae: 0.0292 - val_loss: 0.0013 - val_mae: 0.0256 - lr: 1.0000e-05\n",
            "Epoch 127/500\n",
            "15/15 [==============================] - 3s 174ms/step - loss: 0.0016 - mae: 0.0295 - val_loss: 0.0013 - val_mae: 0.0256 - lr: 1.0000e-05\n",
            "Epoch 128/500\n",
            "15/15 [==============================] - 2s 136ms/step - loss: 0.0015 - mae: 0.0292 - val_loss: 0.0013 - val_mae: 0.0257 - lr: 1.0000e-05\n",
            "Epoch 129/500\n",
            "15/15 [==============================] - 2s 143ms/step - loss: 0.0016 - mae: 0.0300 - val_loss: 0.0013 - val_mae: 0.0257 - lr: 1.0000e-05\n",
            "Epoch 130/500\n",
            "15/15 [==============================] - 2s 130ms/step - loss: 0.0014 - mae: 0.0284 - val_loss: 0.0013 - val_mae: 0.0256 - lr: 1.0000e-05\n",
            "Epoch 131/500\n",
            "15/15 [==============================] - 2s 131ms/step - loss: 0.0015 - mae: 0.0290 - val_loss: 0.0013 - val_mae: 0.0256 - lr: 1.0000e-05\n",
            "Epoch 132/500\n",
            "15/15 [==============================] - 3s 178ms/step - loss: 0.0015 - mae: 0.0291 - val_loss: 0.0013 - val_mae: 0.0256 - lr: 1.0000e-05\n",
            "Epoch 133/500\n",
            "15/15 [==============================] - 3s 220ms/step - loss: 0.0016 - mae: 0.0295 - val_loss: 0.0013 - val_mae: 0.0257 - lr: 1.0000e-05\n",
            "Epoch 134/500\n",
            "15/15 [==============================] - 2s 130ms/step - loss: 0.0016 - mae: 0.0296 - val_loss: 0.0013 - val_mae: 0.0258 - lr: 1.0000e-05\n",
            "Epoch 135/500\n",
            "15/15 [==============================] - 2s 131ms/step - loss: 0.0015 - mae: 0.0292 - val_loss: 0.0013 - val_mae: 0.0257 - lr: 1.0000e-05\n",
            "Epoch 136/500\n",
            "15/15 [==============================] - 2s 129ms/step - loss: 0.0016 - mae: 0.0297 - val_loss: 0.0013 - val_mae: 0.0257 - lr: 1.0000e-05\n",
            "Epoch 137/500\n",
            "15/15 [==============================] - 2s 146ms/step - loss: 0.0016 - mae: 0.0296 - val_loss: 0.0013 - val_mae: 0.0258 - lr: 1.0000e-05\n",
            "Epoch 138/500\n",
            "15/15 [==============================] - 3s 220ms/step - loss: 0.0016 - mae: 0.0297 - val_loss: 0.0013 - val_mae: 0.0258 - lr: 1.0000e-05\n",
            "Epoch 139/500\n",
            "15/15 [==============================] - 2s 132ms/step - loss: 0.0015 - mae: 0.0290 - val_loss: 0.0013 - val_mae: 0.0258 - lr: 1.0000e-05\n",
            "Epoch 140/500\n",
            "15/15 [==============================] - 2s 129ms/step - loss: 0.0016 - mae: 0.0300 - val_loss: 0.0013 - val_mae: 0.0257 - lr: 1.0000e-05\n",
            "Epoch 141/500\n",
            "15/15 [==============================] - 2s 138ms/step - loss: 0.0014 - mae: 0.0285 - val_loss: 0.0013 - val_mae: 0.0255 - lr: 1.0000e-05\n",
            "Epoch 142/500\n",
            "15/15 [==============================] - 2s 133ms/step - loss: 0.0015 - mae: 0.0293 - val_loss: 0.0013 - val_mae: 0.0255 - lr: 1.0000e-05\n",
            "Epoch 143/500\n",
            "15/15 [==============================] - 4s 249ms/step - loss: 0.0016 - mae: 0.0297 - val_loss: 0.0013 - val_mae: 0.0256 - lr: 1.0000e-05\n",
            "Epoch 144/500\n",
            "15/15 [==============================] - 2s 159ms/step - loss: 0.0016 - mae: 0.0297 - val_loss: 0.0013 - val_mae: 0.0257 - lr: 1.0000e-05\n",
            "Epoch 145/500\n",
            "15/15 [==============================] - 2s 137ms/step - loss: 0.0016 - mae: 0.0294 - val_loss: 0.0013 - val_mae: 0.0257 - lr: 1.0000e-05\n",
            "Epoch 146/500\n",
            "15/15 [==============================] - 2s 131ms/step - loss: 0.0015 - mae: 0.0287 - val_loss: 0.0013 - val_mae: 0.0256 - lr: 1.0000e-05\n",
            "Epoch 147/500\n",
            "15/15 [==============================] - 2s 128ms/step - loss: 0.0016 - mae: 0.0293 - val_loss: 0.0013 - val_mae: 0.0257 - lr: 1.0000e-05\n",
            "Epoch 148/500\n",
            "15/15 [==============================] - 2s 134ms/step - loss: 0.0015 - mae: 0.0288 - val_loss: 0.0013 - val_mae: 0.0256 - lr: 1.0000e-05\n",
            "Epoch 149/500\n",
            "15/15 [==============================] - 3s 231ms/step - loss: 0.0016 - mae: 0.0297 - val_loss: 0.0013 - val_mae: 0.0256 - lr: 1.0000e-05\n",
            "Epoch 150/500\n",
            "15/15 [==============================] - 2s 128ms/step - loss: 0.0015 - mae: 0.0293 - val_loss: 0.0013 - val_mae: 0.0256 - lr: 1.0000e-05\n",
            "Epoch 151/500\n",
            "15/15 [==============================] - 2s 131ms/step - loss: 0.0015 - mae: 0.0290 - val_loss: 0.0013 - val_mae: 0.0255 - lr: 1.0000e-05\n",
            "Epoch 152/500\n",
            "15/15 [==============================] - 2s 139ms/step - loss: 0.0015 - mae: 0.0286 - val_loss: 0.0013 - val_mae: 0.0255 - lr: 1.0000e-05\n",
            "Epoch 153/500\n",
            "15/15 [==============================] - 2s 143ms/step - loss: 0.0015 - mae: 0.0293 - val_loss: 0.0013 - val_mae: 0.0255 - lr: 1.0000e-05\n",
            "Epoch 154/500\n",
            "15/15 [==============================] - 3s 228ms/step - loss: 0.0015 - mae: 0.0291 - val_loss: 0.0013 - val_mae: 0.0255 - lr: 1.0000e-05\n",
            "Epoch 155/500\n",
            "15/15 [==============================] - 2s 134ms/step - loss: 0.0015 - mae: 0.0290 - val_loss: 0.0013 - val_mae: 0.0255 - lr: 1.0000e-05\n",
            "Epoch 156/500\n",
            "15/15 [==============================] - 2s 135ms/step - loss: 0.0015 - mae: 0.0286 - val_loss: 0.0013 - val_mae: 0.0255 - lr: 1.0000e-05\n",
            "Epoch 157/500\n",
            "15/15 [==============================] - 2s 133ms/step - loss: 0.0015 - mae: 0.0290 - val_loss: 0.0013 - val_mae: 0.0255 - lr: 1.0000e-05\n",
            "Epoch 158/500\n",
            "15/15 [==============================] - 2s 156ms/step - loss: 0.0016 - mae: 0.0293 - val_loss: 0.0013 - val_mae: 0.0255 - lr: 1.0000e-05\n",
            "Epoch 159/500\n",
            "15/15 [==============================] - 3s 228ms/step - loss: 0.0015 - mae: 0.0291 - val_loss: 0.0013 - val_mae: 0.0256 - lr: 1.0000e-05\n",
            "Epoch 160/500\n",
            "15/15 [==============================] - 2s 134ms/step - loss: 0.0016 - mae: 0.0297 - val_loss: 0.0013 - val_mae: 0.0255 - lr: 1.0000e-05\n",
            "Epoch 161/500\n",
            "15/15 [==============================] - 2s 130ms/step - loss: 0.0015 - mae: 0.0286 - val_loss: 0.0013 - val_mae: 0.0255 - lr: 1.0000e-05\n",
            "Epoch 162/500\n",
            "15/15 [==============================] - 2s 143ms/step - loss: 0.0015 - mae: 0.0292 - val_loss: 0.0013 - val_mae: 0.0256 - lr: 1.0000e-05\n",
            "Epoch 163/500\n",
            "15/15 [==============================] - 3s 189ms/step - loss: 0.0016 - mae: 0.0299 - val_loss: 0.0013 - val_mae: 0.0255 - lr: 1.0000e-05\n",
            "Epoch 164/500\n",
            "15/15 [==============================] - 3s 220ms/step - loss: 0.0016 - mae: 0.0297 - val_loss: 0.0013 - val_mae: 0.0254 - lr: 1.0000e-05\n",
            "Epoch 165/500\n",
            "15/15 [==============================] - 2s 156ms/step - loss: 0.0016 - mae: 0.0301 - val_loss: 0.0013 - val_mae: 0.0255 - lr: 1.0000e-05\n",
            "Epoch 166/500\n",
            "15/15 [==============================] - 2s 135ms/step - loss: 0.0015 - mae: 0.0292 - val_loss: 0.0013 - val_mae: 0.0254 - lr: 1.0000e-05\n",
            "Epoch 167/500\n",
            "15/15 [==============================] - 2s 135ms/step - loss: 0.0015 - mae: 0.0290 - val_loss: 0.0013 - val_mae: 0.0253 - lr: 1.0000e-05\n",
            "Epoch 168/500\n",
            "15/15 [==============================] - 2s 129ms/step - loss: 0.0015 - mae: 0.0293 - val_loss: 0.0013 - val_mae: 0.0253 - lr: 1.0000e-05\n",
            "Epoch 169/500\n",
            "15/15 [==============================] - 3s 214ms/step - loss: 0.0015 - mae: 0.0291 - val_loss: 0.0013 - val_mae: 0.0255 - lr: 1.0000e-05\n",
            "Epoch 170/500\n",
            "15/15 [==============================] - 2s 134ms/step - loss: 0.0015 - mae: 0.0288 - val_loss: 0.0013 - val_mae: 0.0256 - lr: 1.0000e-05\n",
            "Epoch 171/500\n",
            "15/15 [==============================] - 2s 126ms/step - loss: 0.0015 - mae: 0.0286 - val_loss: 0.0013 - val_mae: 0.0256 - lr: 1.0000e-05\n",
            "Epoch 172/500\n",
            "15/15 [==============================] - 2s 141ms/step - loss: 0.0015 - mae: 0.0290 - val_loss: 0.0013 - val_mae: 0.0255 - lr: 1.0000e-05\n",
            "Epoch 173/500\n",
            "15/15 [==============================] - 2s 139ms/step - loss: 0.0016 - mae: 0.0291 - val_loss: 0.0013 - val_mae: 0.0255 - lr: 1.0000e-05\n",
            "Epoch 174/500\n",
            "15/15 [==============================] - 3s 224ms/step - loss: 0.0014 - mae: 0.0285 - val_loss: 0.0013 - val_mae: 0.0254 - lr: 1.0000e-05\n",
            "Epoch 175/500\n",
            "15/15 [==============================] - 2s 139ms/step - loss: 0.0014 - mae: 0.0282 - val_loss: 0.0013 - val_mae: 0.0253 - lr: 1.0000e-05\n",
            "Epoch 176/500\n",
            "15/15 [==============================] - 2s 136ms/step - loss: 0.0015 - mae: 0.0288 - val_loss: 0.0013 - val_mae: 0.0254 - lr: 1.0000e-05\n",
            "Epoch 177/500\n",
            "15/15 [==============================] - 2s 143ms/step - loss: 0.0016 - mae: 0.0293 - val_loss: 0.0013 - val_mae: 0.0255 - lr: 1.0000e-05\n",
            "Epoch 178/500\n",
            "15/15 [==============================] - 2s 137ms/step - loss: 0.0015 - mae: 0.0294 - val_loss: 0.0013 - val_mae: 0.0253 - lr: 1.0000e-05\n",
            "Epoch 179/500\n",
            "15/15 [==============================] - 3s 229ms/step - loss: 0.0015 - mae: 0.0290 - val_loss: 0.0013 - val_mae: 0.0252 - lr: 1.0000e-05\n",
            "Epoch 180/500\n",
            "15/15 [==============================] - 2s 152ms/step - loss: 0.0015 - mae: 0.0288 - val_loss: 0.0013 - val_mae: 0.0252 - lr: 1.0000e-05\n",
            "Epoch 181/500\n",
            "15/15 [==============================] - 2s 128ms/step - loss: 0.0015 - mae: 0.0288 - val_loss: 0.0013 - val_mae: 0.0252 - lr: 1.0000e-05\n",
            "Epoch 182/500\n",
            "15/15 [==============================] - 3s 168ms/step - loss: 0.0015 - mae: 0.0291 - val_loss: 0.0013 - val_mae: 0.0254 - lr: 1.0000e-05\n",
            "Epoch 183/500\n",
            "15/15 [==============================] - 3s 226ms/step - loss: 0.0015 - mae: 0.0288 - val_loss: 0.0013 - val_mae: 0.0253 - lr: 1.0000e-05\n",
            "Epoch 184/500\n",
            "15/15 [==============================] - 3s 191ms/step - loss: 0.0015 - mae: 0.0291 - val_loss: 0.0012 - val_mae: 0.0253 - lr: 1.0000e-05\n",
            "Epoch 185/500\n",
            "15/15 [==============================] - 3s 197ms/step - loss: 0.0015 - mae: 0.0292 - val_loss: 0.0012 - val_mae: 0.0253 - lr: 1.0000e-05\n",
            "Epoch 186/500\n",
            "15/15 [==============================] - 2s 143ms/step - loss: 0.0015 - mae: 0.0287 - val_loss: 0.0012 - val_mae: 0.0253 - lr: 1.0000e-05\n",
            "Epoch 187/500\n",
            "15/15 [==============================] - 2s 132ms/step - loss: 0.0016 - mae: 0.0293 - val_loss: 0.0012 - val_mae: 0.0253 - lr: 1.0000e-05\n",
            "Epoch 188/500\n",
            "15/15 [==============================] - 2s 141ms/step - loss: 0.0015 - mae: 0.0290 - val_loss: 0.0012 - val_mae: 0.0253 - lr: 1.0000e-05\n",
            "Epoch 189/500\n",
            "15/15 [==============================] - 3s 226ms/step - loss: 0.0016 - mae: 0.0290 - val_loss: 0.0012 - val_mae: 0.0253 - lr: 1.0000e-05\n",
            "Epoch 190/500\n",
            "15/15 [==============================] - 2s 134ms/step - loss: 0.0015 - mae: 0.0290 - val_loss: 0.0012 - val_mae: 0.0252 - lr: 1.0000e-05\n",
            "Epoch 191/500\n",
            "15/15 [==============================] - 2s 143ms/step - loss: 0.0015 - mae: 0.0290 - val_loss: 0.0012 - val_mae: 0.0252 - lr: 1.0000e-05\n",
            "Epoch 192/500\n",
            "15/15 [==============================] - 2s 127ms/step - loss: 0.0015 - mae: 0.0290 - val_loss: 0.0012 - val_mae: 0.0252 - lr: 1.0000e-05\n",
            "Epoch 193/500\n",
            "15/15 [==============================] - 2s 147ms/step - loss: 0.0015 - mae: 0.0284 - val_loss: 0.0012 - val_mae: 0.0255 - lr: 1.0000e-05\n",
            "Epoch 194/500\n",
            "15/15 [==============================] - 3s 229ms/step - loss: 0.0015 - mae: 0.0284 - val_loss: 0.0012 - val_mae: 0.0255 - lr: 1.0000e-05\n",
            "Epoch 195/500\n",
            "15/15 [==============================] - 2s 127ms/step - loss: 0.0016 - mae: 0.0293 - val_loss: 0.0012 - val_mae: 0.0254 - lr: 1.0000e-05\n",
            "Epoch 196/500\n",
            "15/15 [==============================] - 2s 130ms/step - loss: 0.0015 - mae: 0.0284 - val_loss: 0.0012 - val_mae: 0.0252 - lr: 1.0000e-05\n",
            "Epoch 197/500\n",
            "15/15 [==============================] - 2s 143ms/step - loss: 0.0015 - mae: 0.0291 - val_loss: 0.0012 - val_mae: 0.0251 - lr: 1.0000e-05\n",
            "Epoch 198/500\n",
            "15/15 [==============================] - 2s 132ms/step - loss: 0.0015 - mae: 0.0281 - val_loss: 0.0012 - val_mae: 0.0251 - lr: 1.0000e-05\n",
            "Epoch 199/500\n",
            "15/15 [==============================] - 3s 222ms/step - loss: 0.0015 - mae: 0.0288 - val_loss: 0.0012 - val_mae: 0.0253 - lr: 1.0000e-05\n",
            "Epoch 200/500\n",
            "15/15 [==============================] - 2s 127ms/step - loss: 0.0015 - mae: 0.0288 - val_loss: 0.0012 - val_mae: 0.0253 - lr: 1.0000e-05\n",
            "Epoch 201/500\n",
            "15/15 [==============================] - 2s 139ms/step - loss: 0.0016 - mae: 0.0292 - val_loss: 0.0012 - val_mae: 0.0254 - lr: 1.0000e-05\n",
            "Epoch 202/500\n",
            "15/15 [==============================] - 2s 129ms/step - loss: 0.0016 - mae: 0.0295 - val_loss: 0.0012 - val_mae: 0.0252 - lr: 1.0000e-05\n",
            "Epoch 203/500\n",
            "15/15 [==============================] - 2s 129ms/step - loss: 0.0015 - mae: 0.0285 - val_loss: 0.0012 - val_mae: 0.0252 - lr: 1.0000e-05\n",
            "Epoch 204/500\n",
            "15/15 [==============================] - 3s 209ms/step - loss: 0.0015 - mae: 0.0286 - val_loss: 0.0012 - val_mae: 0.0252 - lr: 1.0000e-05\n",
            "Epoch 205/500\n",
            "15/15 [==============================] - 2s 130ms/step - loss: 0.0014 - mae: 0.0284 - val_loss: 0.0012 - val_mae: 0.0251 - lr: 1.0000e-05\n",
            "Epoch 206/500\n",
            "15/15 [==============================] - 2s 129ms/step - loss: 0.0015 - mae: 0.0284 - val_loss: 0.0012 - val_mae: 0.0252 - lr: 1.0000e-05\n",
            "Epoch 207/500\n",
            "15/15 [==============================] - 3s 238ms/step - loss: 0.0015 - mae: 0.0285 - val_loss: 0.0012 - val_mae: 0.0252 - lr: 1.0000e-05\n",
            "Epoch 208/500\n",
            "15/15 [==============================] - 5s 338ms/step - loss: 0.0015 - mae: 0.0290 - val_loss: 0.0012 - val_mae: 0.0252 - lr: 1.0000e-05\n",
            "Epoch 209/500\n",
            "15/15 [==============================] - 4s 234ms/step - loss: 0.0015 - mae: 0.0285 - val_loss: 0.0012 - val_mae: 0.0251 - lr: 1.0000e-05\n",
            "Epoch 210/500\n",
            "15/15 [==============================] - 3s 207ms/step - loss: 0.0015 - mae: 0.0292 - val_loss: 0.0012 - val_mae: 0.0252 - lr: 1.0000e-05\n",
            "Epoch 211/500\n",
            "15/15 [==============================] - 2s 135ms/step - loss: 0.0015 - mae: 0.0288 - val_loss: 0.0012 - val_mae: 0.0253 - lr: 1.0000e-05\n",
            "Epoch 212/500\n",
            "15/15 [==============================] - 3s 212ms/step - loss: 0.0015 - mae: 0.0296 - val_loss: 0.0012 - val_mae: 0.0253 - lr: 1.0000e-05\n",
            "Epoch 213/500\n",
            "15/15 [==============================] - 2s 135ms/step - loss: 0.0014 - mae: 0.0285 - val_loss: 0.0012 - val_mae: 0.0252 - lr: 1.0000e-05\n",
            "Epoch 214/500\n",
            "15/15 [==============================] - 2s 144ms/step - loss: 0.0015 - mae: 0.0285 - val_loss: 0.0012 - val_mae: 0.0250 - lr: 1.0000e-05\n",
            "Epoch 215/500\n",
            "15/15 [==============================] - 2s 127ms/step - loss: 0.0015 - mae: 0.0291 - val_loss: 0.0012 - val_mae: 0.0251 - lr: 1.0000e-05\n",
            "Epoch 216/500\n",
            "15/15 [==============================] - 2s 129ms/step - loss: 0.0015 - mae: 0.0288 - val_loss: 0.0012 - val_mae: 0.0253 - lr: 1.0000e-05\n",
            "Epoch 217/500\n",
            "15/15 [==============================] - 4s 237ms/step - loss: 0.0015 - mae: 0.0288 - val_loss: 0.0012 - val_mae: 0.0252 - lr: 1.0000e-05\n",
            "Epoch 218/500\n",
            "15/15 [==============================] - 2s 127ms/step - loss: 0.0014 - mae: 0.0281 - val_loss: 0.0012 - val_mae: 0.0252 - lr: 1.0000e-05\n",
            "Epoch 219/500\n",
            "15/15 [==============================] - 2s 129ms/step - loss: 0.0015 - mae: 0.0289 - val_loss: 0.0012 - val_mae: 0.0250 - lr: 1.0000e-05\n",
            "Epoch 220/500\n",
            "15/15 [==============================] - 2s 129ms/step - loss: 0.0014 - mae: 0.0283 - val_loss: 0.0012 - val_mae: 0.0250 - lr: 1.0000e-05\n",
            "Epoch 221/500\n",
            "15/15 [==============================] - 2s 128ms/step - loss: 0.0015 - mae: 0.0283 - val_loss: 0.0012 - val_mae: 0.0249 - lr: 1.0000e-05\n",
            "Epoch 222/500\n",
            "15/15 [==============================] - 3s 207ms/step - loss: 0.0015 - mae: 0.0287 - val_loss: 0.0012 - val_mae: 0.0251 - lr: 1.0000e-05\n",
            "Epoch 223/500\n",
            "15/15 [==============================] - 2s 131ms/step - loss: 0.0015 - mae: 0.0290 - val_loss: 0.0012 - val_mae: 0.0251 - lr: 1.0000e-05\n",
            "Epoch 224/500\n",
            "15/15 [==============================] - 2s 132ms/step - loss: 0.0015 - mae: 0.0292 - val_loss: 0.0012 - val_mae: 0.0251 - lr: 1.0000e-05\n",
            "Epoch 225/500\n",
            "15/15 [==============================] - 2s 129ms/step - loss: 0.0015 - mae: 0.0286 - val_loss: 0.0012 - val_mae: 0.0251 - lr: 1.0000e-05\n",
            "Epoch 226/500\n",
            "15/15 [==============================] - 2s 140ms/step - loss: 0.0015 - mae: 0.0288 - val_loss: 0.0012 - val_mae: 0.0251 - lr: 1.0000e-05\n",
            "Epoch 227/500\n",
            "15/15 [==============================] - 3s 212ms/step - loss: 0.0015 - mae: 0.0287 - val_loss: 0.0012 - val_mae: 0.0250 - lr: 1.0000e-05\n",
            "Epoch 228/500\n",
            "15/15 [==============================] - 2s 139ms/step - loss: 0.0015 - mae: 0.0287 - val_loss: 0.0012 - val_mae: 0.0250 - lr: 1.0000e-05\n",
            "Epoch 229/500\n",
            "15/15 [==============================] - 2s 132ms/step - loss: 0.0015 - mae: 0.0285 - val_loss: 0.0012 - val_mae: 0.0249 - lr: 1.0000e-05\n",
            "Epoch 230/500\n",
            "15/15 [==============================] - 2s 129ms/step - loss: 0.0015 - mae: 0.0289 - val_loss: 0.0012 - val_mae: 0.0249 - lr: 1.0000e-05\n",
            "Epoch 231/500\n",
            "15/15 [==============================] - 2s 128ms/step - loss: 0.0015 - mae: 0.0288 - val_loss: 0.0012 - val_mae: 0.0250 - lr: 1.0000e-05\n",
            "Epoch 232/500\n",
            "15/15 [==============================] - 3s 174ms/step - loss: 0.0015 - mae: 0.0288 - val_loss: 0.0012 - val_mae: 0.0250 - lr: 1.0000e-05\n",
            "Epoch 233/500\n",
            "15/15 [==============================] - 2s 132ms/step - loss: 0.0015 - mae: 0.0294 - val_loss: 0.0012 - val_mae: 0.0250 - lr: 1.0000e-05\n",
            "Epoch 234/500\n",
            "15/15 [==============================] - 2s 131ms/step - loss: 0.0014 - mae: 0.0283 - val_loss: 0.0012 - val_mae: 0.0250 - lr: 1.0000e-05\n",
            "Epoch 235/500\n",
            "15/15 [==============================] - 2s 142ms/step - loss: 0.0014 - mae: 0.0284 - val_loss: 0.0012 - val_mae: 0.0249 - lr: 1.0000e-05\n",
            "Epoch 236/500\n",
            "15/15 [==============================] - 2s 136ms/step - loss: 0.0015 - mae: 0.0288 - val_loss: 0.0012 - val_mae: 0.0250 - lr: 1.0000e-05\n",
            "Epoch 237/500\n",
            "15/15 [==============================] - 3s 225ms/step - loss: 0.0014 - mae: 0.0275 - val_loss: 0.0012 - val_mae: 0.0251 - lr: 1.0000e-05\n",
            "Epoch 238/500\n",
            "15/15 [==============================] - 2s 142ms/step - loss: 0.0015 - mae: 0.0289 - val_loss: 0.0012 - val_mae: 0.0249 - lr: 1.0000e-05\n",
            "Epoch 239/500\n",
            "15/15 [==============================] - 2s 131ms/step - loss: 0.0015 - mae: 0.0285 - val_loss: 0.0012 - val_mae: 0.0248 - lr: 1.0000e-05\n",
            "Epoch 240/500\n",
            "15/15 [==============================] - 2s 131ms/step - loss: 0.0015 - mae: 0.0287 - val_loss: 0.0012 - val_mae: 0.0248 - lr: 1.0000e-05\n",
            "Epoch 241/500\n",
            "15/15 [==============================] - 2s 128ms/step - loss: 0.0015 - mae: 0.0291 - val_loss: 0.0012 - val_mae: 0.0249 - lr: 1.0000e-05\n",
            "Epoch 242/500\n",
            "15/15 [==============================] - 3s 208ms/step - loss: 0.0014 - mae: 0.0283 - val_loss: 0.0012 - val_mae: 0.0250 - lr: 1.0000e-05\n",
            "Epoch 243/500\n",
            "15/15 [==============================] - 2s 128ms/step - loss: 0.0014 - mae: 0.0285 - val_loss: 0.0012 - val_mae: 0.0251 - lr: 1.0000e-05\n",
            "Epoch 244/500\n",
            "15/15 [==============================] - 2s 138ms/step - loss: 0.0015 - mae: 0.0287 - val_loss: 0.0012 - val_mae: 0.0250 - lr: 1.0000e-05\n",
            "Epoch 245/500\n",
            "15/15 [==============================] - 2s 129ms/step - loss: 0.0015 - mae: 0.0286 - val_loss: 0.0012 - val_mae: 0.0250 - lr: 1.0000e-05\n",
            "Epoch 246/500\n",
            "15/15 [==============================] - 2s 167ms/step - loss: 0.0015 - mae: 0.0291 - val_loss: 0.0012 - val_mae: 0.0251 - lr: 1.0000e-05\n",
            "Epoch 247/500\n",
            "15/15 [==============================] - 3s 224ms/step - loss: 0.0014 - mae: 0.0280 - val_loss: 0.0012 - val_mae: 0.0251 - lr: 1.0000e-05\n",
            "Epoch 248/500\n",
            "15/15 [==============================] - 2s 145ms/step - loss: 0.0015 - mae: 0.0291 - val_loss: 0.0012 - val_mae: 0.0251 - lr: 1.0000e-05\n",
            "Epoch 249/500\n",
            "15/15 [==============================] - 2s 143ms/step - loss: 0.0016 - mae: 0.0291 - val_loss: 0.0012 - val_mae: 0.0247 - lr: 1.0000e-05\n",
            "Epoch 250/500\n",
            "15/15 [==============================] - 2s 135ms/step - loss: 0.0015 - mae: 0.0283 - val_loss: 0.0012 - val_mae: 0.0246 - lr: 1.0000e-05\n",
            "Epoch 251/500\n",
            "15/15 [==============================] - 2s 143ms/step - loss: 0.0015 - mae: 0.0284 - val_loss: 0.0012 - val_mae: 0.0247 - lr: 1.0000e-05\n",
            "Epoch 252/500\n",
            "15/15 [==============================] - 3s 228ms/step - loss: 0.0015 - mae: 0.0285 - val_loss: 0.0012 - val_mae: 0.0248 - lr: 1.0000e-05\n",
            "Epoch 253/500\n",
            "15/15 [==============================] - 2s 132ms/step - loss: 0.0015 - mae: 0.0287 - val_loss: 0.0012 - val_mae: 0.0247 - lr: 1.0000e-05\n",
            "Epoch 254/500\n",
            "15/15 [==============================] - 2s 135ms/step - loss: 0.0015 - mae: 0.0288 - val_loss: 0.0012 - val_mae: 0.0247 - lr: 1.0000e-05\n",
            "Epoch 255/500\n",
            "15/15 [==============================] - 2s 129ms/step - loss: 0.0014 - mae: 0.0283 - val_loss: 0.0012 - val_mae: 0.0247 - lr: 1.0000e-05\n",
            "Epoch 256/500\n",
            "15/15 [==============================] - 2s 144ms/step - loss: 0.0016 - mae: 0.0291 - val_loss: 0.0012 - val_mae: 0.0248 - lr: 1.0000e-05\n",
            "Epoch 257/500\n",
            "15/15 [==============================] - 3s 226ms/step - loss: 0.0015 - mae: 0.0287 - val_loss: 0.0012 - val_mae: 0.0250 - lr: 1.0000e-05\n",
            "Epoch 258/500\n",
            "15/15 [==============================] - 2s 129ms/step - loss: 0.0015 - mae: 0.0282 - val_loss: 0.0012 - val_mae: 0.0250 - lr: 1.0000e-05\n",
            "Epoch 259/500\n",
            "15/15 [==============================] - 3s 179ms/step - loss: 0.0014 - mae: 0.0282 - val_loss: 0.0012 - val_mae: 0.0248 - lr: 1.0000e-05\n",
            "Epoch 260/500\n",
            "15/15 [==============================] - 3s 171ms/step - loss: 0.0014 - mae: 0.0282 - val_loss: 0.0012 - val_mae: 0.0249 - lr: 1.0000e-05\n",
            "Epoch 261/500\n",
            "15/15 [==============================] - 3s 220ms/step - loss: 0.0015 - mae: 0.0287 - val_loss: 0.0012 - val_mae: 0.0249 - lr: 1.0000e-05\n",
            "Epoch 262/500\n",
            "15/15 [==============================] - 2s 129ms/step - loss: 0.0015 - mae: 0.0293 - val_loss: 0.0012 - val_mae: 0.0247 - lr: 1.0000e-05\n",
            "Epoch 263/500\n",
            "15/15 [==============================] - 2s 131ms/step - loss: 0.0014 - mae: 0.0281 - val_loss: 0.0012 - val_mae: 0.0246 - lr: 1.0000e-05\n",
            "Epoch 264/500\n",
            "15/15 [==============================] - 2s 131ms/step - loss: 0.0015 - mae: 0.0287 - val_loss: 0.0012 - val_mae: 0.0246 - lr: 1.0000e-05\n",
            "Epoch 265/500\n",
            "15/15 [==============================] - 2s 143ms/step - loss: 0.0015 - mae: 0.0282 - val_loss: 0.0012 - val_mae: 0.0246 - lr: 1.0000e-05\n",
            "Epoch 266/500\n",
            "15/15 [==============================] - 3s 226ms/step - loss: 0.0014 - mae: 0.0281 - val_loss: 0.0012 - val_mae: 0.0248 - lr: 1.0000e-05\n",
            "Epoch 267/500\n",
            "15/15 [==============================] - 2s 140ms/step - loss: 0.0015 - mae: 0.0289 - val_loss: 0.0012 - val_mae: 0.0247 - lr: 1.0000e-05\n",
            "Epoch 268/500\n",
            "15/15 [==============================] - 2s 145ms/step - loss: 0.0015 - mae: 0.0282 - val_loss: 0.0012 - val_mae: 0.0247 - lr: 1.0000e-05\n",
            "Epoch 269/500\n",
            "15/15 [==============================] - 2s 142ms/step - loss: 0.0015 - mae: 0.0286 - val_loss: 0.0012 - val_mae: 0.0247 - lr: 1.0000e-05\n",
            "Epoch 270/500\n",
            "15/15 [==============================] - 2s 137ms/step - loss: 0.0015 - mae: 0.0285 - val_loss: 0.0012 - val_mae: 0.0245 - lr: 1.0000e-05\n",
            "Epoch 271/500\n",
            "15/15 [==============================] - 3s 221ms/step - loss: 0.0015 - mae: 0.0291 - val_loss: 0.0012 - val_mae: 0.0246 - lr: 1.0000e-05\n",
            "Epoch 272/500\n",
            "15/15 [==============================] - 2s 131ms/step - loss: 0.0015 - mae: 0.0286 - val_loss: 0.0012 - val_mae: 0.0245 - lr: 1.0000e-05\n",
            "Epoch 273/500\n",
            "15/15 [==============================] - 2s 132ms/step - loss: 0.0014 - mae: 0.0283 - val_loss: 0.0012 - val_mae: 0.0246 - lr: 1.0000e-05\n",
            "Epoch 274/500\n",
            "15/15 [==============================] - 2s 130ms/step - loss: 0.0014 - mae: 0.0282 - val_loss: 0.0012 - val_mae: 0.0247 - lr: 1.0000e-05\n",
            "Epoch 275/500\n",
            "15/15 [==============================] - 2s 139ms/step - loss: 0.0014 - mae: 0.0284 - val_loss: 0.0012 - val_mae: 0.0246 - lr: 1.0000e-05\n",
            "Epoch 276/500\n",
            "15/15 [==============================] - 3s 234ms/step - loss: 0.0014 - mae: 0.0280 - val_loss: 0.0012 - val_mae: 0.0247 - lr: 1.0000e-05\n",
            "Epoch 277/500\n",
            "15/15 [==============================] - 2s 137ms/step - loss: 0.0015 - mae: 0.0286 - val_loss: 0.0012 - val_mae: 0.0247 - lr: 1.0000e-05\n",
            "Epoch 278/500\n",
            "15/15 [==============================] - 2s 132ms/step - loss: 0.0015 - mae: 0.0288 - val_loss: 0.0012 - val_mae: 0.0247 - lr: 1.0000e-05\n",
            "Epoch 279/500\n",
            "15/15 [==============================] - 2s 136ms/step - loss: 0.0015 - mae: 0.0289 - val_loss: 0.0012 - val_mae: 0.0246 - lr: 1.0000e-05\n",
            "Epoch 280/500\n",
            "15/15 [==============================] - 2s 169ms/step - loss: 0.0015 - mae: 0.0280 - val_loss: 0.0012 - val_mae: 0.0246 - lr: 1.0000e-05\n",
            "Epoch 281/500\n",
            "15/15 [==============================] - 3s 229ms/step - loss: 0.0014 - mae: 0.0278 - val_loss: 0.0012 - val_mae: 0.0245 - lr: 1.0000e-05\n",
            "Epoch 282/500\n",
            "15/15 [==============================] - 2s 136ms/step - loss: 0.0014 - mae: 0.0279 - val_loss: 0.0012 - val_mae: 0.0246 - lr: 1.0000e-05\n",
            "Epoch 283/500\n",
            "15/15 [==============================] - 2s 129ms/step - loss: 0.0014 - mae: 0.0281 - val_loss: 0.0012 - val_mae: 0.0247 - lr: 1.0000e-05\n",
            "Epoch 284/500\n",
            "15/15 [==============================] - 2s 146ms/step - loss: 0.0014 - mae: 0.0279 - val_loss: 0.0012 - val_mae: 0.0245 - lr: 1.0000e-05\n",
            "Epoch 285/500\n",
            "15/15 [==============================] - 2s 151ms/step - loss: 0.0014 - mae: 0.0284 - val_loss: 0.0012 - val_mae: 0.0245 - lr: 1.0000e-05\n",
            "Epoch 286/500\n",
            "15/15 [==============================] - 3s 226ms/step - loss: 0.0014 - mae: 0.0280 - val_loss: 0.0012 - val_mae: 0.0246 - lr: 1.0000e-05\n",
            "Epoch 287/500\n",
            "15/15 [==============================] - 2s 132ms/step - loss: 0.0014 - mae: 0.0279 - val_loss: 0.0012 - val_mae: 0.0247 - lr: 1.0000e-05\n",
            "Epoch 288/500\n",
            "15/15 [==============================] - 2s 142ms/step - loss: 0.0015 - mae: 0.0286 - val_loss: 0.0012 - val_mae: 0.0244 - lr: 1.0000e-05\n",
            "Epoch 289/500\n",
            "15/15 [==============================] - 2s 142ms/step - loss: 0.0014 - mae: 0.0278 - val_loss: 0.0012 - val_mae: 0.0245 - lr: 1.0000e-05\n",
            "Epoch 290/500\n",
            "15/15 [==============================] - 2s 159ms/step - loss: 0.0015 - mae: 0.0290 - val_loss: 0.0012 - val_mae: 0.0245 - lr: 1.0000e-05\n",
            "Epoch 291/500\n",
            "15/15 [==============================] - 3s 230ms/step - loss: 0.0014 - mae: 0.0281 - val_loss: 0.0012 - val_mae: 0.0245 - lr: 1.0000e-05\n",
            "Epoch 292/500\n",
            "15/15 [==============================] - 2s 143ms/step - loss: 0.0015 - mae: 0.0283 - val_loss: 0.0012 - val_mae: 0.0247 - lr: 1.0000e-05\n",
            "Epoch 293/500\n",
            "15/15 [==============================] - 2s 143ms/step - loss: 0.0015 - mae: 0.0285 - val_loss: 0.0011 - val_mae: 0.0245 - lr: 1.0000e-05\n",
            "Epoch 294/500\n",
            "15/15 [==============================] - 2s 134ms/step - loss: 0.0014 - mae: 0.0281 - val_loss: 0.0011 - val_mae: 0.0244 - lr: 1.0000e-05\n",
            "Epoch 295/500\n",
            "15/15 [==============================] - 2s 167ms/step - loss: 0.0014 - mae: 0.0279 - val_loss: 0.0011 - val_mae: 0.0245 - lr: 1.0000e-05\n",
            "Epoch 296/500\n",
            "15/15 [==============================] - 3s 227ms/step - loss: 0.0015 - mae: 0.0284 - val_loss: 0.0011 - val_mae: 0.0244 - lr: 1.0000e-05\n",
            "Epoch 297/500\n",
            "15/15 [==============================] - 2s 134ms/step - loss: 0.0015 - mae: 0.0285 - val_loss: 0.0011 - val_mae: 0.0245 - lr: 1.0000e-05\n",
            "Epoch 298/500\n",
            "15/15 [==============================] - 2s 137ms/step - loss: 0.0014 - mae: 0.0280 - val_loss: 0.0011 - val_mae: 0.0246 - lr: 1.0000e-05\n",
            "Epoch 299/500\n",
            "15/15 [==============================] - 2s 131ms/step - loss: 0.0014 - mae: 0.0282 - val_loss: 0.0011 - val_mae: 0.0244 - lr: 1.0000e-05\n",
            "Epoch 300/500\n",
            "15/15 [==============================] - 2s 131ms/step - loss: 0.0014 - mae: 0.0280 - val_loss: 0.0011 - val_mae: 0.0243 - lr: 1.0000e-05\n",
            "Epoch 301/500\n",
            "15/15 [==============================] - 3s 237ms/step - loss: 0.0014 - mae: 0.0280 - val_loss: 0.0011 - val_mae: 0.0244 - lr: 1.0000e-05\n",
            "Epoch 302/500\n",
            "15/15 [==============================] - 2s 137ms/step - loss: 0.0015 - mae: 0.0285 - val_loss: 0.0011 - val_mae: 0.0243 - lr: 1.0000e-05\n",
            "Epoch 303/500\n",
            "15/15 [==============================] - 2s 135ms/step - loss: 0.0014 - mae: 0.0283 - val_loss: 0.0011 - val_mae: 0.0242 - lr: 1.0000e-05\n",
            "Epoch 304/500\n",
            "15/15 [==============================] - 2s 131ms/step - loss: 0.0014 - mae: 0.0282 - val_loss: 0.0011 - val_mae: 0.0244 - lr: 1.0000e-05\n",
            "Epoch 305/500\n",
            "15/15 [==============================] - 2s 131ms/step - loss: 0.0014 - mae: 0.0278 - val_loss: 0.0011 - val_mae: 0.0245 - lr: 1.0000e-05\n",
            "Epoch 306/500\n",
            "15/15 [==============================] - 3s 231ms/step - loss: 0.0015 - mae: 0.0283 - val_loss: 0.0011 - val_mae: 0.0245 - lr: 1.0000e-05\n",
            "Epoch 307/500\n",
            "15/15 [==============================] - 2s 130ms/step - loss: 0.0015 - mae: 0.0282 - val_loss: 0.0011 - val_mae: 0.0244 - lr: 1.0000e-05\n",
            "Epoch 308/500\n",
            "15/15 [==============================] - 2s 134ms/step - loss: 0.0014 - mae: 0.0286 - val_loss: 0.0011 - val_mae: 0.0243 - lr: 1.0000e-05\n",
            "Epoch 309/500\n",
            "15/15 [==============================] - 2s 134ms/step - loss: 0.0014 - mae: 0.0281 - val_loss: 0.0011 - val_mae: 0.0242 - lr: 1.0000e-05\n",
            "Epoch 310/500\n",
            "15/15 [==============================] - 2s 140ms/step - loss: 0.0014 - mae: 0.0280 - val_loss: 0.0011 - val_mae: 0.0244 - lr: 1.0000e-05\n",
            "Epoch 311/500\n",
            "15/15 [==============================] - 2s 163ms/step - loss: 0.0015 - mae: 0.0288 - val_loss: 0.0011 - val_mae: 0.0243 - lr: 1.0000e-05\n",
            "Epoch 312/500\n",
            "15/15 [==============================] - 3s 230ms/step - loss: 0.0014 - mae: 0.0279 - val_loss: 0.0011 - val_mae: 0.0244 - lr: 1.0000e-05\n",
            "Epoch 313/500\n",
            "15/15 [==============================] - 2s 132ms/step - loss: 0.0014 - mae: 0.0281 - val_loss: 0.0011 - val_mae: 0.0244 - lr: 1.0000e-05\n",
            "Epoch 314/500\n",
            "15/15 [==============================] - 2s 143ms/step - loss: 0.0014 - mae: 0.0280 - val_loss: 0.0011 - val_mae: 0.0242 - lr: 1.0000e-05\n",
            "Epoch 315/500\n",
            "15/15 [==============================] - 2s 129ms/step - loss: 0.0013 - mae: 0.0277 - val_loss: 0.0011 - val_mae: 0.0244 - lr: 1.0000e-05\n",
            "Epoch 316/500\n",
            "15/15 [==============================] - 2s 132ms/step - loss: 0.0014 - mae: 0.0278 - val_loss: 0.0011 - val_mae: 0.0243 - lr: 1.0000e-05\n",
            "Epoch 317/500\n",
            "15/15 [==============================] - 2s 157ms/step - loss: 0.0014 - mae: 0.0280 - val_loss: 0.0011 - val_mae: 0.0241 - lr: 1.0000e-05\n",
            "Epoch 318/500\n",
            "15/15 [==============================] - 3s 227ms/step - loss: 0.0015 - mae: 0.0283 - val_loss: 0.0011 - val_mae: 0.0241 - lr: 1.0000e-05\n",
            "Epoch 319/500\n",
            "15/15 [==============================] - 2s 143ms/step - loss: 0.0015 - mae: 0.0284 - val_loss: 0.0011 - val_mae: 0.0242 - lr: 1.0000e-05\n",
            "Epoch 320/500\n",
            "15/15 [==============================] - 2s 142ms/step - loss: 0.0014 - mae: 0.0278 - val_loss: 0.0011 - val_mae: 0.0241 - lr: 1.0000e-05\n",
            "Epoch 321/500\n",
            "15/15 [==============================] - 2s 131ms/step - loss: 0.0015 - mae: 0.0283 - val_loss: 0.0011 - val_mae: 0.0242 - lr: 1.0000e-05\n",
            "Epoch 322/500\n",
            "15/15 [==============================] - 3s 197ms/step - loss: 0.0014 - mae: 0.0281 - val_loss: 0.0011 - val_mae: 0.0243 - lr: 1.0000e-05\n",
            "Epoch 323/500\n",
            "15/15 [==============================] - 3s 199ms/step - loss: 0.0014 - mae: 0.0275 - val_loss: 0.0011 - val_mae: 0.0242 - lr: 1.0000e-05\n",
            "Epoch 324/500\n",
            "15/15 [==============================] - 2s 143ms/step - loss: 0.0014 - mae: 0.0278 - val_loss: 0.0011 - val_mae: 0.0242 - lr: 1.0000e-05\n",
            "Epoch 325/500\n",
            "15/15 [==============================] - 2s 142ms/step - loss: 0.0014 - mae: 0.0281 - val_loss: 0.0011 - val_mae: 0.0242 - lr: 1.0000e-05\n",
            "Epoch 326/500\n",
            "15/15 [==============================] - 2s 133ms/step - loss: 0.0014 - mae: 0.0281 - val_loss: 0.0011 - val_mae: 0.0240 - lr: 1.0000e-05\n",
            "Epoch 327/500\n",
            "15/15 [==============================] - 3s 228ms/step - loss: 0.0014 - mae: 0.0278 - val_loss: 0.0011 - val_mae: 0.0240 - lr: 1.0000e-05\n",
            "Epoch 328/500\n",
            "15/15 [==============================] - 2s 134ms/step - loss: 0.0014 - mae: 0.0280 - val_loss: 0.0011 - val_mae: 0.0242 - lr: 1.0000e-05\n",
            "Epoch 329/500\n",
            "15/15 [==============================] - 2s 131ms/step - loss: 0.0014 - mae: 0.0281 - val_loss: 0.0011 - val_mae: 0.0243 - lr: 1.0000e-05\n",
            "Epoch 330/500\n",
            "15/15 [==============================] - 2s 129ms/step - loss: 0.0015 - mae: 0.0283 - val_loss: 0.0011 - val_mae: 0.0244 - lr: 1.0000e-05\n",
            "Epoch 331/500\n",
            "15/15 [==============================] - 2s 133ms/step - loss: 0.0014 - mae: 0.0276 - val_loss: 0.0011 - val_mae: 0.0244 - lr: 1.0000e-05\n",
            "Epoch 332/500\n",
            "15/15 [==============================] - 3s 232ms/step - loss: 0.0014 - mae: 0.0280 - val_loss: 0.0011 - val_mae: 0.0243 - lr: 1.0000e-05\n",
            "Epoch 333/500\n",
            "15/15 [==============================] - 2s 153ms/step - loss: 0.0014 - mae: 0.0276 - val_loss: 0.0011 - val_mae: 0.0241 - lr: 1.0000e-05\n",
            "Epoch 334/500\n",
            "15/15 [==============================] - 2s 137ms/step - loss: 0.0014 - mae: 0.0280 - val_loss: 0.0011 - val_mae: 0.0241 - lr: 1.0000e-05\n",
            "Epoch 335/500\n",
            "15/15 [==============================] - 2s 133ms/step - loss: 0.0015 - mae: 0.0283 - val_loss: 0.0011 - val_mae: 0.0240 - lr: 1.0000e-05\n",
            "Epoch 336/500\n",
            "15/15 [==============================] - 2s 169ms/step - loss: 0.0014 - mae: 0.0279 - val_loss: 0.0011 - val_mae: 0.0241 - lr: 1.0000e-05\n",
            "Epoch 337/500\n",
            "15/15 [==============================] - 4s 235ms/step - loss: 0.0014 - mae: 0.0285 - val_loss: 0.0011 - val_mae: 0.0241 - lr: 1.0000e-05\n",
            "Epoch 338/500\n",
            "15/15 [==============================] - 3s 169ms/step - loss: 0.0014 - mae: 0.0279 - val_loss: 0.0011 - val_mae: 0.0241 - lr: 1.0000e-05\n",
            "Epoch 339/500\n",
            "15/15 [==============================] - 2s 133ms/step - loss: 0.0014 - mae: 0.0278 - val_loss: 0.0011 - val_mae: 0.0242 - lr: 1.0000e-05\n",
            "Epoch 340/500\n",
            "15/15 [==============================] - 2s 164ms/step - loss: 0.0014 - mae: 0.0280 - val_loss: 0.0011 - val_mae: 0.0244 - lr: 1.0000e-05\n",
            "Epoch 341/500\n",
            "15/15 [==============================] - 4s 258ms/step - loss: 0.0014 - mae: 0.0281 - val_loss: 0.0011 - val_mae: 0.0239 - lr: 1.0000e-05\n",
            "Epoch 342/500\n",
            "15/15 [==============================] - 4s 263ms/step - loss: 0.0014 - mae: 0.0280 - val_loss: 0.0011 - val_mae: 0.0240 - lr: 1.0000e-05\n",
            "Epoch 343/500\n",
            "15/15 [==============================] - 4s 237ms/step - loss: 0.0015 - mae: 0.0283 - val_loss: 0.0011 - val_mae: 0.0244 - lr: 1.0000e-05\n",
            "Epoch 344/500\n",
            "15/15 [==============================] - 4s 280ms/step - loss: 0.0014 - mae: 0.0281 - val_loss: 0.0011 - val_mae: 0.0241 - lr: 1.0000e-05\n",
            "Epoch 345/500\n",
            "15/15 [==============================] - 4s 248ms/step - loss: 0.0014 - mae: 0.0275 - val_loss: 0.0011 - val_mae: 0.0240 - lr: 1.0000e-05\n",
            "Epoch 346/500\n",
            "15/15 [==============================] - 3s 181ms/step - loss: 0.0014 - mae: 0.0276 - val_loss: 0.0011 - val_mae: 0.0241 - lr: 1.0000e-05\n",
            "Epoch 347/500\n",
            "15/15 [==============================] - 4s 244ms/step - loss: 0.0014 - mae: 0.0278 - val_loss: 0.0011 - val_mae: 0.0242 - lr: 1.0000e-05\n",
            "Epoch 348/500\n",
            "15/15 [==============================] - 3s 207ms/step - loss: 0.0014 - mae: 0.0275 - val_loss: 0.0011 - val_mae: 0.0243 - lr: 1.0000e-05\n",
            "Epoch 349/500\n",
            "15/15 [==============================] - 3s 218ms/step - loss: 0.0014 - mae: 0.0278 - val_loss: 0.0011 - val_mae: 0.0240 - lr: 1.0000e-05\n",
            "Epoch 350/500\n",
            "15/15 [==============================] - 5s 314ms/step - loss: 0.0014 - mae: 0.0279 - val_loss: 0.0011 - val_mae: 0.0241 - lr: 1.0000e-05\n",
            "Epoch 351/500\n",
            "15/15 [==============================] - 4s 244ms/step - loss: 0.0014 - mae: 0.0276 - val_loss: 0.0011 - val_mae: 0.0243 - lr: 1.0000e-05\n",
            "Epoch 352/500\n",
            "15/15 [==============================] - 3s 230ms/step - loss: 0.0014 - mae: 0.0278 - val_loss: 0.0011 - val_mae: 0.0242 - lr: 1.0000e-05\n",
            "Epoch 353/500\n",
            "15/15 [==============================] - 4s 255ms/step - loss: 0.0014 - mae: 0.0279 - val_loss: 0.0011 - val_mae: 0.0240 - lr: 1.0000e-05\n",
            "Epoch 354/500\n",
            "15/15 [==============================] - 4s 282ms/step - loss: 0.0014 - mae: 0.0277 - val_loss: 0.0011 - val_mae: 0.0239 - lr: 1.0000e-05\n",
            "Epoch 355/500\n",
            "15/15 [==============================] - 2s 146ms/step - loss: 0.0014 - mae: 0.0281 - val_loss: 0.0011 - val_mae: 0.0242 - lr: 1.0000e-05\n",
            "Epoch 356/500\n",
            "15/15 [==============================] - 2s 140ms/step - loss: 0.0014 - mae: 0.0282 - val_loss: 0.0011 - val_mae: 0.0240 - lr: 1.0000e-05\n",
            "Epoch 357/500\n",
            "15/15 [==============================] - 2s 134ms/step - loss: 0.0014 - mae: 0.0282 - val_loss: 0.0011 - val_mae: 0.0239 - lr: 1.0000e-05\n",
            "Epoch 358/500\n",
            "15/15 [==============================] - 2s 132ms/step - loss: 0.0014 - mae: 0.0277 - val_loss: 0.0011 - val_mae: 0.0238 - lr: 1.0000e-05\n",
            "Epoch 359/500\n",
            "15/15 [==============================] - 3s 200ms/step - loss: 0.0014 - mae: 0.0283 - val_loss: 0.0011 - val_mae: 0.0240 - lr: 1.0000e-05\n",
            "Epoch 360/500\n",
            "15/15 [==============================] - 3s 194ms/step - loss: 0.0014 - mae: 0.0280 - val_loss: 0.0011 - val_mae: 0.0240 - lr: 1.0000e-05\n",
            "Epoch 361/500\n",
            "15/15 [==============================] - 4s 239ms/step - loss: 0.0014 - mae: 0.0280 - val_loss: 0.0011 - val_mae: 0.0241 - lr: 1.0000e-05\n",
            "Epoch 362/500\n",
            "15/15 [==============================] - 4s 282ms/step - loss: 0.0014 - mae: 0.0285 - val_loss: 0.0011 - val_mae: 0.0243 - lr: 1.0000e-05\n",
            "Epoch 363/500\n",
            "15/15 [==============================] - 4s 237ms/step - loss: 0.0014 - mae: 0.0279 - val_loss: 0.0011 - val_mae: 0.0240 - lr: 1.0000e-05\n",
            "Epoch 364/500\n",
            "15/15 [==============================] - 4s 258ms/step - loss: 0.0014 - mae: 0.0274 - val_loss: 0.0011 - val_mae: 0.0239 - lr: 1.0000e-05\n",
            "Epoch 365/500\n",
            "15/15 [==============================] - 5s 313ms/step - loss: 0.0014 - mae: 0.0275 - val_loss: 0.0011 - val_mae: 0.0241 - lr: 1.0000e-05\n",
            "Epoch 366/500\n",
            "15/15 [==============================] - 5s 327ms/step - loss: 0.0014 - mae: 0.0277 - val_loss: 0.0011 - val_mae: 0.0239 - lr: 1.0000e-05\n",
            "Epoch 367/500\n",
            "15/15 [==============================] - 4s 260ms/step - loss: 0.0014 - mae: 0.0273 - val_loss: 0.0011 - val_mae: 0.0239 - lr: 1.0000e-05\n",
            "Epoch 368/500\n",
            "15/15 [==============================] - 3s 233ms/step - loss: 0.0014 - mae: 0.0275 - val_loss: 0.0011 - val_mae: 0.0241 - lr: 1.0000e-05\n",
            "Epoch 369/500\n",
            "15/15 [==============================] - 4s 284ms/step - loss: 0.0014 - mae: 0.0280 - val_loss: 0.0011 - val_mae: 0.0241 - lr: 1.0000e-05\n",
            "Epoch 370/500\n",
            "15/15 [==============================] - 3s 173ms/step - loss: 0.0014 - mae: 0.0276 - val_loss: 0.0011 - val_mae: 0.0240 - lr: 1.0000e-05\n",
            "Epoch 371/500\n",
            "15/15 [==============================] - 3s 227ms/step - loss: 0.0013 - mae: 0.0274 - val_loss: 0.0011 - val_mae: 0.0239 - lr: 1.0000e-05\n",
            "Epoch 372/500\n",
            "15/15 [==============================] - 5s 316ms/step - loss: 0.0014 - mae: 0.0276 - val_loss: 0.0011 - val_mae: 0.0240 - lr: 1.0000e-05\n",
            "Epoch 373/500\n",
            "15/15 [==============================] - 2s 145ms/step - loss: 0.0014 - mae: 0.0273 - val_loss: 0.0011 - val_mae: 0.0238 - lr: 1.0000e-05\n",
            "Epoch 374/500\n",
            "15/15 [==============================] - 2s 162ms/step - loss: 0.0013 - mae: 0.0269 - val_loss: 0.0011 - val_mae: 0.0239 - lr: 1.0000e-05\n",
            "Epoch 375/500\n",
            "15/15 [==============================] - 3s 190ms/step - loss: 0.0014 - mae: 0.0274 - val_loss: 0.0011 - val_mae: 0.0241 - lr: 1.0000e-05\n",
            "Epoch 376/500\n",
            "15/15 [==============================] - 5s 320ms/step - loss: 0.0014 - mae: 0.0276 - val_loss: 0.0011 - val_mae: 0.0241 - lr: 1.0000e-05\n",
            "Epoch 377/500\n",
            "15/15 [==============================] - 3s 230ms/step - loss: 0.0013 - mae: 0.0268 - val_loss: 0.0011 - val_mae: 0.0238 - lr: 1.0000e-05\n",
            "Epoch 378/500\n",
            "15/15 [==============================] - 3s 184ms/step - loss: 0.0014 - mae: 0.0273 - val_loss: 0.0011 - val_mae: 0.0238 - lr: 1.0000e-05\n",
            "Epoch 379/500\n",
            "15/15 [==============================] - 3s 173ms/step - loss: 0.0014 - mae: 0.0275 - val_loss: 0.0011 - val_mae: 0.0239 - lr: 1.0000e-05\n",
            "Epoch 380/500\n",
            "15/15 [==============================] - 4s 265ms/step - loss: 0.0013 - mae: 0.0270 - val_loss: 0.0011 - val_mae: 0.0240 - lr: 1.0000e-05\n",
            "Epoch 381/500\n",
            "15/15 [==============================] - 4s 248ms/step - loss: 0.0014 - mae: 0.0275 - val_loss: 0.0011 - val_mae: 0.0235 - lr: 1.0000e-05\n",
            "Epoch 382/500\n",
            "15/15 [==============================] - 3s 185ms/step - loss: 0.0014 - mae: 0.0276 - val_loss: 0.0011 - val_mae: 0.0236 - lr: 1.0000e-05\n",
            "Epoch 383/500\n",
            "15/15 [==============================] - 3s 202ms/step - loss: 0.0014 - mae: 0.0281 - val_loss: 0.0011 - val_mae: 0.0239 - lr: 1.0000e-05\n",
            "Epoch 384/500\n",
            "15/15 [==============================] - 3s 170ms/step - loss: 0.0014 - mae: 0.0281 - val_loss: 0.0011 - val_mae: 0.0239 - lr: 1.0000e-05\n",
            "Epoch 385/500\n",
            "15/15 [==============================] - 5s 314ms/step - loss: 0.0014 - mae: 0.0277 - val_loss: 0.0011 - val_mae: 0.0240 - lr: 1.0000e-05\n",
            "Epoch 386/500\n",
            "15/15 [==============================] - 5s 301ms/step - loss: 0.0014 - mae: 0.0276 - val_loss: 0.0011 - val_mae: 0.0237 - lr: 1.0000e-05\n",
            "Epoch 387/500\n",
            "15/15 [==============================] - 4s 244ms/step - loss: 0.0014 - mae: 0.0272 - val_loss: 0.0011 - val_mae: 0.0238 - lr: 1.0000e-05\n",
            "Epoch 388/500\n",
            "15/15 [==============================] - 3s 232ms/step - loss: 0.0014 - mae: 0.0279 - val_loss: 0.0011 - val_mae: 0.0240 - lr: 1.0000e-05\n",
            "Epoch 389/500\n",
            "15/15 [==============================] - 3s 171ms/step - loss: 0.0014 - mae: 0.0276 - val_loss: 0.0011 - val_mae: 0.0240 - lr: 1.0000e-05\n",
            "Epoch 390/500\n",
            "15/15 [==============================] - 4s 269ms/step - loss: 0.0014 - mae: 0.0279 - val_loss: 0.0011 - val_mae: 0.0237 - lr: 1.0000e-05\n",
            "Epoch 391/500\n",
            "15/15 [==============================] - 6s 396ms/step - loss: 0.0014 - mae: 0.0279 - val_loss: 0.0011 - val_mae: 0.0238 - lr: 1.0000e-05\n",
            "Epoch 392/500\n",
            "15/15 [==============================] - 3s 185ms/step - loss: 0.0014 - mae: 0.0279 - val_loss: 0.0011 - val_mae: 0.0237 - lr: 1.0000e-05\n",
            "Epoch 393/500\n",
            "15/15 [==============================] - 3s 177ms/step - loss: 0.0014 - mae: 0.0273 - val_loss: 0.0011 - val_mae: 0.0239 - lr: 1.0000e-05\n",
            "Epoch 394/500\n",
            "15/15 [==============================] - 5s 339ms/step - loss: 0.0014 - mae: 0.0279 - val_loss: 0.0011 - val_mae: 0.0236 - lr: 1.0000e-05\n",
            "Epoch 395/500\n",
            "15/15 [==============================] - 2s 156ms/step - loss: 0.0014 - mae: 0.0275 - val_loss: 0.0011 - val_mae: 0.0236 - lr: 1.0000e-05\n",
            "Epoch 396/500\n",
            "15/15 [==============================] - 2s 143ms/step - loss: 0.0013 - mae: 0.0268 - val_loss: 0.0011 - val_mae: 0.0238 - lr: 1.0000e-05\n",
            "Epoch 397/500\n",
            "15/15 [==============================] - 3s 214ms/step - loss: 0.0014 - mae: 0.0274 - val_loss: 0.0011 - val_mae: 0.0238 - lr: 1.0000e-05\n",
            "Epoch 398/500\n",
            "15/15 [==============================] - 4s 303ms/step - loss: 0.0014 - mae: 0.0277 - val_loss: 0.0011 - val_mae: 0.0238 - lr: 1.0000e-05\n",
            "Epoch 399/500\n",
            "15/15 [==============================] - 4s 250ms/step - loss: 0.0013 - mae: 0.0270 - val_loss: 0.0011 - val_mae: 0.0236 - lr: 1.0000e-05\n",
            "Epoch 400/500\n",
            "15/15 [==============================] - 3s 169ms/step - loss: 0.0014 - mae: 0.0277 - val_loss: 0.0011 - val_mae: 0.0240 - lr: 1.0000e-05\n",
            "Epoch 401/500\n",
            "15/15 [==============================] - 5s 322ms/step - loss: 0.0014 - mae: 0.0276 - val_loss: 0.0011 - val_mae: 0.0236 - lr: 1.0000e-05\n",
            "Epoch 402/500\n",
            "15/15 [==============================] - 2s 158ms/step - loss: 0.0014 - mae: 0.0282 - val_loss: 0.0011 - val_mae: 0.0236 - lr: 1.0000e-05\n",
            "Epoch 403/500\n",
            "15/15 [==============================] - 2s 146ms/step - loss: 0.0013 - mae: 0.0270 - val_loss: 0.0011 - val_mae: 0.0239 - lr: 1.0000e-05\n",
            "Epoch 404/500\n",
            "15/15 [==============================] - 3s 225ms/step - loss: 0.0014 - mae: 0.0281 - val_loss: 0.0011 - val_mae: 0.0237 - lr: 1.0000e-05\n",
            "Epoch 405/500\n",
            "15/15 [==============================] - 5s 340ms/step - loss: 0.0014 - mae: 0.0276 - val_loss: 0.0011 - val_mae: 0.0235 - lr: 1.0000e-05\n",
            "Epoch 406/500\n",
            "15/15 [==============================] - 4s 271ms/step - loss: 0.0013 - mae: 0.0273 - val_loss: 0.0011 - val_mae: 0.0237 - lr: 1.0000e-05\n",
            "Epoch 407/500\n",
            "15/15 [==============================] - 3s 234ms/step - loss: 0.0013 - mae: 0.0267 - val_loss: 0.0011 - val_mae: 0.0239 - lr: 1.0000e-05\n",
            "Epoch 408/500\n",
            "15/15 [==============================] - 3s 229ms/step - loss: 0.0014 - mae: 0.0276 - val_loss: 0.0010 - val_mae: 0.0237 - lr: 1.0000e-05\n",
            "Epoch 409/500\n",
            "15/15 [==============================] - 4s 265ms/step - loss: 0.0014 - mae: 0.0277 - val_loss: 0.0010 - val_mae: 0.0237 - lr: 1.0000e-05\n",
            "Epoch 410/500\n",
            "15/15 [==============================] - 2s 153ms/step - loss: 0.0014 - mae: 0.0275 - val_loss: 0.0011 - val_mae: 0.0239 - lr: 1.0000e-05\n",
            "Epoch 411/500\n",
            "15/15 [==============================] - 2s 141ms/step - loss: 0.0013 - mae: 0.0270 - val_loss: 0.0010 - val_mae: 0.0237 - lr: 1.0000e-05\n",
            "Epoch 412/500\n",
            "15/15 [==============================] - 2s 140ms/step - loss: 0.0013 - mae: 0.0269 - val_loss: 0.0010 - val_mae: 0.0236 - lr: 1.0000e-05\n",
            "Epoch 413/500\n",
            "15/15 [==============================] - 2s 166ms/step - loss: 0.0013 - mae: 0.0272 - val_loss: 0.0010 - val_mae: 0.0238 - lr: 1.0000e-05\n",
            "Epoch 414/500\n",
            "15/15 [==============================] - 3s 227ms/step - loss: 0.0014 - mae: 0.0275 - val_loss: 0.0010 - val_mae: 0.0237 - lr: 1.0000e-05\n",
            "Epoch 415/500\n",
            "15/15 [==============================] - 2s 133ms/step - loss: 0.0013 - mae: 0.0271 - val_loss: 0.0010 - val_mae: 0.0236 - lr: 1.0000e-05\n",
            "Epoch 416/500\n",
            "15/15 [==============================] - 3s 179ms/step - loss: 0.0014 - mae: 0.0277 - val_loss: 0.0010 - val_mae: 0.0236 - lr: 1.0000e-05\n",
            "Epoch 417/500\n",
            "15/15 [==============================] - 2s 155ms/step - loss: 0.0014 - mae: 0.0278 - val_loss: 0.0010 - val_mae: 0.0237 - lr: 1.0000e-05\n",
            "Epoch 418/500\n",
            "15/15 [==============================] - 4s 245ms/step - loss: 0.0013 - mae: 0.0269 - val_loss: 0.0010 - val_mae: 0.0238 - lr: 1.0000e-05\n",
            "Epoch 419/500\n",
            "15/15 [==============================] - 2s 164ms/step - loss: 0.0014 - mae: 0.0272 - val_loss: 0.0010 - val_mae: 0.0236 - lr: 1.0000e-05\n",
            "Epoch 420/500\n",
            "15/15 [==============================] - 2s 160ms/step - loss: 0.0014 - mae: 0.0275 - val_loss: 0.0010 - val_mae: 0.0235 - lr: 1.0000e-05\n",
            "Epoch 421/500\n",
            "15/15 [==============================] - 3s 234ms/step - loss: 0.0013 - mae: 0.0273 - val_loss: 0.0010 - val_mae: 0.0237 - lr: 1.0000e-05\n",
            "Epoch 422/500\n",
            "15/15 [==============================] - 4s 297ms/step - loss: 0.0014 - mae: 0.0270 - val_loss: 0.0010 - val_mae: 0.0237 - lr: 1.0000e-05\n",
            "Epoch 423/500\n",
            "15/15 [==============================] - 3s 178ms/step - loss: 0.0013 - mae: 0.0270 - val_loss: 0.0010 - val_mae: 0.0236 - lr: 1.0000e-05\n",
            "Epoch 424/500\n",
            "15/15 [==============================] - 4s 284ms/step - loss: 0.0013 - mae: 0.0267 - val_loss: 0.0010 - val_mae: 0.0237 - lr: 1.0000e-05\n",
            "Epoch 425/500\n",
            "15/15 [==============================] - 4s 280ms/step - loss: 0.0014 - mae: 0.0275 - val_loss: 0.0010 - val_mae: 0.0239 - lr: 1.0000e-05\n",
            "Epoch 426/500\n",
            "15/15 [==============================] - 3s 217ms/step - loss: 0.0013 - mae: 0.0269 - val_loss: 0.0010 - val_mae: 0.0235 - lr: 1.0000e-05\n",
            "Epoch 427/500\n",
            "15/15 [==============================] - 2s 160ms/step - loss: 0.0013 - mae: 0.0272 - val_loss: 0.0010 - val_mae: 0.0235 - lr: 1.0000e-05\n",
            "Epoch 428/500\n",
            "15/15 [==============================] - 3s 185ms/step - loss: 0.0014 - mae: 0.0277 - val_loss: 0.0010 - val_mae: 0.0239 - lr: 1.0000e-05\n",
            "Epoch 429/500\n",
            "15/15 [==============================] - 4s 281ms/step - loss: 0.0014 - mae: 0.0273 - val_loss: 0.0010 - val_mae: 0.0235 - lr: 1.0000e-05\n",
            "Epoch 430/500\n",
            "15/15 [==============================] - 4s 242ms/step - loss: 0.0014 - mae: 0.0277 - val_loss: 0.0010 - val_mae: 0.0233 - lr: 1.0000e-05\n",
            "Epoch 431/500\n",
            "15/15 [==============================] - 2s 152ms/step - loss: 0.0013 - mae: 0.0270 - val_loss: 0.0010 - val_mae: 0.0236 - lr: 1.0000e-05\n",
            "Epoch 432/500\n",
            "15/15 [==============================] - 3s 225ms/step - loss: 0.0013 - mae: 0.0269 - val_loss: 0.0010 - val_mae: 0.0236 - lr: 1.0000e-05\n",
            "Epoch 433/500\n",
            "15/15 [==============================] - 4s 258ms/step - loss: 0.0014 - mae: 0.0271 - val_loss: 0.0010 - val_mae: 0.0237 - lr: 1.0000e-05\n",
            "Epoch 434/500\n",
            "15/15 [==============================] - 3s 221ms/step - loss: 0.0013 - mae: 0.0268 - val_loss: 0.0010 - val_mae: 0.0235 - lr: 1.0000e-05\n",
            "Epoch 435/500\n",
            "15/15 [==============================] - 2s 158ms/step - loss: 0.0013 - mae: 0.0272 - val_loss: 0.0010 - val_mae: 0.0234 - lr: 1.0000e-05\n",
            "Epoch 436/500\n",
            "15/15 [==============================] - 4s 237ms/step - loss: 0.0013 - mae: 0.0272 - val_loss: 0.0010 - val_mae: 0.0238 - lr: 1.0000e-05\n",
            "Epoch 437/500\n",
            "15/15 [==============================] - 2s 134ms/step - loss: 0.0013 - mae: 0.0271 - val_loss: 0.0010 - val_mae: 0.0236 - lr: 1.0000e-05\n",
            "Epoch 438/500\n",
            "15/15 [==============================] - 2s 135ms/step - loss: 0.0013 - mae: 0.0272 - val_loss: 0.0010 - val_mae: 0.0235 - lr: 1.0000e-05\n",
            "Epoch 439/500\n",
            "15/15 [==============================] - 3s 225ms/step - loss: 0.0013 - mae: 0.0267 - val_loss: 0.0010 - val_mae: 0.0236 - lr: 1.0000e-05\n",
            "Epoch 440/500\n",
            "15/15 [==============================] - 6s 392ms/step - loss: 0.0013 - mae: 0.0269 - val_loss: 0.0010 - val_mae: 0.0234 - lr: 1.0000e-05\n",
            "Epoch 441/500\n",
            "15/15 [==============================] - 4s 289ms/step - loss: 0.0014 - mae: 0.0275 - val_loss: 0.0010 - val_mae: 0.0237 - lr: 1.0000e-05\n",
            "Epoch 442/500\n",
            "15/15 [==============================] - 4s 248ms/step - loss: 0.0014 - mae: 0.0279 - val_loss: 0.0010 - val_mae: 0.0233 - lr: 1.0000e-05\n",
            "Epoch 443/500\n",
            "15/15 [==============================] - 5s 323ms/step - loss: 0.0013 - mae: 0.0268 - val_loss: 0.0010 - val_mae: 0.0236 - lr: 1.0000e-05\n",
            "Epoch 444/500\n",
            "15/15 [==============================] - 2s 162ms/step - loss: 0.0013 - mae: 0.0271 - val_loss: 0.0010 - val_mae: 0.0233 - lr: 1.0000e-05\n",
            "Epoch 445/500\n",
            "15/15 [==============================] - 5s 351ms/step - loss: 0.0014 - mae: 0.0272 - val_loss: 0.0010 - val_mae: 0.0236 - lr: 1.0000e-05\n",
            "Epoch 446/500\n",
            "15/15 [==============================] - 5s 301ms/step - loss: 0.0013 - mae: 0.0271 - val_loss: 0.0010 - val_mae: 0.0233 - lr: 1.0000e-05\n",
            "Epoch 447/500\n",
            "15/15 [==============================] - 4s 277ms/step - loss: 0.0014 - mae: 0.0276 - val_loss: 0.0010 - val_mae: 0.0236 - lr: 1.0000e-05\n",
            "Epoch 448/500\n",
            "15/15 [==============================] - 3s 229ms/step - loss: 0.0014 - mae: 0.0273 - val_loss: 0.0010 - val_mae: 0.0238 - lr: 1.0000e-05\n",
            "Epoch 449/500\n",
            "15/15 [==============================] - 3s 189ms/step - loss: 0.0013 - mae: 0.0269 - val_loss: 0.0010 - val_mae: 0.0233 - lr: 1.0000e-05\n",
            "Epoch 450/500\n",
            "15/15 [==============================] - 4s 256ms/step - loss: 0.0014 - mae: 0.0277 - val_loss: 0.0010 - val_mae: 0.0234 - lr: 1.0000e-05\n",
            "Epoch 451/500\n",
            "15/15 [==============================] - 3s 228ms/step - loss: 0.0014 - mae: 0.0274 - val_loss: 0.0010 - val_mae: 0.0236 - lr: 1.0000e-05\n",
            "Epoch 452/500\n",
            "15/15 [==============================] - 3s 177ms/step - loss: 0.0014 - mae: 0.0274 - val_loss: 0.0010 - val_mae: 0.0234 - lr: 1.0000e-05\n",
            "Epoch 453/500\n",
            "15/15 [==============================] - 2s 135ms/step - loss: 0.0013 - mae: 0.0273 - val_loss: 0.0010 - val_mae: 0.0235 - lr: 1.0000e-05\n",
            "Epoch 454/500\n",
            "15/15 [==============================] - 3s 188ms/step - loss: 0.0014 - mae: 0.0274 - val_loss: 0.0010 - val_mae: 0.0236 - lr: 1.0000e-05\n",
            "Epoch 455/500\n",
            "15/15 [==============================] - 3s 187ms/step - loss: 0.0014 - mae: 0.0276 - val_loss: 0.0010 - val_mae: 0.0232 - lr: 1.0000e-05\n",
            "Epoch 456/500\n",
            "15/15 [==============================] - 6s 387ms/step - loss: 0.0013 - mae: 0.0270 - val_loss: 0.0010 - val_mae: 0.0234 - lr: 1.0000e-05\n",
            "Epoch 457/500\n",
            "15/15 [==============================] - 2s 134ms/step - loss: 0.0014 - mae: 0.0277 - val_loss: 0.0010 - val_mae: 0.0235 - lr: 1.0000e-05\n",
            "Epoch 458/500\n",
            "15/15 [==============================] - 2s 135ms/step - loss: 0.0014 - mae: 0.0271 - val_loss: 0.0010 - val_mae: 0.0233 - lr: 1.0000e-05\n",
            "Epoch 459/500\n",
            "15/15 [==============================] - 3s 182ms/step - loss: 0.0014 - mae: 0.0283 - val_loss: 0.0010 - val_mae: 0.0233 - lr: 1.0000e-05\n",
            "Epoch 460/500\n",
            "15/15 [==============================] - 3s 223ms/step - loss: 0.0013 - mae: 0.0270 - val_loss: 0.0010 - val_mae: 0.0234 - lr: 1.0000e-05\n",
            "Epoch 461/500\n",
            "15/15 [==============================] - 2s 137ms/step - loss: 0.0013 - mae: 0.0266 - val_loss: 0.0010 - val_mae: 0.0234 - lr: 1.0000e-05\n",
            "Epoch 462/500\n",
            "15/15 [==============================] - 2s 139ms/step - loss: 0.0013 - mae: 0.0271 - val_loss: 0.0010 - val_mae: 0.0233 - lr: 1.0000e-05\n",
            "Epoch 463/500\n",
            "15/15 [==============================] - 2s 134ms/step - loss: 0.0013 - mae: 0.0272 - val_loss: 0.0010 - val_mae: 0.0233 - lr: 1.0000e-05\n",
            "Epoch 464/500\n",
            "15/15 [==============================] - 3s 182ms/step - loss: 0.0012 - mae: 0.0261 - val_loss: 0.0010 - val_mae: 0.0233 - lr: 1.0000e-05\n",
            "Epoch 465/500\n",
            "15/15 [==============================] - 3s 230ms/step - loss: 0.0014 - mae: 0.0271 - val_loss: 0.0010 - val_mae: 0.0234 - lr: 1.0000e-05\n",
            "Epoch 466/500\n",
            "15/15 [==============================] - 2s 139ms/step - loss: 0.0014 - mae: 0.0276 - val_loss: 0.0010 - val_mae: 0.0233 - lr: 1.0000e-05\n",
            "Epoch 467/500\n",
            "15/15 [==============================] - 2s 135ms/step - loss: 0.0013 - mae: 0.0265 - val_loss: 0.0010 - val_mae: 0.0234 - lr: 1.0000e-05\n",
            "Epoch 468/500\n",
            "15/15 [==============================] - 2s 140ms/step - loss: 0.0014 - mae: 0.0273 - val_loss: 0.0010 - val_mae: 0.0235 - lr: 1.0000e-05\n",
            "Epoch 469/500\n",
            "15/15 [==============================] - 2s 138ms/step - loss: 0.0014 - mae: 0.0275 - val_loss: 0.0010 - val_mae: 0.0234 - lr: 1.0000e-05\n",
            "Epoch 470/500\n",
            "15/15 [==============================] - 3s 231ms/step - loss: 0.0013 - mae: 0.0270 - val_loss: 0.0010 - val_mae: 0.0237 - lr: 1.0000e-05\n",
            "Epoch 471/500\n",
            "15/15 [==============================] - 2s 138ms/step - loss: 0.0013 - mae: 0.0269 - val_loss: 0.0010 - val_mae: 0.0234 - lr: 1.0000e-05\n",
            "Epoch 472/500\n",
            "15/15 [==============================] - 2s 136ms/step - loss: 0.0014 - mae: 0.0273 - val_loss: 0.0010 - val_mae: 0.0234 - lr: 1.0000e-05\n",
            "Epoch 473/500\n",
            "15/15 [==============================] - 2s 146ms/step - loss: 0.0013 - mae: 0.0267 - val_loss: 0.0010 - val_mae: 0.0235 - lr: 1.0000e-05\n",
            "Epoch 474/500\n",
            "15/15 [==============================] - 2s 156ms/step - loss: 0.0013 - mae: 0.0273 - val_loss: 0.0010 - val_mae: 0.0233 - lr: 1.0000e-05\n",
            "Epoch 475/500\n",
            "15/15 [==============================] - 5s 331ms/step - loss: 0.0013 - mae: 0.0271 - val_loss: 0.0010 - val_mae: 0.0233 - lr: 1.0000e-05\n",
            "Epoch 476/500\n",
            "15/15 [==============================] - 3s 214ms/step - loss: 0.0013 - mae: 0.0268 - val_loss: 0.0010 - val_mae: 0.0234 - lr: 1.0000e-05\n",
            "Epoch 477/500\n",
            "15/15 [==============================] - 3s 198ms/step - loss: 0.0013 - mae: 0.0269 - val_loss: 0.0010 - val_mae: 0.0233 - lr: 1.0000e-05\n",
            "Epoch 478/500\n",
            "15/15 [==============================] - 3s 211ms/step - loss: 0.0014 - mae: 0.0272 - val_loss: 0.0010 - val_mae: 0.0235 - lr: 1.0000e-05\n",
            "Epoch 479/500\n",
            "15/15 [==============================] - 4s 268ms/step - loss: 0.0013 - mae: 0.0269 - val_loss: 0.0010 - val_mae: 0.0236 - lr: 1.0000e-05\n",
            "Epoch 480/500\n",
            "15/15 [==============================] - 3s 218ms/step - loss: 0.0013 - mae: 0.0268 - val_loss: 9.9998e-04 - val_mae: 0.0230 - lr: 1.0000e-05\n",
            "Epoch 481/500\n",
            "15/15 [==============================] - 2s 165ms/step - loss: 0.0013 - mae: 0.0267 - val_loss: 9.9992e-04 - val_mae: 0.0231 - lr: 1.0000e-05\n",
            "Epoch 482/500\n",
            "15/15 [==============================] - 3s 231ms/step - loss: 0.0013 - mae: 0.0270 - val_loss: 0.0010 - val_mae: 0.0235 - lr: 1.0000e-05\n",
            "Epoch 483/500\n",
            "15/15 [==============================] - 4s 263ms/step - loss: 0.0013 - mae: 0.0267 - val_loss: 9.9894e-04 - val_mae: 0.0232 - lr: 1.0000e-05\n",
            "Epoch 484/500\n",
            "15/15 [==============================] - 2s 163ms/step - loss: 0.0014 - mae: 0.0272 - val_loss: 9.9732e-04 - val_mae: 0.0231 - lr: 1.0000e-05\n",
            "Epoch 485/500\n",
            "15/15 [==============================] - 2s 153ms/step - loss: 0.0013 - mae: 0.0266 - val_loss: 9.9836e-04 - val_mae: 0.0233 - lr: 1.0000e-05\n",
            "Epoch 486/500\n",
            "15/15 [==============================] - 3s 182ms/step - loss: 0.0013 - mae: 0.0274 - val_loss: 9.9814e-04 - val_mae: 0.0233 - lr: 1.0000e-05\n",
            "Epoch 487/500\n",
            "15/15 [==============================] - 5s 314ms/step - loss: 0.0014 - mae: 0.0274 - val_loss: 9.9716e-04 - val_mae: 0.0232 - lr: 1.0000e-05\n",
            "Epoch 488/500\n",
            "15/15 [==============================] - 4s 294ms/step - loss: 0.0014 - mae: 0.0273 - val_loss: 9.9738e-04 - val_mae: 0.0232 - lr: 1.0000e-05\n",
            "Epoch 489/500\n",
            "15/15 [==============================] - 3s 224ms/step - loss: 0.0013 - mae: 0.0272 - val_loss: 0.0010 - val_mae: 0.0235 - lr: 1.0000e-05\n",
            "Epoch 490/500\n",
            "15/15 [==============================] - 3s 213ms/step - loss: 0.0013 - mae: 0.0271 - val_loss: 9.9537e-04 - val_mae: 0.0231 - lr: 1.0000e-05\n",
            "Epoch 491/500\n",
            "15/15 [==============================] - 3s 230ms/step - loss: 0.0013 - mae: 0.0264 - val_loss: 9.9515e-04 - val_mae: 0.0231 - lr: 1.0000e-05\n",
            "Epoch 492/500\n",
            "15/15 [==============================] - 2s 150ms/step - loss: 0.0014 - mae: 0.0277 - val_loss: 9.9772e-04 - val_mae: 0.0233 - lr: 1.0000e-05\n",
            "Epoch 493/500\n",
            "15/15 [==============================] - 2s 133ms/step - loss: 0.0013 - mae: 0.0270 - val_loss: 9.9924e-04 - val_mae: 0.0234 - lr: 1.0000e-05\n",
            "Epoch 494/500\n",
            "15/15 [==============================] - 2s 137ms/step - loss: 0.0013 - mae: 0.0269 - val_loss: 9.9682e-04 - val_mae: 0.0233 - lr: 1.0000e-05\n",
            "Epoch 495/500\n",
            "15/15 [==============================] - 3s 175ms/step - loss: 0.0013 - mae: 0.0270 - val_loss: 9.9754e-04 - val_mae: 0.0234 - lr: 1.0000e-05\n",
            "Epoch 496/500\n",
            "15/15 [==============================] - 4s 279ms/step - loss: 0.0013 - mae: 0.0267 - val_loss: 9.9306e-04 - val_mae: 0.0230 - lr: 1.0000e-05\n",
            "Epoch 497/500\n",
            "15/15 [==============================] - 3s 231ms/step - loss: 0.0014 - mae: 0.0273 - val_loss: 9.9464e-04 - val_mae: 0.0233 - lr: 1.0000e-05\n",
            "Epoch 498/500\n",
            "15/15 [==============================] - 4s 247ms/step - loss: 0.0012 - mae: 0.0265 - val_loss: 9.9453e-04 - val_mae: 0.0233 - lr: 1.0000e-05\n",
            "Epoch 499/500\n",
            "15/15 [==============================] - 5s 329ms/step - loss: 0.0013 - mae: 0.0272 - val_loss: 9.9337e-04 - val_mae: 0.0232 - lr: 1.0000e-05\n",
            "Epoch 500/500\n",
            "15/15 [==============================] - 4s 250ms/step - loss: 0.0012 - mae: 0.0264 - val_loss: 9.9468e-04 - val_mae: 0.0233 - lr: 1.0000e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GRU_sigmoid_model.evaluate(X_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WcXZWVB3u05-",
        "outputId": "95b6fd76-86a9-4e67-8da0-916325830956"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 1s 24ms/step - loss: 9.9468e-04 - mae: 0.0233\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0009946845239028335, 0.023342275992035866]"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GRU_sigmoid_model.save(\"/content/drive/MyDrive/CRYPTO/Models/GRU_sigmoid_model.h5\")"
      ],
      "metadata": {
        "id": "qAf9pzd4vBZ7"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GRU_sigmoid_model_loaded=load_model(\"/content/drive/MyDrive/CRYPTO/Models/GRU_sigmoid_model.h5\")"
      ],
      "metadata": {
        "id": "S5WnTpkkvjwk"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model z warstwami GRU z bazową aktywacją tanh osiąga najlepsze wyniki.\n",
        "\n",
        "Dane są na tyle nieskomplikowane, że jakiekolwiek rozszerzenie modelu tylko go pogarsza.\n",
        "\n",
        "Wprowadzanie i testowanie kolejnych warstw nie przyniesie żadncyh efektów.\n",
        "\n",
        "GRU_model jest na tyle prosty że nie możemy już nic więcej z nim zrobić.\n",
        "\n",
        "Możemy uznać ten model za nasz model ostateczny.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Aoss81576b5X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Na koniec trzeba jeszcze zwrócić uwagę na jedną rzecz. Nasz ostateczny model ma gorsze wyniki niż jeszcze prostsze modele które trenowaliśmy wcześniej (modele z pętli), na których sprawdzaliśmy wpływ poszczególnych danych.\n",
        "\n",
        "Czy to oznacza, że nasz ostateczny model jest gorszy od pierwszego lepszego modelu?\n",
        "\n",
        "I tak i nie.\n",
        "\n",
        "Prosty model sekwencyjny przewiduje na podstawie zmian w cenie które zaobserwował w przeszłości i nic poza tym. Na pierwszy rzut oka widać, że jest to bardzo naiwne. Ceny rynkowe są zależne od tysięcy różnych czynników, prosty model, który tego nie rozumie, przestanie być wairygodny kiedy tylko wydarzy się coś co ma wpływ na cenę a co nie wystąpiło w przeszłości. Model który nauczył się patternów spadków i wzrostów cen nie będzie miał możliwości prawidłowo zareagować w takiej sytuacji.\n",
        "\n",
        "Model który stworzyliśmy jest w stanie zareagować na tego typu sytuacje znacznie lepiej. Używa on danych z wielu różnych źródeł, które na swój sposób obrazują działanie rynku, walut i innych coinów. Dzięki dywersyfikacji danych model ma znacznie większą odporność na niespodziewane wydarzenia na rynku.\n",
        "\n",
        "Mimo iż jego MAE jest gorsze o niecały 1% od prostego modelu. Jest on znacznie bezpieczniejszym produktem np. dla kogoś kto chce inwestować część swoich oszczędności. Nie będzie on dokładny co do złotówki(chociaż w naszym przypadku to co do USD), ale będzie znacznie stabilniejszy i odporniejszy na różnego rodzaju rynkowe zawirowania.\n",
        "\n"
      ],
      "metadata": {
        "id": "3-80K7la-14e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_predictions=GRU_model.predict(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "suYW2y0m8S-o",
        "outputId": "3702efcb-7ebd-43d8-96ca-60cab930b590"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "58/58 [==============================] - 2s 28ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions=GRU_model.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLmXsLRXvjr9",
        "outputId": "85694312-d131-4c60-d165-86263da9f8c0"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 0s 29ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_predictions=np.append(train_predictions,test_predictions)"
      ],
      "metadata": {
        "id": "5yLhjYFm8jG_"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_predictions = scalers[3].inverse_transform(final_predictions.reshape(-1, 1))"
      ],
      "metadata": {
        "id": "amu3ptSB89Qo"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_y=np.append(y_train,y_test)"
      ],
      "metadata": {
        "id": "QJou765g8XHm"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_y=scalers[3].inverse_transform(final_y.reshape(-1, 1))"
      ],
      "metadata": {
        "id": "6gijGSa-9Hy4"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nasz model miał MAE(mean absolute error) na poziomie 0.02.\n",
        "\n",
        "Używaliśmy MinMaxScaler co oznacza  że nasz model przewiduje cenę średnio o 2% większą lub mniejszą od ceny prawdziwej.\n",
        "\n",
        "Najprościej będzie to zwizualizować"
      ],
      "metadata": {
        "id": "JV7rsPOu9WjE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(final_predictions, label='Predictions', color='blue')\n",
        "plt.plot(final_y, label='Real', color='red')\n",
        "plt.title('Real values VS Predictions')\n",
        "plt.xlabel('Index')\n",
        "plt.ylabel('Value')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "igRNn0CW6VG6",
        "outputId": "140e093a-d434-4e07-aa3b-8df2e1c8f070"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BU2gsDN4HOLv"
      },
      "execution_count": 149,
      "outputs": []
    }
  ]
}